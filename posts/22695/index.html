<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>VMware系统紫屏问题定位思路 | HILL</title><meta name="keywords" content="VMware"><meta name="author" content="gaoshuai,gaoshuais@126.com"><meta name="copyright" content="gaoshuai"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="VMware系统紫屏问题定位思路引言Vmware EXSi主机在运行过程遇到严重错误时，会出现紫屏（类似windows系统的蓝屏），然后系统挂死。本文讲解如果定位VMware系统的紫屏问题。 紫屏解析出现紫屏以后，根据紫屏的提示信息，可以完成问题的初步定位。从VMware 紫屏可以获取以下下的信息。 产品和内部版本  紫色诊断屏幕中的此部分表示出错的产品和内部版本。在本示例中，产品是esxi 6.">
<meta property="og:type" content="article">
<meta property="og:title" content="VMware系统紫屏问题定位思路">
<meta property="og:url" content="https://www.gaoshuais.top/posts/22695/index.html">
<meta property="og:site_name" content="HILL">
<meta property="og:description" content="VMware系统紫屏问题定位思路引言Vmware EXSi主机在运行过程遇到严重错误时，会出现紫屏（类似windows系统的蓝屏），然后系统挂死。本文讲解如果定位VMware系统的紫屏问题。 紫屏解析出现紫屏以后，根据紫屏的提示信息，可以完成问题的初步定位。从VMware 紫屏可以获取以下下的信息。 产品和内部版本  紫色诊断屏幕中的此部分表示出错的产品和内部版本。在本示例中，产品是esxi 6.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.gaoshuais.top/img/head.jpg">
<meta property="article:published_time" content="2022-04-19T09:41:33.000Z">
<meta property="article:modified_time" content="2022-04-19T13:37:01.015Z">
<meta property="article:author" content="gaoshuai">
<meta property="article:tag" content="VMware">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.gaoshuais.top/img/head.jpg"><link rel="shortcut icon" href="/img/head.jpg"><link rel="canonical" href="https://www.gaoshuais.top/posts/22695/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'VMware系统紫屏问题定位思路',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-04-19 21:37:01'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><link rel="stylesheet" href="/css/staticbutterfly.css"><link rel="stylesheet" href="/css/waifu1.css"><link rel="stylesheet" href="/css/flat-ui.min.css"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="HILL" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于&amp;留言板</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">HILL</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于&amp;留言板</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">VMware系统紫屏问题定位思路</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-04-19T09:41:33.000Z" title="发表于 2022-04-19 17:41:33">2022-04-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-04-19T13:37:01.015Z" title="更新于 2022-04-19 21:37:01">2022-04-19</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="VMware系统紫屏问题定位思路"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="VMware系统紫屏问题定位思路"><a href="#VMware系统紫屏问题定位思路" class="headerlink" title="VMware系统紫屏问题定位思路"></a>VMware系统紫屏问题定位思路</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>Vmware EXSi主机在运行过程遇到严重错误时，会出现紫屏（类似windows系统的蓝屏），然后系统挂死。本文讲解如果定位VMware系统的紫屏问题。</p>
<h2 id="紫屏解析"><a href="#紫屏解析" class="headerlink" title="紫屏解析"></a>紫屏解析</h2><p>出现紫屏以后，根据紫屏的提示信息，可以完成问题的初步定位。从VMware 紫屏可以获取以下下的信息。</p>
<h3 id="产品和内部版本"><a href="#产品和内部版本" class="headerlink" title="产品和内部版本"></a>产品和内部版本</h3><img src="/posts/22695/zh-cn_image_0258619345.png" class="">

<p>紫色诊断屏幕中的此部分表示出错的产品和内部版本。在本示例中，产品是esxi 6.0 build号是3247720。</p>
<h3 id="错误消息"><a href="#错误消息" class="headerlink" title="错误消息"></a>错误消息</h3><img src="/posts/22695/zh-cn_image_0258619346.png" class="">

<p>紫色诊断屏幕的此部分表示报告的错误消息。指示出是什么错误导致的VMware系统紫屏，本示例中是mce问题导致的VMware系统紫屏，这个信息对定位问题非常重要。本文后面会针对常见的错误类型分别讲解。</p>
<h3 id="CPU寄存器"><a href="#CPU寄存器" class="headerlink" title="CPU寄存器"></a>CPU寄存器</h3><img src="/posts/22695/zh-cn_image_0258619381.png" class="">

<p>出错时，这些值存储在物理CPU寄存器中。这些寄存器中的信息千差万别，具体取决于出现的VMkernel错误。这些寄存器只能用于内部调试VMkernel错误的核心转储。</p>
<h3 id="物理CPU"><a href="#物理CPU" class="headerlink" title="物理CPU"></a>物理CPU</h3><img src="/posts/22695/zh-cn_image_0258619353.png" class="">

<p>紫色诊断屏幕的此部分表示VMkernel出错期间运行指令的物理CPU。</p>
<h3 id="堆栈跟踪"><a href="#堆栈跟踪" class="headerlink" title="堆栈跟踪"></a>堆栈跟踪</h3><img src="/posts/22695/zh-cn_image_0258619485.png" class="">

<p>堆栈表示出错时VMkernel正在执行的操作。此信息是一个重要工具，有助于通过评估出错时内核所执行的操作来诊断紫色屏幕错误。</p>
<h3 id="主机运行时长"><a href="#主机运行时长" class="headerlink" title="主机运行时长"></a>主机运行时长</h3><img src="/posts/22695/zh-cn_image_0258619503.png" class="">

<p>VMK uptime表示自上次启动以来服务器运行的时间。在本示例中，Esxi主机已运行了1天14时6分26秒。</p>
<h3 id="核心转储"><a href="#核心转储" class="headerlink" title="核心转储"></a>核心转储</h3><img src="/posts/22695/zh-cn_image_0258619927.png" class="">

<p>紫色诊断屏幕的此部分表示正复制到vmkcore分区的VMkernel内存内容。</p>
<h2 id="常见紫屏问题分析"><a href="#常见紫屏问题分析" class="headerlink" title="常见紫屏问题分析"></a>常见紫屏问题分析</h2><p>常见的导致VMware紫屏的错误有NMI、MCE、no heartbeat、failed to ack TLB invalidate、GP Exception(13)、PF Exception type 14等。下面一次介绍这几种常见的紫屏问题产生的原因。</p>
<h3 id="NMI"><a href="#NMI" class="headerlink" title="NMI"></a>NMI</h3><img src="/posts/22695/zh-cn_image_0258620622.png" class="">

<h4 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h4><p>服务器从V2 开始增加了故障诊断功能（fdm）。故障诊断功能使能以后，CPU检测到IIO（包括：PCI Express interfaces, DMI2 interface, IIO core logic, and Intel® VT-d）错误以后，先产生SMI中断跳转到BIOS的故障处理流程中。BIOS的故障处理流程负责记录这个Aer错误，当BIOS检测到不可恢复的Aer错误时，会产生NMI中断给OS。Vmware系统检测到这个NMI中断以后就会出现紫屏挂死，紫屏显示的错误类型为 “LINT1/NMI…” 。</p>
<p>下图IIO Modules的错误处理流程如下图所示，仅供参考。</p>
<img src="/posts/22695/zh-cn_image_0258621254.png" class="">

<h4 id="定位思路"><a href="#定位思路" class="headerlink" title="定位思路"></a>定位思路</h4><p>对于NMI导致的紫屏问题，绝大多数为PCIe设备问题导致的。出现这类问题时，优先查看fdm log中挂死时刻的错误日志，找到对应PCIe设备进行定位。</p>
<h4 id="解决措施"><a href="#解决措施" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：3108-RAID卡FW-amp-驱动问题导致VMware紫屏"><a href="#场景1：3108-RAID卡FW-amp-驱动问题导致VMware紫屏" class="headerlink" title="场景1：3108 RAID卡FW&amp;驱动问题导致VMware紫屏"></a>场景1：3108 RAID卡FW&amp;驱动问题导致VMware紫屏</h5><p><strong>硬件配置：</strong>RH5885 V3服务器，配置3108 RAID卡。</p>
<p><strong>OS****：</strong>VMware 6.0</p>
<p><strong>问题现象：</strong></p>
<ol>
<li><p>操作系统宕机，VMware紫屏，紫屏信息如图1所示。</p>
<p><strong>图1</strong> VMware紫屏信息</p>
<img src="/posts/22695/zh-cn_image_0261130308.jpg" class=""></li>
<li><p>BMC日志中有RAID卡异常打印，如图2所示。</p>
<p><strong>图2</strong> BMC日志</p>
 <img src="/posts/22695/zh-cn_image_0261130302.png" class=""></li>
<li><p>现场更换RAID卡，告警依旧。</p>
</li>
<li><p>现场升级RAID卡FW和VMware驱动后，问题解决。</p>
</li>
</ol>
<p><strong>关键过程、根本原因分析</strong></p>
<p>故障根因：OS中自带驱动版本和3108 RAID卡FW不配套，需要执行华为网站上的驱动包并按照驱动包脚本提示进行FW配套升级。详细升级方案在解决方案中给出。</p>
<p><strong>结论、解决方案及效果</strong></p>
<p>升级前请先下载软件：</p>
<p>驱动下载链接：<a target="_blank" rel="noopener" href="https://support.huawei.com/enterprise/zh/computing/fusionserver-idriver-pid-21588909/software">https://support.huawei.com/enterprise/zh/computing/fusionserver-idriver-pid-21588909/software</a></p>
<p><strong>FW****升级指导</strong></p>
<ol>
<li><p>将下载的FW镜像挂在到KVM虚拟光驱界面，服务器上电。</p>
<img src="/posts/22695/zh-cn_image_0261130328.png" class=""></li>
<li><p>按F11进入启动项，选择从虚拟光驱启动。</p>
<img src="/posts/22695/zh-cn_image_0261130325.png" class=""></li>
<li><p>选择Toolkit-V101。</p>
<img src="/posts/22695/zh-cn_image_0261130310.png" class=""></li>
<li><p>按C进入命令行模式。</p>
<img src="/posts/22695/zh-cn_image_0261130327.png" class=""></li>
<li><p>输入用户名密码。用户名为<strong>root</strong>，默认密码为**Huawei12#$**。</p>
<img src="/posts/22695/zh-cn_image_0261130312.png" class=""></li>
<li><p>执行指令**cd /home/Project/FTK/upgrade/raid/tool/**进入文件夹。执行指令 ****./FwUpgrade.py FwUpgrade.XML****，回车确定后开始升级。升级完成后，重启服务器生效。</p>
<img src="/posts/22695/zh-cn_image_0261130334.png" class=""></li>
<li><p>查看3108 RAID的FW版本，最新版本是4.270.00.4382。</p>
<img src="/posts/22695/zh-cn_image_0261130314.png" class="">

<p><em>*<em>*</em>*驱动升级指导****</em>*</p>
</li>
<li><p>将VMware系统对应的文件通过SSH等工具上传到操作系统tmp文件夹下。</p>
<img src="/posts/22695/zh-cn_image_0261130313.png" class=""></li>
<li><p>执行指令<strong>cd tmp/vmware5.5</strong>进入tmp文件夹。</p>
</li>
<li><p>执行指令<strong><em>*</em>*sh install_driver.sh**。*</strong>*</p>
</li>
<li><p>选择1，进行全部升级。</p>
</li>
<li><p>升级驱动版本至6.606.06.00。升级完成后，重启操作系统生效。</p>
</li>
</ol>
<img src="/posts/22695/zh-cn_image_0261130339.jpg" class="">

<h5 id="场景2：LSI3108-5288-V3配置3108安装VMware运行中紫屏案例"><a href="#场景2：LSI3108-5288-V3配置3108安装VMware运行中紫屏案例" class="headerlink" title="场景2：LSI3108-5288 V3配置3108安装VMware运行中紫屏案例"></a>场景2：LSI3108-5288 V3配置3108安装VMware运行中紫屏案例</h5><p><strong>问题现象描述</strong></p>
<p>硬件配置：RH5288 V3服务器，配置3108扣卡和3108标卡，并配有超级电容模块；</p>
<p>软件配置：安装VMware操作系统</p>
<p>故障现象：运行过程中出现VMware紫屏</p>
<img src="/posts/22695/zh-cn_image_0261128938.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p><strong>查看<strong><strong>RAID</strong></strong>卡日志</strong>：</p>
<p>系统日志中/raid目录下的sasraidlog.txt，显示No Controller found。</p>
<p>有可能是驱动没有安装，或者是RAID卡硬件没有运行。</p>
<p><strong>查看系统****dmesg</strong>：</p>
<p>系统日志中/system目录下的dmesg，全局搜索关键字mega，没有搜索到。</p>
<p>确认驱动没有安装。</p>
<p><strong>查看<strong><strong>lspci</strong></strong>记录</strong>：</p>
<p>系统日志/mainboard目录下的lspci，全局搜索3108, LSI等关键字，没有搜到。</p>
<p>说明3108扣卡和标卡硬件（PCIe底层）都没有运行。</p>
<p><strong>确认已连接的****RAID卡</strong> ：</p>
<p>在BMC dump_info中，在/AppDump/card_manage/card_info文件中，看到确实安装了3108标卡和扣卡。</p>
<img src="/posts/22695/zh-cn_image_0261128939.png" class="">



<img src="/posts/22695/zh-cn_image_0261128874.png" class="">

<p>说明3108标卡和扣卡硬件确实在位。</p>
<p>以上分析表明，3108扣卡和标卡的底层硬件逻辑（如PCIe）都没有运行。</p>
<p>两个卡都坏掉的可能性不大，这时建议优先从主板分析，排查硬件原因。</p>
<p><strong>结论：</strong></p>
<p>由各种日志综合分析，3108扣卡和标卡都没有运行，优先从主板开始分析，排查硬件故障原因。</p>
<p><strong>解决方案：</strong></p>
<p>排查硬件故障原因后，更换故障件。</p>
<h5 id="场景3：RH2288-V5配合VMware-6-0，在长期业务压力下导致紫屏"><a href="#场景3：RH2288-V5配合VMware-6-0，在长期业务压力下导致紫屏" class="headerlink" title="场景3：RH2288 V5配合VMware 6.0，在长期业务压力下导致紫屏"></a>场景3：RH2288 V5配合VMware 6.0，在长期业务压力下导致紫屏</h5><p><strong>问题现象描述</strong></p>
<p>2288H V5在环境上装VMware6.0，在vm下装有red7.3（数据库服务器）和suse12.2（文件服务器），这两台虚拟机是装在连接的外部的磁阵上。通过外部设备，向搭建的数据库和文件服务器长期打进业务流（TCP/IP/HTTP），发现业务持续一周之后，VMware6.0出现紫屏现象，并自己复位，bmc有CPU1和fc卡error的相关信息。</p>
<ol>
<li>2288H V5安装VMware6.0，配置相关以太、QL2672 FC标卡。</li>
<li>通过外接的磁阵，安装suse12.2（文件服务器）虚拟机、Redhat7.3（数据库服务器）虚拟机。</li>
<li>外部工具持续向虚拟机打流。</li>
<li>业务持续一周，发现host上VMware6.0紫屏，业务中断。</li>
</ol>
<img src="/posts/22695/zh-cn_image_0261129584.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p>出问题的环境QL2672 FC卡的FW版本是8.01.02，而驱动版本是qlnativefc 2.1.63.0-1OEM，但是VMware官网上版本配套关系是qlnativefc 2.1.63.0-1OEM要配套8.07.xx的版本，环境升级FW版本到8.07.xx后问题不再出现。</p>
<p><strong>结论、解决方案及效果</strong></p>
<p>Vmware环境下部件FW&amp;驱动要和官网发布的关系配套。</p>
<h3 id="MCE"><a href="#MCE" class="headerlink" title="MCE"></a>MCE</h3><img src="/posts/22695/zh-cn_image_0258621493.png" class="">

<h4 id="原因分析-1"><a href="#原因分析-1" class="headerlink" title="原因分析"></a>原因分析</h4><p>Mce 问题大家肯定都很熟悉，绝大多数的mce 问题都是硬件错误导致的。</p>
<h4 id="定位思路-1"><a href="#定位思路-1" class="headerlink" title="定位思路"></a>定位思路</h4><p>对于mce 问题触发的紫屏，紫屏信息上会提示出故障的 bank，bank 的status 状态寄存器（IA32_MCi_STATUS），MISC 寄存器（IA32_MCi_MISC），ADDR 寄存器（IA32_MCi_ADDR）。</p>
<p>示例中的故障：</p>
<p>B:19 ，表示故障bank为19</p>
<p>S：0xfe200000003110a ，表示 IA32_MC19_STATUS 为0xfe200000003110a</p>
<p>M：0x4f008b888c01086，表示 IA32_MC19_MISC 寄存器为0x4f008b888c01086</p>
<p>A：0x3551615440 ，表示 IA32_MC19_ADDR 寄存器为0x3551615440</p>
<p>在fdm 使能的情况，出现mce 导致紫屏时，fdm log 也会记录到相同的错误。如果紫屏的信息不完整时，可以结合fdm log 中故障时间端的日志记录进行定位。</p>
<h4 id="解决措施-1"><a href="#解决措施-1" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：RH5885-V3服务器内存故障导致Vmware紫屏"><a href="#场景1：RH5885-V3服务器内存故障导致Vmware紫屏" class="headerlink" title="场景1：RH5885 V3服务器内存故障导致Vmware紫屏"></a>场景1：RH5885 V3服务器内存故障导致Vmware紫屏</h5><p><strong>问题现象描述</strong></p>
<p>硬件配置：RH5885 V3服务器： E7-4850 v4*4+3108RAID卡</p>
<p>问题现象：客户反馈服务器运行过程中紫屏</p>
<img src="/posts/22695/zh-cn_image_0261656414.png" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p>关键过程：</p>
<p>1.curren日志中记录内存DIMM001 UCE错误，同时记录系统致命错误。</p>
<img src="/posts/22695/zh-cn_image_0261656413.png" class="">

<p>2.fdm_log多次记录内存DIMM001 UCE错误。</p>
<img src="/posts/22695/zh-cn_image_0261656415.png" class="">

<p>3.fdm_output中先打印内存DIMM001 CE风暴，3秒后打印内存 DIMM001 UCE。</p>
<img src="/posts/22695/zh-cn_image_0261656416.png" class="">

<p><strong>根本原因分析：</strong></p>
<p>内存DIMM001故障导致wmware系统紫屏。</p>
<p><strong>结论、解决方案及效果</strong></p>
<p>结论：内存DIMM001故障导致wmware系统紫屏。</p>
<p>解决方案：更换内存DIMM001。</p>
<h5 id="场景2：地址空间属性问题导致紫屏案例"><a href="#场景2：地址空间属性问题导致紫屏案例" class="headerlink" title="场景2：地址空间属性问题导致紫屏案例"></a>场景2：地址空间属性问题导致紫屏案例</h5><p><strong>问题现象描述</strong></p>
<p><strong>图****1</strong> 2015年12月19日至2016年2月4日，客户现场陆续出现5台RH2288H V3 VMware紫屏，系统重启后恢复</p>
<img src="/posts/22695/zh-cn_image_0261656932.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p>对于2015-12-19的VMware紫屏，我们可以确认紫屏报错类别是MCE（Machine Check Exception），紫屏时间点是2015-12-19 03:04:42（VMware时间），报错地址是0x35516154440。</p>
<img src="/posts/22695/zh-cn_image_0261656947.jpg" class="">

<p>对于2015-12-19的VMware紫屏，分析iBMC fdm log，问题发生时间点是2015-12-19 03:04:42（iBMC时间），MCE错误类型是SAD_ERR_WB_TO_MMIO错误，报错地址是0x35516154440 (FAILED TO LOCATE ADDRESS)，说明该地址是无效地址。RH2288H V3服务器所用的Intel Grantley平台配置能用的最高地址为2T+256G，0x35516154440地址属于无效地址范围。由于硬件故障仅限于有效地址的报错，无效地址报错说明不是硬件故障，而是软件错误地访问无效地址导致问题。</p>
<img src="/posts/22695/zh-cn_image_0261656948.jpg" class="">

<p><strong>结论、解决方案及效果</strong></p>
<p><strong>结论：</strong>该问题原因已确认是上层软件错误地访问无效地址。</p>
<p><strong>解决方案：</strong></p>
<ol>
<li>配合客户查明导致该问题的异常软件。</li>
<li>将无效地址默认属性设置为UC（使用BIOS V157版本），使上层软件无法错误地访问无效地址而避免触发MCE紫屏。</li>
<li>升级到兼容性列表中要求的驱动。</li>
</ol>
<h5 id="场景3：VMware紫屏问题案例"><a href="#场景3：VMware紫屏问题案例" class="headerlink" title="场景3：VMware紫屏问题案例"></a>场景3：VMware紫屏问题案例</h5><p><strong>现象、问题描述</strong></p>
<p>客户反馈一台RH5885H V3设备上部署VMware操作系统，物理机5月21日发生紫屏，需分析是否有硬件异常。</p>
<p><strong>关键过程、根本原因分析</strong></p>
<p>1.紫屏信息分析：</p>
<p>根据客户反馈的紫屏截图可以看到本次紫屏是由于MCE（Machine Check Exception）导致，设备检测到了PCPU72上有不可纠正的错误发生。其次从截图中我们可以看到本次系统启动后运行时间为427天，发生紫屏的时间为2018年5月21日9:14:41。如下图1所示。</p>
<p><strong>图****1</strong> 紫屏信息</p>
<img src="/posts/22695/zh-cn_image_0261657360.png" class="">

<p>2.Vmksummary日志分析：</p>
<p>Vmksummary日志中每隔一小时会记录一次心跳，从该日志中可以看到系统在2018-05-21T09:59:57重启，如下图2所示。</p>
<p><strong>图****2</strong> Vmksummary日志信息</p>
<img src="/posts/22695/zh-cn_image_0261657379.jpg" class="">

<p>3.SEL日志分析：</p>
<p>根据紫屏出现时间和设备重启时间来查询对应时间段内服务器BMC SEL事件记录信息，仅看到有重启前的电源线插拔lost的告警，无其他任何信息，如下图3所示。</p>
<p><strong>图****3</strong> SEL日志信息</p>
<img src="/posts/22695/zh-cn_image_0261657359.jpg" class="">

<p>4.FDM日志分析：</p>
<p>根据紫屏出现时间和设备重启时间来查询对应时间段内服务器FDM日志，发现2018-05-21 09:14:41有打印逻辑CPU2（物理CPU3）不可纠正错误，如下图4所示。</p>
<p><strong>图****4</strong> FDM日志信息</p>
<img src="/posts/22695/zh-cn_image_0261657380.png" class="">

<p>进一步确认vmkernel下查询CPU与PCPU对应关系，可看到PCPU72归属于逻辑CPU2（物理CPU3），如下图5所示。</p>
<p><strong>图****5</strong> CPU与PCPU对应关系</p>
<img src="/posts/22695/zh-cn_image_0261657381.png" class="">

<p><strong>结论、解决方案及效果</strong></p>
<p>通过以上分析可知本次紫屏是由于逻辑CPU2（物理CPU3）发生不可纠正错误导致。更换CPU后恢复。</p>
<h3 id="Failed-to-ack-TLB-invalidate"><a href="#Failed-to-ack-TLB-invalidate" class="headerlink" title="Failed to ack TLB invalidate"></a>Failed to ack TLB invalidate</h3><img src="/posts/22695/zh-cn_image_0258622057.png" class="">

<h4 id="原因分析-2"><a href="#原因分析-2" class="headerlink" title="原因分析"></a>原因分析</h4><p>什么是“TLB invalidate”？</p>
<p>我们都知道，操作系统用的虚拟地址。虚拟地址和物理地址进行转换要用到page table，但是每次内存访问的时候都遍历一遍page table，会很耗时间。为了加速page table转换，intel 设计了TLB，有了TLB 以后，CPU访问内存时，会先查找TLB buffer ，如果能查到，可以直接完成page table的转换，不需要去遍历page table 。当内核进行进程切换时，由于要装载新的page table，所以要把之前的TLB buffer invalidate。</p>
<p>TLB buffer invalidate 的过程是这样，发生进程切换的CPU把自己TLB buffer invalidate ,然后通过ipi 中断通知其他CPU也要进行TLB buffer invalidate 。CPU发送ipi 中断给其他CPU以后，会循环等待其他的CPU回复它已经完成TLB buffer invalidate。如果在等待的时间阈值内有一颗或多颗CPU未回应，EXSi 就会提示 “Failed to ack TLB invalidate”出现紫屏。</p>
<h4 id="定位思路-2"><a href="#定位思路-2" class="headerlink" title="定位思路"></a>定位思路</h4><p>导致Failed to ack TLB invalidate 原因可能是VMware 系统的问题，也可能是硬件的问题。</p>
<p>之前5885HV3上曾出现过BIOS下mwait 默认使能，CPU进入C state 以后无法唤醒是Intel CPU的一个bug ，最新的BIOS都已经合入微码解决这个问题。</p>
<p>一般遇到Failed to ack TLB invalidate”问题时，优先检查BIOS的C state ，mwait 等菜单是否已经禁用，如果禁用以后还有问题，收集vm-support 日志提case 给VMware 进行深入定位分析。</p>
<h4 id="解决措施-2"><a href="#解决措施-2" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：Mwait故障导致VMware系统紫屏问题"><a href="#场景1：Mwait故障导致VMware系统紫屏问题" class="headerlink" title="场景1：Mwait故障导致VMware系统紫屏问题"></a>场景1：Mwait故障导致VMware系统紫屏问题</h5><p><strong>问题现象描述</strong></p>
<p>Vmware系统运行过程中出现紫屏。紫屏信息显示 “Failed to ack TLB invalidate”</p>
<img src="/posts/22695/zh-cn_image_0261724540.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p>通过VMware 分析系统日志，发现紫屏时 故障CPU处于C state ，进一步排查BIOS设置，发现BIOS下 Monitor/Mwait 设置为 “Enable”。 Monitor/Mwait enable 时，CPU会进入C state 导致系统问题。</p>
<img src="/posts/22695/zh-cn_image_0261724521.png" class="">

<p><strong>结论、解决方案及效果</strong></p>
<p><strong>结论：</strong></p>
<p>Monitor/Mwait enable 时，CPU进入C state ，无法响应TLB invalidate ，导致VMware系统出现紫屏 。</p>
<p><strong>解决方案：</strong></p>
<p>升级到最新 BIOS版本，已默认把Monitor/Mwait设置为Disable 。</p>
<h5 id="场景2：【RH5885-V3】【VMware-6-0】Intel-Haswell-CPU平台（微码编号为erratum-HSX54，Mwait功能）缺陷导致ESXi6-0紫屏，BMC日志打印CatError告警，FDM日志打印MCA错误"><a href="#场景2：【RH5885-V3】【VMware-6-0】Intel-Haswell-CPU平台（微码编号为erratum-HSX54，Mwait功能）缺陷导致ESXi6-0紫屏，BMC日志打印CatError告警，FDM日志打印MCA错误" class="headerlink" title="场景2：【RH5885 V3】【VMware 6.0】Intel Haswell CPU平台（微码编号为erratum HSX54，Mwait功能）缺陷导致ESXi6.0紫屏，BMC日志打印CatError告警，FDM日志打印MCA错误"></a>场景2：【RH5885 V3】【VMware 6.0】Intel Haswell CPU平台（微码编号为erratum HSX54，Mwait功能）缺陷导致ESXi6.0紫屏，BMC日志打印CatError告警，FDM日志打印MCA错误</h5><p><strong>问题现象描述</strong></p>
<p>硬件配置：RH5885 V3服务器，配置Emulex OCe11102 CNA卡。</p>
<p>软件配置：VMware6.0</p>
<p>问题现象：操作系统宕机，VMware紫屏，紫屏信息如下：</p>
<img src="/posts/22695/zh-cn_image_0261724868.png" class="">

<p>BMC日志中有CatError告警，FDM日志中CPU1和CPU2均发生了不可修复的MCA错误：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CPU:0 (socket:CPU1)    core:0    LogType:MCA BANK4  (PCU)    MCA mode:Corrupt Data Containment</span><br><span class="line">Error type:Uncorrected Errors-Catastrophic1/Fatal    MCACODE:0x0402 (Any logged Error for the PCU) </span><br><span class="line">CPU:1 (socket:CPU2)    core:0    LogType:MCA BANK4  (PCU)    MCA mode:Corrupt Data Containment</span><br><span class="line">Error type:Uncorrected Errors-Catastrophic1/Fatal    MCACODE:0x0400 (Internal Timer Error)</span><br></pre></td></tr></table></figure>

<p><strong>关键过程、根本原因分析</strong></p>
<p>紫屏显示TLB虚拟内存快速映射模块在调用TLB invalidate功能相关函数时刷新TLB时发生CPU死锁，与BMC日志相符，当时初步判断为CPU硬件故障。但是之后去现场更换硬件以及升级V628版本的BIOS之后问题仍然出现，之后推动VMware L3服务人员和美国研发人员继续分析之后，定位出紫屏问题是Intel最新Haswell CPU平台微码的编号为erratum HSX54的缺陷引起的，属于Intel平台节能功能与VMware的兼容性问题，并且是概率性触发。而V628版本只是关闭了mwait功能(合入的补丁为patch 0x7版本)，并未合入修改该缺陷的patch 0x9 补丁，V630版本将会合入修正所有已知缺陷的patch 0x9补丁，并且为了保险起见，默认关闭了mwait功能。</p>
<p><strong>解决方案</strong></p>
<p>Haswell-EX CPU机型升级BIOS到V630版本。</p>
<p><strong>备注</strong></p>
<p>Monitor/Mwait指令介绍：</p>
<p>当在一个多处理器系统中的一个逻辑处理器（包括多核处理器或支持Intel超线程技术的处理器）处于空闲（没有工作可做）或阻塞（等待一个锁或信号量）时，核心执行引擎资源的额外的管理可以通过使用HLT（中止）、PAUSE或MONITOR/MWAIT指令来完成。</p>
<p>MONITOR指令定义一些特定的要被等待的回写地址区域，MWAIT指令用于配合MONITOR指令使用，它指定一个软件线程去等待对MONITOR指令定义的地址做出回写动作(a write-back store)。</p>
<p>除了MONITOR定义的区域的数据被写这个条件之外，以下条件也能触发MWAIT唤醒：</p>
<ul>
<li>External interrupts: NMI, SML, INIT, BINIT, MCERR</li>
<li>Faults, Aborts including Machine Check</li>
<li>Architectural TLB invalidations, including writes to CR0, CR3, CR4 and certain MSR writes</li>
<li>Voluntary transitions due to fast system call and far calls</li>
</ul>
<p>Intel官网对Monitor/Mwait功能的介绍。</p>
<p><a target="_blank" rel="noopener" href="https://software.intel.com/en-us/articles/how-to-use-the-monitor-and-mwait-streaming-simd-extensions-3-instructions">https://software.intel.com/en-us/articles/how-to-use-the-monitor-and-mwait-streaming-simd-extensions-3-instructions</a></p>
<h3 id="No-heartbeat"><a href="#No-heartbeat" class="headerlink" title="No heartbeat"></a>No heartbeat</h3><img src="/posts/22695/zh-cn_image_0258622063.png" class="">

<h4 id="原因分析-3"><a href="#原因分析-3" class="headerlink" title="原因分析"></a>原因分析</h4><p>ESX VMkernel和服务控制台 Linux内核同时在 ESX 上运行。服务控制台 Linux内核会定时向VMkernel发送心跳信号。如果一定时间内未收到心跳信号，VMkernel 会触发紫屏。</p>
<h4 id="定位思路-3"><a href="#定位思路-3" class="headerlink" title="定位思路"></a>定位思路</h4><p>导致No heartbeat的原因肯能是软件问题，也可能是硬件问题。我们曾遇到过，内存可纠正错误ECC过多，导致VMware系统紫屏。紫屏的原因就是内存ECC错误一直产生CMCI中断给VMware系统，VMware系统无法响应心跳检查，导致系统挂死。详解VMware kb：</p>
<p><a target="_blank" rel="noopener" href="http://kb.vmware.com/kb/2140848">http://kb.vmware.com/kb/2140848</a></p>
<h4 id="解决措施-3"><a href="#解决措施-3" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：VMware-6-5跑虚拟机NVME硬盘压力出现紫屏问题"><a href="#场景1：VMware-6-5跑虚拟机NVME硬盘压力出现紫屏问题" class="headerlink" title="场景1：VMware 6.5跑虚拟机NVME硬盘压力出现紫屏问题"></a>场景1：VMware 6.5跑虚拟机NVME硬盘压力出现紫屏问题</h5><p><strong>现象、问题描述</strong></p>
<p>Vmware 6.5系统运行NVMe硬盘压力过程中出现紫屏。紫屏信息显示 “no heartbeat”。</p>
<img src="/posts/22695/zh-cn_image_0261729306.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p>Vmware 6.5系统bug</p>
<p><a target="_blank" rel="noopener" href="https://kb.vmware.com/s/article/2151597#q=2151597">https://kb.vmware.com/s/article/2151597#q=2151597</a></p>
<img src="/posts/22695/zh-cn_image_0261729307.jpg" class="">

<p><strong>结论、解决方案及效果</strong></p>
<p><strong>结论：</strong></p>
<p>Vmware 6.5系统bug导致紫屏。</p>
<p><strong>解决方案：</strong></p>
<p>升级系统版本到6.5U1版本。</p>
<h5 id="场景2：Esxi-6-0U2-lsi-mr3驱动导致紫屏"><a href="#场景2：Esxi-6-0U2-lsi-mr3驱动导致紫屏" class="headerlink" title="场景2：Esxi_6.0U2_lsi_mr3驱动导致紫屏"></a>场景2：Esxi_6.0U2_lsi_mr3驱动导致紫屏</h5><p><strong>问题现象描述</strong></p>
<p>RH5885H V3服务器配置LSI 3108卡，运行Esxi 6.0U2过程中出现紫屏（如图1所示），RAID卡驱动使用OS自带的lsi_mr3，非华为发布的megaraid_sas。</p>
<p><strong>图****1</strong> Esxi紫屏</p>
<img src="/posts/22695/zh-cn_image_0261735763.png" class="">

<p><strong>图****2</strong> lsi_mr3驱动信息</p>
<img src="/posts/22695/zh-cn_image_0261735713.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p><strong>根本原因分析：</strong></p>
<p>Esxi自带的lsi_mr3驱动程序从低内存区域初始引导期间不会保留所需的完整内存，导致RAID卡运行过程中出现异常。</p>
<p><strong>图****3</strong> VMWare分析结果</p>
<img src="/posts/22695/zh-cn_image_0261735762.jpg" class="">

<p><strong>结论、解决方案及效果</strong></p>
<p><strong>结论：</strong></p>
<p>Esxi自带的lsi_mr3驱动程序从低内存区域初始引导期间不会保留所需的完整内存，导致RAID卡运行过程中出现异常。</p>
<p><strong>解决方案：</strong></p>
<p>参考VMWare分析结果，该问题有两种方案，选择其一解决即可。</p>
<p>1、升级主机OS版本至ESXi 6.0 P04。</p>
<p>2、如果主机OS版本无法升级，可以安装传统驱动程序（如megaraid sas）而不使用本地驱动程序（如lsi_mr3）。建议使用华为发布的megaraid_sas驱动。</p>
<h5 id="场景3：RH2288-V3服务器VMware系统紫屏问题"><a href="#场景3：RH2288-V3服务器VMware系统紫屏问题" class="headerlink" title="场景3：RH2288 V3服务器VMware系统紫屏问题"></a>场景3：RH2288 V3服务器VMware系统紫屏问题</h5><p><strong>问题现象描述</strong></p>
<p>硬件配置：RH2288 V3，CPU型号Xeon E5-2640 V3</p>
<p>问题现象：VMware系统频繁重启，没有硬件告警，紫屏</p>
<p><strong>关键过程、根本原因分析</strong></p>
<p>关键过程：</p>
<ol>
<li>BMC版本2.41，BIOS版本3.57</li>
</ol>
<img src="/posts/22695/zh-cn_image_0261735888.jpg" class="">

<ol start="2">
<li>sel日志看到12月30日9:47分带内业务侧power off，没有硬件告警，前后几次上下电是人为操作按下power button的打印</li>
</ol>
<img src="/posts/22695/zh-cn_image_0261735889.jpg" class="">

<ol start="3">
<li>operate日志看到09:47的下电前无人为操作按power button的记录，判断为系统侧异常下电</li>
</ol>
<img src="/posts/22695/zh-cn_image_0261735823.jpg" class="">

<ol start="4">
<li>fdm日志没有有效信息，仅几次2019年1月9日的内存CE告警，指向DIMM001</li>
</ol>
<img src="/posts/22695/zh-cn_image_0261735890.png" class="">

<ol start="5">
<li>vmsummary日志看到有core dump文件生成</li>
</ol>
<img src="/posts/22695/zh-cn_image_0261735824.jpg" class="">

<ol start="6">
<li>vmwarning日志中有PCPU 21无心跳响应8秒，可能locked up的打印，且有NMI IPI received打印</li>
</ol>
<img src="/posts/22695/zh-cn_image_0261735905.jpg" class="">

<ol start="7">
<li>紫屏打印是no heartbeat，时间去年12月30日8:50，OS比BMC时间多8小时，即硬件时间2019-12-30 0:50</li>
</ol>
<img src="/posts/22695/zh-cn_image_0261735906.jpg" class="">

<img src="/posts/22695/zh-cn_image_0261735907.jpg" class="">

<p><strong>根本原因分析：</strong></p>
<p>PCPU 21无心跳响应8秒，可能locked up的打印，且有NMI IPI received打印，导致系统紫屏。</p>
<p>结论：</p>
<p>PCPU 21逻辑核所在物理CPU2故障。</p>
<p>解决方案：</p>
<p>更换CPU2。</p>
<h5 id="场景4：MZ510-FC驱动和FW不匹配导致VMware紫屏"><a href="#场景4：MZ510-FC驱动和FW不匹配导致VMware紫屏" class="headerlink" title="场景4：MZ510 FC驱动和FW不匹配导致VMware紫屏"></a>场景4：MZ510 FC驱动和FW不匹配导致VMware紫屏</h5><p><strong>问题现象描述</strong></p>
<p><strong>硬件配置：</strong></p>
<p>2x E5-2603 CPU，16x8G，LSI2308 RAID卡、MZ510扣卡。</p>
<p><strong>软件配置：</strong></p>
<p>MZ510扣卡驱动: 8.2.3.1-127vmw；FW: 4.4.262.3 OS:VMware5.1</p>
<p><strong>问题描述：</strong></p>
<p>客户在CH121服务器上安装VMware5.1系统后，概率性出现紫屏。如图1所示。</p>
<p><strong>图****1</strong> VMware系统紫屏</p>
<img src="/posts/22695/zh-cn_image_0261736931.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p><strong>定位步骤如下：</strong></p>
<ol>
<li>分析VMware日志，确认是MZ510扣卡FC驱动和FW不匹配导致紫屏。如图2所示。</li>
</ol>
<p><strong>图****2</strong> VMware日志分析</p>
<img src="/posts/22695/zh-cn_image_0261736932.jpg" class="">

<p>请参考此KB：<a target="_blank" rel="noopener" href="http://kb.vmware.com/kb/2052729%E3%80%82">http://kb.vmware.com/kb/2052729。</a></p>
<p><strong>根本原因分析**</strong>:**</p>
<p>现场使用的MZ510扣卡FC驱动和FW不匹配会概率性出现紫屏，且不是经过华为兼容性测试的配套版本。</p>
<p><strong>结论、解决方案**</strong>:**</p>
<p>结论：</p>
<p>MZ510扣卡FC驱动和FW不匹配</p>
<p>解决方案：</p>
<p>参考E9000服务器驱动版本配套表，升级MZ510扣卡FC的驱动版本8.2.4.151.65，FW：4.6.320.3。</p>
<h3 id="PF-Exception-14-amp-GP-Exception-13"><a href="#PF-Exception-14-amp-GP-Exception-13" class="headerlink" title="PF Exception 14 &amp; GP Exception 13"></a>PF Exception 14 &amp; GP Exception 13</h3><img src="/posts/22695/zh-cn_image_0258622940.png" class="">

<h4 id="原因分析-4"><a href="#原因分析-4" class="headerlink" title="原因分析"></a>原因分析</h4><p>PF Exception 14 ，产生的原因：</p>
<ul>
<li>正在请求的页面未成功加载到内存时出现页面错</li>
</ul>
<p>GP Exception 13，在以下任一情况下都会出现一般保护错误。</p>
<ul>
<li>正在请求的页面不属于请求该页的程序（未映射到程序内存中）</li>
<li>程序无权在页面上执行读取或写入操作。</li>
</ul>
<h4 id="定位思路-4"><a href="#定位思路-4" class="headerlink" title="定位思路"></a>定位思路</h4><p>GP Exception 13或者PF Exception 14，一般都是软件导致的紫屏，跟服务器没有关系，这类问题直接找VMware 创建case分析即可。</p>
<p>示例是我们曾经遇到VMware系统驱动bug 导致的PF Exception 14问题。参考如下的kb：</p>
<p><a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2052368">https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2052368</a></p>
<h4 id="解决措施-4"><a href="#解决措施-4" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：VMware系统自带2208驱动紫屏问题"><a href="#场景1：VMware系统自带2208驱动紫屏问题" class="headerlink" title="场景1：VMware系统自带2208驱动紫屏问题"></a>场景1：VMware系统自带2208驱动紫屏问题</h5><p><strong>问题现象描述</strong></p>
<p>Vmware系统运行过程中出现紫屏。紫屏信息显示 “PF Exception 14 in xxx”</p>
<img src="/posts/22695/zh-cn_image_0261740943.png" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p>Vmware 5.x系统bug 导致2208 卡在复位过程中出现紫屏无响应。</p>
<p><a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2052368">https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2052368</a></p>
<p><strong>结论、解决方案及效果</strong></p>
<p><strong>结论：</strong></p>
<p>Vmware 系统自带2208驱动驱动bug 导致紫屏。</p>
<p><strong>解决方案：</strong></p>
<p>升级最新的iDriver驱动。</p>
<h5 id="场景2：CH121-V3服务器EXSi紫屏问题"><a href="#场景2：CH121-V3服务器EXSi紫屏问题" class="headerlink" title="场景2：CH121 V3服务器EXSi紫屏问题"></a>场景2：CH121 V3服务器EXSi紫屏问题</h5><p><strong>问题现象描述</strong></p>
<p>3台CH121 V3服务器ESXi 6.5出现紫屏，现象如下：</p>
<img src="/posts/22695/zh-cn_image_0261742568.jpg" class="">

<p>VMware版本信息为：</p>
<img src="/posts/22695/zh-cn_image_0261742569.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p>分析BMC SEL日志，在ESXi主机出现紫屏时硬件没有异常：</p>
<img src="/posts/22695/zh-cn_image_0261742551.jpg" class="">

<p>FDM日志也没有检测到硬件有异常：</p>
<img src="/posts/22695/zh-cn_image_0261742570.jpg" class="">

<p>分析VMware日志发下在出现紫屏时出现以下异常：</p>
<img src="/posts/22695/zh-cn_image_0261742552.jpg" class="">

<p><strong>结论、解决方案及效果</strong></p>
<p>联合VMware定位，该问题是由于EXSi 6.5 U2内核存在BUG导致紫屏，参考如下KB：</p>
<p><a target="_blank" rel="noopener" href="https://kb.vmware.com/s/article/56492">https://kb.vmware.com/s/article/56492</a></p>
<h5 id="场景3：VMware-5-5自带MZ910网卡驱动bug导致紫屏"><a href="#场景3：VMware-5-5自带MZ910网卡驱动bug导致紫屏" class="headerlink" title="场景3：VMware 5.5自带MZ910网卡驱动bug导致紫屏"></a>场景3：VMware 5.5自带MZ910网卡驱动bug导致紫屏</h5><p><strong>问题现象描述</strong></p>
<p>硬件配置：E9000 CH配置MZ910</p>
<p>软件配置：VMware 5.5</p>
<p>问题描述：VMware5.5出现紫屏。如图1所示。</p>
<p><strong>图****1</strong> VMware 5.5紫屏</p>
<img src="/posts/22695/zh-cn_image_0261742625.png" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p><strong>关键过程：</strong></p>
<p>联系VMware厂家分析VMware和Coredump文件。</p>
<p>紫屏是由VMware5.5系统自带MZ910驱动（驱动版本：4.6.100.0v）所导致的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vmnic0 be2net 10df:e220 10df:e264 4.6.100.0v 1.1.43.24 </span><br><span class="line">vmnic1 be2net 10df:e220 10df:e264 4.6.100.0v 1.1.43.24 </span><br><span class="line">vmnic2 be2net 10df:e220 10df:e264 4.6.100.0v 1.1.43.24 </span><br><span class="line">vmnic3 be2net 10df:e220 10df:e264 4.6.100.0v 1.1.43.24 </span><br><span class="line">#0 0x0000418015c8e218 in be_cq_create_v2 (pfob=0x410ae8948218, rd=, length=, solicited_eventable=, no_delay=, cqe_dma_coalescing=, eq_object=0x120, cq_object=0x410ae8948778) at vmkdrivers/src_9/private_drivers/ServerEngines/be2net/hwlib/cq.c:269 #1 0x0000418015c796de in be_mcc_create (adapter=0x410ae89481c0) at vmkdrivers/src_9/private_drivers/ServerEngines/be2net/be_init.c:2523 #2 mcc_setup (adapter=0x410ae89481c0) at vmkdrivers/src_9/private_drivers/ServerEngines/be2net/be_init.c:2908 #3 0x0000418015c7d41c in pf_reset (adapter=0x410ae89481c0, tx_timeo_ctxt=8 &#x27;b&#x27;) at vmkdrivers/src_9/private_drivers/ServerEngines/be2net/be_init.c:3989 #4 0x0000418015ae5516 in vmklnx_workqueue_callout (data=) at vmkdrivers/src_92/vmklinux_92/vmware/linux_workqueue.c:696 #5 0x000041801546165a in helpFunc (data=) at bora/vmkernel/main/helper.c:3251 #6 0x0000418015653532 in CpuSched_StartWorld (destWorld=, previous=) at bora/vmkernel/sched/cpusched.c:10052 #7 0x0000000000000000 in ?? ()</span><br></pre></td></tr></table></figure>

<p>在宕机前，vmnic0产生如下消息:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2014-07-02T15:29:12.477Z cpu12:33361)VMK_PCI: 720: device 0000:02:00.0 allocated 8 interrupts (intrType 3) 2014-07-02T15:29:12.477Z cpu12:33361)MSIX enabled for dev 0000:02:00.0 2014-07-02T15:29:12.480Z cpu12:33361)TX queue creation failed 2014-07-02T15:29:12.480Z cpu12:33361)Rings creation of ring set 2 failed 2014-07-02T15:29:12.483Z cpu12:33361)pf_reset: ring_sets_setup Failed 2014-07-02T15:29:12.483Z cpu12:33361)World: 8773: PRDA 0x418043000000 ss 0x0 ds 0x10b es 0x10b fs 0x10b gs 0x0 2014-07-02T15:29:12.483Z cpu12:33361)World: 8775: TR 0x4020 GDT 0x4123c9461000 (0x402f) IDT 0x4180154f3000 (0xfff) 2014-07-02T15:29:12.483Z cpu12:33361)World: 8776: CR0 0x80010031 CR3 0x1686a54000 CR4 0x42768</span><br></pre></td></tr></table></figure>

<p><strong>根本原因分析：</strong></p>
<p>VMware5.5系统自带MZ910驱动（驱动版本：4.6.100.0v）导致紫屏。</p>
<p><strong>结论、解决方案及效果</strong></p>
<p><strong>定位结论：</strong></p>
<p>VMware5.5系统自带MZ910驱动（驱动版本：4.6.100.0v）导致紫屏。</p>
<p><strong>解决方案：</strong></p>
<ol>
<li><p>下载VMware5.5驱动和MZ910的firmware，请参考《华为服务器操作系统安装指南》安装</p>
</li>
<li><p>通过虚拟光驱挂载MZ910的firmware。</p>
</li>
<li><p>在VMware系统下升级驱动。</p>
</li>
<li><p>把VMware5.5的驱动上传到VMware5.5系统某个目录。</p>
</li>
<li><p>在此目录下执行sh install.sh命令安装驱动。</p>
</li>
<li><p>选择1自动全部安装。</p>
</li>
<li><p>升级完成驱动后，重启VMware系统，然后按F11选择虚拟光驱启动，详细请参考指导书升级MZ910的firmware。</p>
</li>
<li><p>MZ910的firmware升级完成后，按照提示重启进入VMware系统，执行如下三条命令确认版本。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">esxcli software vib list |grep lpfc</span><br><span class="line">esxcli software vib list |grep elxnet</span><br><span class="line">esxcli network nic get -n vmnicx (x表示网卡序号)</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="场景4：2288H-V5服务器VMware系统出现紫屏"><a href="#场景4：2288H-V5服务器VMware系统出现紫屏" class="headerlink" title="场景4：2288H V5服务器VMware系统出现紫屏"></a>场景4：2288H V5服务器VMware系统出现紫屏</h5><p><strong>问题现象描述</strong></p>
<p>硬件配置：2288H V5服务器+SM212网卡</p>
<p>问题现象：客户升级SM212网卡1.4.7版本驱动后，运行过程中出现紫屏问题</p>
<p><strong>关键过程、根本原因分析</strong></p>
<p>关键过程：</p>
<p>1、查看BMC日志，未发现硬件故障；</p>
<p>2、查看VMware官方论坛，找到同样紫屏打印的KB案例</p>
<p>客户服务器紫屏打印：</p>
<img src="/posts/22695/zh-cn_image_0261745792.png" class="">

<p>VMware官方论坛紫屏KB案例打印</p>
<img src="/posts/22695/zh-cn_image_0261745793.png" class="">

<p>3、对比call trace的函数和偏移量均完全匹配，说明代码调用逻辑完全一样</p>
<p><strong>根本原因分析：</strong></p>
<p>驱动版本和VMware系统不兼容</p>
<p><strong>结论、解决方案及效果</strong></p>
<p>结论：SM212网卡驱动版本和VMware系统不兼容，导致紫屏</p>
<p>解决方案：升级网卡驱动至1.4.10最新版本</p>
<h5 id="场景5：MZ910驱动不配套导致紫屏"><a href="#场景5：MZ910驱动不配套导致紫屏" class="headerlink" title="场景5：MZ910驱动不配套导致紫屏"></a>场景5：MZ910驱动不配套导致紫屏</h5><p><strong>问题现象描述</strong></p>
<p>E9000服务器安装MZ910网卡安装VMware5.5系统，并使用系统自带网卡驱动，然后跑网络压力，会概率性出现系统紫屏，如下图所示：</p>
<p>Vmawre5.5下紫屏</p>
<img src="/posts/22695/zh-cn_image_0261745843.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<ol>
<li>使用MZ910网卡在CH121刀片上安装VMware5.5系统，并使用系统自带MZ910网卡驱动，然后跑网络压力，很大概率性出现紫屏。</li>
<li>重启该套环境，进入系统后卸载掉系统自带驱动，并安装发布配套的驱动，再跑网络压力三天，未出现紫屏现象。</li>
<li>因此基本确认紫屏是由于系统自带MZ910驱动导致。</li>
<li>将出现紫屏的系统dump系统以及OS内日志反馈给供应商，供应商反馈原因是由于系统自带MZ910网卡驱动导致，建议卸载系统自带MZ910网卡驱动，并升级至配套版本。</li>
</ol>
<p><strong>结论、解决方案及效果</strong></p>
<p><strong>结论：</strong></p>
<p>系统自带MZ910网卡驱动导致系统紫屏，需要卸载系统自带驱动，并升级到华为官网发布的FW&amp;驱动。</p>
<p><strong>解决方案：</strong></p>
<p>在Vmware5.5系统下卸载MZ910 系统自带vmklnux driver，包括lpfc存储和be2net以太驱动。</p>
<p>esxcli software vib remove -n net-be2net</p>
<p>esxcli software vib remove -n scsi-lpfc820</p>
<p>然后在华为官网下载查看驱动配套表，并升级FW和安装驱动，重启生效。以当前发布的VMware5.5下配套关系为例：</p>
<p>MZ910 FW:10.2.590.0</p>
<p>elxnet：10.2.590.0</p>
<p>lpfc: 10.2.455.0</p>
<h5 id="场景6：MZ910网卡三次闪断问题"><a href="#场景6：MZ910网卡三次闪断问题" class="headerlink" title="场景6：MZ910网卡三次闪断问题"></a>场景6：MZ910网卡三次闪断问题</h5><p><strong>问题现象描述</strong></p>
<p>（一） 第一次闪断问题</p>
<p>1、问题回顾：</p>
<p>7月24日~8月3日，客户现网CH242 V3刀片运行ESXi操作系统，上层运行虚拟机。13个刀片不同时间发生网络瞬断问题，3个刀片出现紫屏宕机。</p>
<p>2、现象分析：</p>
<ol>
<li><p>瞬断现象：网络瞬断的过程中，网卡驱动能检查到FW产生dump，并上报ERR错误<img src="/posts/22695/zh-cn_image_0261746880.jpg" class=""></p>
</li>
<li><p>紫屏现象：在网卡瞬断的过程中，大概率出现紫屏现象，紫屏现象如下图所示。</p>
<img src="/posts/22695/zh-cn_image_0261746881.png" class=""></li>
</ol>
<p>3、根因分析：</p>
<p>网卡FW缺陷导致TX 方向的报文出现阻塞，之后网卡重启自愈，并出现闪断的现象。</p>
<p>4、网卡原厂报告：</p>
<img src="/posts/22695/zh-cn_image_0261746882.jpg" class="">

<p>（二） 第二次闪断问题</p>
<p>1、问题回顾</p>
<p>8月10日~9月6日，在FW升级到11.1.245.5版本之后，客户现网再次出现网络瞬断与紫屏问题。</p>
<p>2、现象分析：</p>
<ol>
<li><p>瞬断现象：网络瞬断的过程中，网卡驱动同样检查到FW产生dump，并上报ERR错误。(由于出现瞬断时，网卡驱动的打印相似，这里不再描述)</p>
</li>
<li><p>紫屏现象：在网卡瞬断的过程中，小概率出现紫屏现象，紫屏现象如下图所示。</p>
<img src="/posts/22695/zh-cn_image_0261746883.jpg" class=""></li>
<li><p>根因分析：</p>
</li>
<li><p>网卡FW缺陷导致处理队列(HQPE)出现死锁，之后网卡重启自愈，并出现闪断的现象。</p>
</li>
<li><p>对比前两次网卡闪断的堆栈信息：第二次网卡紫屏后的堆栈明显不同于第一次，也从侧面说明两次问题的触发点与根因也不同。</p>
</li>
</ol>
<p>根因分析报告：</p>
<img src="/posts/22695/zh-cn_image_0261746884.png" class="">

<p>解决措施说明<strong>：</strong></p>
<img src="/posts/22695/zh-cn_image_0261746885.png" class="">

<p>瞬断现象：网络瞬断的过程中，网卡驱动同样检查到FW产生dump，并上报ERR错误。(出现瞬断时，网卡驱动的打印相似)</p>
<img src="/posts/22695/zh-cn_image_0261746859.jpg" class="">

<p>紫屏现象：暂没有出现紫屏现象。</p>
<p><strong>关键过程、根本原因分析</strong></p>
<p>网卡三次闪断时的现象相似，但根因却不同。经初步分析认为：当网卡运行在客户新业务的流量场景下，并强制在GE的速率配置时，会大概率触发网卡FW缺陷，导致网卡闪断。</p>
<h5 id="场景7：VMware主机紫屏异常问题"><a href="#场景7：VMware主机紫屏异常问题" class="headerlink" title="场景7：VMware主机紫屏异常问题"></a>场景7：VMware主机紫屏异常问题</h5><p><strong>问题现象描述</strong></p>
<p>硬件配置：E9000机框+16<em>CH121 V3 +2</em> CX311+MZ512.</p>
<p>驱动版本信息如下：</p>
<p>Firmware Version: 11.1.240.0</p>
<p>Driver Version: lpfc/11.1.145.18-1OEM.600.0.0.2768847</p>
<p>组网配置如下：</p>
<img src="/posts/22695/zh-cn_image_0261747896.png" class="">

<p><strong>问题现象：</strong></p>
<img src="/posts/22695/zh-cn_image_0261747927.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p>三个紫屏的 stack trace 是相同的：</p>
<p>VMware官方KB： <a target="_blank" rel="noopener" href="https://kb.vmware.com/s/article/2151391">https://kb.vmware.com/s/article/2151391</a></p>
<p>由 lpfc driver 的问题导致，解决方法是 “Upgrade brcmfcoe driver to 11.2.1153.13 and lpfc driver to 11.2.156.20 or newer”</p>
<p><strong>结论、解决方案及效果</strong></p>
<p>There is same issue on ESXi6.5, please update to 11.2.156.20 or above your OS is ESXi6.0 and 6.5.</p>
<p>Issue happens when there are error frames on the line, and in FC SAN, usually the link is clean and you will not see the issue very frequently。</p>
<h5 id="场景8：2288H-V5-CPU故障导致Vmware紫屏PSOD"><a href="#场景8：2288H-V5-CPU故障导致Vmware紫屏PSOD" class="headerlink" title="场景8：2288H V5 CPU故障导致Vmware紫屏PSOD"></a>场景8：2288H V5 CPU故障导致Vmware紫屏PSOD</h5><p><strong>问题现象描述</strong></p>
<p>硬件配置：RH 2288HV5</p>
<p>问题现象：荷兰某局点2288H V5服务器，虚拟机在迁移过程中，发生紫屏PSOD</p>
<p><strong>关键过程、根本原因分析</strong></p>
<p>关键过程：</p>
<p>基于BMC日志分析，硬件无异常，fdm诊断日志无异常</p>
<img src="/posts/22695/zh-cn_image_0261747988.png" class=""><img src="/posts/22695/zh-cn_image_0261748748.png" class="">

<p>OS日志分析</p>
<img src="/posts/22695/zh-cn_image_0261748749.png" class="">

<p>Vmware厂商分析</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">All the PSOD instances are referring hardware related issues. PSOD is always seen on CPU 32.</span><br><span class="line">Panic Details: Crash at 2019-02-08T11:54:28.085Z on CPU 32 running world 66483. VMK Uptime:0:00:01:23.077</span><br><span class="line">Panic Details: Crash at 2019-02-08T12:06:25.189Z on CPU 32 running world 67007. VMK Uptime:0:00:01:59.485</span><br><span class="line">Panic Details: Crash at 2019-02-12T08:05:58.130Z on CPU 32 running world 65568. VMK Uptime:0:00:01:36.781</span><br><span class="line">Panic Details: Crash at 2019-02-14T13:53:33.024Z on CPU 32 running world 67077. VMK Uptime:0:00:01:25.644</span><br><span class="line">Panic Details: Crash at 2019-02-19T12:42:55.571Z on CPU 32 running world 71368. VMK Uptime:0:03:48:01.755</span><br><span class="line">Panic Details: Crash at 2019-02-20T11:43:12.443Z on CPU 32 running world 65682. VMK Uptime:0:00:51:15.911</span><br><span class="line">Panic Details: Crash at 2019-02-21T13:29:33.365Z on CPU 32 running world 69634. VMK Uptime:0:00:17:53.863</span><br><span class="line">CPU global information &#123;</span><br><span class="line">Hyperthreading state:Hyperthreading state: 3 -&gt; enabled</span><br><span class="line">HV state:HV state: 3 -&gt; HV Enabled</span><br><span class="line">Number of packages:2</span><br><span class="line">Number of cores:24</span><br><span class="line">Number of CPUs (threads):48</span><br><span class="line">Number of licensable cores:24</span><br><span class="line">SLC64 capable:0</span><br><span class="line">HV Replay capable:0</span><br><span class="line">&#125;</span><br><span class="line">Core:16</span><br><span class="line">Package:1</span><br><span class="line">Node:1</span><br><span class="line">Number of microcode updates:0</span><br><span class="line">Kindly engage hardware vendor and perform extensive diagnostic test on CPU. Core 16 (package 1) has some issues.</span><br><span class="line">Also try limiting the CPU to use the package 12 via CLI VMkernel.Boot.maxPCPUS=12. This shall avoid ESXi to use secondary package and we do not expect another crash. If so, post the said changes made, I shall take it further with VMware Engineering team for further investigation.</span><br><span class="line">I also did notice about BIOS of the said physical hardware isn&#x27;t compatible. Considering this to be a latest version, request you to receive acknowledge from hardware vendor about its compatibility and no known issues with reference to its room for kernel crash.</span><br></pre></td></tr></table></figure>

<p><strong>根本原因分析</strong>：</p>
<p>CPU故障导致VmwarePSOD</p>
<p><strong>结论、解决方案及效果</strong></p>
<p>结论：</p>
<p>CPU 16核和32核硬件故障导致Vmware发生紫屏PSOD现象</p>
<p>解决方案：</p>
<p>更换两个CPU，故障解决。</p>
<h5 id="场景9：RH2288H-V3使用ESXi-6-5-U2操作系统，加入vsan集群后出现紫屏"><a href="#场景9：RH2288H-V3使用ESXi-6-5-U2操作系统，加入vsan集群后出现紫屏" class="headerlink" title="场景9：RH2288H V3使用ESXi 6.5 U2操作系统，加入vsan集群后出现紫屏"></a>场景9：RH2288H V3使用ESXi 6.5 U2操作系统，加入vsan集群后出现紫屏</h5><p><strong>问题现象描述</strong></p>
<p>硬件配置：RH2288H V3</p>
<p>问题现象：RH2288H V3使用Esxi 6.5 U2操作系统，加入vsan集群后出现紫屏告警</p>
<p><strong>关键过程、根本原因分析</strong></p>
<p>关键过程：</p>
<p>1、紫屏代码：GP Exception 13所以初步判断是软件导致的紫屏</p>
<img src="/posts/22695/zh-cn_image_0261750602.png" class="">

<p>2、VMware工程师分析如下，判断是硬件问题导致</p>
<img src="/posts/22695/zh-cn_image_0261750978.png" class="">

<p>3、针对上述分析结果，进行了进一步测试，分别使用FTK压测各个部件均没有发现异常</p>
<p>4、交叉CPU测试，加入集群，发现BMC始终有CPU1告警（VTD 97类型告警，非硬件原因）</p>
<p>5、由于告警没有跟随CPU走，所以判断是主板原因，进行主板更换后，问题仍未解决。</p>
<p>6、经过了解，现场使用的ESXI6.5 U2的系统是通过ESXI 6.0 U3升级而来，怀疑是系统残留数据导致的不兼容，现场重装系统后问题未再复现。</p>
<p><strong>根本原因分析</strong>：</p>
<p>系统升级后，有残留文件导致存在导致集群内系统存在兼容性问题。</p>
<p><strong>结论、解决方案及效果</strong></p>
<p>结论：</p>
<p>系统升级后，有残留文件导致存在导致集群内系统存在兼容性问题。</p>
<p>解决方案：</p>
<p>重装操作系统。</p>
<h5 id="场景10：ESXi-5-5-x取消存储映射后可能触发紫屏"><a href="#场景10：ESXi-5-5-x取消存储映射后可能触发紫屏" class="headerlink" title="场景10：ESXi 5.5.x取消存储映射后可能触发紫屏"></a>场景10：ESXi 5.5.x取消存储映射后可能触发紫屏</h5><p><strong>问题现象</strong>：</p>
<p>你会看到类似的紫屏信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">2016-01-23T00:10:50.992Z cpu62:33922)WARNING: iodm: vmk_IodmEvent:193: vmhba2: FRAME DROP event has been observed 6 times in the last one minute. This suggests a problem with Fibre Channel link/switch!.</span><br><span class="line">2016-01-23T00:10:50.997Z cpu37:33222)WARNING: iodm: vmk_IodmEvent:193: vmhba1: FRAME DROP event has been observed 6 times in the last one minute. This suggests a problem with Fibre Channel link/switch!.</span><br><span class="line">2016-01-23T00:10:51.187Z cpu37:33215)World: 8777: PRDA 0x418049400000 ss 0x0 ds 0x4018 es 0x4018 fs 0x4018 gs 0x4018</span><br><span class="line">2016-01-23T00:10:51.187Z cpu37:33215)World: 8779: TR 0x4020 GDT 0x412546fe1000 (0x402f) IDT 0x418017ef4000 (0xfff)</span><br><span class="line">2016-01-23T00:10:51.187Z cpu37:33215)World: 8780: CR0 0x8001003d CR3 0x7abce000 CR4 0x216c</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)Backtrace for current CPU #37, worldID=33215, ebp=0x412546fdd120</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd120:[0x4180184becc9]vmk_IodmEvent@com.vmware.vmkapi#v2_2_0_0+0x89 stack: 0x412546fdd180,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd210:[0x4180185d8e2b]lpfc_handle_fcp_err@#+0xbb7 stack: 0x4125000000c4, 0x418</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd360:[0x4180185d97fe]lpfc_scsi_cmd_iocb_cmpl@#+0x9c2 stack: 0x410ceeb41500, 0</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd520:[0x4180185df0fb]lpfc_sli4_fcp_process_wcqe@#+0xbb stack: 0x412546fdd5b0,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd590:[0x4180185e64e8]lpfc_sli4_fcp_handle_wcqe@#+0x108 stack: 0x412546fdd600,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd660:[0x4180185f68d0]lpfc_sli4_handle_eqe@#+0x7b4 stack: 0x410a571c1ae0, 0x41</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd690:[0x4180185f7065]lpfc_sli4_intr_bh_handler@#+0x89 stack: 0x410a571c1360,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd720:[0x418017e6abe7]IRQBH@vmkernel#nover+0x2e7 stack: 0x412546fdd7e0, 0x2, 0x10000000000</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd7b0:[0x418017e2e9ff]BH_DrainAndDisableInterrupts@vmkernel#nover+0xf3 stack: 0x3, 0x41804</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd7f0:[0x418017e64277]IDT_IntrHandler@vmkernel#nover+0x1af stack: 0x412546fdd910, 0x418018</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd800:[0x418017ef2064]gate_entry@vmkernel#nover+0x64 stack: 0x4018, 0x4018, 0x0, 0x0, 0x0</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd910:[0x4180181a7b7a]Power_HaltPCPU@vmkernel#nover+0x1fe stack: 0xaa1da00, 0x4100355cc000</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd980:[0x418018051e61]CpuSchedIdleLoopInt@vmkernel#nover+0x4c5 stack: 0x2546fdda20, 0x410a</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddae0:[0x418018057f30]CpuSchedDispatch@vmkernel#nover+0x1630 stack: 0x412546fddb50, 0x25e6</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddb50:[0x418018059275]CpuSchedWait@vmkernel#nover+0x245 stack: 0x1, 0x412546fddb80, 0x6874</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddbb0:[0x418018059a47]CpuSched_SleepUntilTC@vmkernel#nover+0xfb stack: 0x1, 0x3200000000,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddbe0:[0x41801815574a]SCSI_DelayOnTransientFailure@vmkernel#nover+0x5e stack: 0x2000000000</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddc50:[0x4180181456f1]SCSISyncPathCmdWithRetriesInt@vmkernel#nover+0xd9 stack: 0x200, 0x41</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddca0:[0x418018145794]vmk_ScsiIssueSyncPathCommandWithRetries@vmkernel#nover+0x4c stack: 0</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddcf0:[0x418018aee265]satp_lib_cx_sendAAQ@com.vmware.satp_lib_cx#0+0x99 stack: 0x4180187a5</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddd60:[0x418018aee3c1]satp_lib_cx_checkNaviReg@com.vmware.satp_lib_cx#0+0xa1 stack: 0x4100</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddda0:[0x418018af19f1]satp_inv_prepareInternalNaviReg@#+0x2d stack: 0x412546fd</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdde20:[0x418018aefa47]satp_inv_updatePathStates@#+0x1f3 stack: 0x412546fddeb0,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddef0:[0x418018798fe1]nmp_DeviceUpdatePathStates@com.vmware.vmkapi#v2_2_0_0+0x6d stack: 0x</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddf10:[0x41801878e928]nmpDeviceProbe@com.vmware.vmkapi#v2_2_0_0+0x2c stack: 0x410b8912dac0</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddf30:[0x41801810dc41]SCSIDeviceProbe@vmkernel#nover+0xc1 stack: 0x0, 0x412546fe7000, 0x41</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddfd0:[0x418017e6133a]helpFunc@vmkernel#nover+0x6b6 stack: 0x0, 0x0, 0x0, 0x0, 0x0</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddff0:[0x418018056842]CpuSched_StartWorld@vmkernel#nover+0xfa stack: 0x0, 0x0, 0x0, 0x0, 0</span><br><span class="line">2016-01-23T00:10:51.284Z cpu37:33215)VMware ESXi 5.5.0 [Releasebuild-2456374 x86_64]</span><br><span class="line">#PF Exception 14 in world 33215:helper31-1 IP 0x4180184becc9 addr 0x410c89af6008</span><br></pre></td></tr></table></figure>

<p>/var/log/vmkernel.log，出现类似信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2015-12-11T11:57:01.035Z cpu58:33904)WARNING: iodm: vmk_IodmEvent:193: vmhba0: FRAME DROP event has been observed 217 times in the last one minute. This suggests a problem with Fibre Channel link/switch! </span><br><span class="line">2015-12-11T11:57:12.044Z cpu60:50767)WARNING: iodm: vmk_IodmEvent:193: vmhba0: FRAME DROP event has been observed 400 times in the last one minute. This suggests a problem with Fibre Channel link/switch! </span><br><span class="line">2015-12-11T11:57:23.001Z cpu48:2805963)WARNING: iodm: vmk_IodmEvent:193: vmhba0: FRAME DROP event has been observed 400 times in the last one minute. This suggests a problem with Fibre Channel link/switch! </span><br></pre></td></tr></table></figure>

<p><strong>问题原因：</strong></p>
<p>执行以下取消映射操作后但没有执行”重新扫描”则将会触发此问题：</p>
<ol>
<li>卸除VMFS数据存储</li>
<li>分离从ESXi主机已卸的LUN</li>
<li>取消映射此LUN从存储到这个ESXi主机</li>
</ol>
<p><strong>解决方案：</strong></p>
<p>要避免此问题，执行取消存储映射操作后务必重新扫描：</p>
<p>要执行ESXi主机的适配器重新扫描：</p>
<ol>
<li>转到在vSphere Web Client中ESXi主机。</li>
<li>单击管理选项卡</li>
<li>点击存储。</li>
<li>点击存储适配器，并选择适配器从列表中重新扫描。</li>
<li>点击重新扫描适配器。</li>
</ol>
<p><strong>涉及版本：</strong></p>
<p>VMware ESXi 5.5.x</p>
<h5 id="场景11：使用Intel-Xeon-Processor-E5-v4、-E7-v4-和D-1500系列处理器时，ESXi可能会出现紫屏"><a href="#场景11：使用Intel-Xeon-Processor-E5-v4、-E7-v4-和D-1500系列处理器时，ESXi可能会出现紫屏" class="headerlink" title="场景11：使用Intel Xeon Processor E5 v4、 E7 v4,和D-1500系列处理器时，ESXi可能会出现紫屏"></a>场景11：使用Intel Xeon Processor E5 v4、 E7 v4,和D-1500系列处理器时，ESXi可能会出现紫屏</h5><p><strong>问题现象</strong>：</p>
<p>当ESXi主机使用英特尔®至强®处理器E5 V4，V4 E7和D-1500系列，您可能会遇到这些症状：</p>
<ul>
<li>ESXi主机宕机，出现紫色屏幕（VMware 统称紫屏问题为：PSOD）</li>
<li>紫屏中没有详细的内核输出信息</li>
<li>紫色屏幕中，出现以下信息</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2016-07-27T13:14:04.549Z cpu58:42053)@BlueScreen: #PF Exception 14 in world 42053:vmm7:My_VM IP 0x410016bb8000 addr 0x410016bb8000 PTEs:0x10001c023;0x8000010023;0x80000e5023;0x800000408841e063;</span><br><span class="line">2016-07-27T13:14:04.549Z cpu58:42053)Code start: 0x418018000000 VMK uptime: 2:04:41:19.840</span><br><span class="line">2016-07-27T13:14:04.552Z cpu58:42053)base fs=0x0 gs=0x41804e800000 Kgs=0x0</span><br></pre></td></tr></table></figure>

<p><strong>解决方案：</strong></p>
<p>这是影响了英特尔®至强®处理器E5 V4，V4 E7和D-1500系列的一个已知的硬件问题。这是不是VMware的问题。</p>
<p>要解决此问题，升级系统BIOS（固件），以它为相关的Intel Xeon处理器以下微补丁修订级别版本：</p>
<table>
<thead>
<tr>
<th>CPU系列</th>
<th>CPUID模型（步进）</th>
<th>要求微码版本补丁</th>
<th>支持的ESXi版本</th>
</tr>
</thead>
<tbody><tr>
<td>英特尔至强E5-2600-V4英特尔至强E5-4600-V4</td>
<td>0x406F1（B0步进）</td>
<td>0x0b00001a或更高版本</td>
<td>ESXi的5.5 U3B或更高版本ESXi 6.0器U1b或更高版本</td>
</tr>
<tr>
<td>英特尔至强E7-8800-V4英特尔至强E7-4800-V4</td>
<td>0x406F1（B0步进）</td>
<td>0x0b00001a或更高版本</td>
<td>ESXi的6.0器U1b或更高版本</td>
</tr>
<tr>
<td>英特尔®至强®D-1500</td>
<td>0x50663（V2步进）</td>
<td>0x0700000c或更高版本</td>
<td>ESXi的6.0器U1b或更高版本</td>
</tr>
<tr>
<td>英特尔®至强®D-1500</td>
<td>0x50664（Y0步进）</td>
<td>0x0f00000a或更高版本</td>
<td>ESXi的6.0器U1b或更高版本</td>
</tr>
</tbody></table>
<p>欲了解更多信息，请联系您的硬件供应商。紫屏输出的内核信息也可能包含以下：</p>
<ul>
<li><p>SP_WaitLockIRQ</p>
<p>SPLockIRQWork</p>
<p>SPUnlockIRQWork</p>
<p>VsanSparseUpdateCache</p>
<p>IpfixPCInit</p>
<p>IpfixPortInsert</p>
</li>
<li><p>Panic_Exception</p>
<p>WorldletBHHandler</p>
<p>Timer_BHHandler</p>
<p>TimerRecomputeInterrupt</p>
<p>BH_DrainAndDisableInterrupts</p>
<p>IDT_IntrHandler</p>
<p>gate_entry_</p>
<p>Power_HaltPCPU</p>
<p>CpuSchedIdleLoopInt</p>
<p>CpuSchedDispatch</p>
<p>CpuSchedWait</p>
<p>CpuSched_VcpuHalt</p>
<p>CpuSched_VcpuMigrateBestPcpu</p>
<p>CpuSchedMarkReschedule</p>
<p>CpuSchedVcpuSetRunState</p>
<p>VMMVMKCall_Call</p>
<p>CpuSchedRebalance_PcpuMigrateIdle</p>
<p>IntrCookie_DoInterrupt</p>
<p>Panicvpanicint</p>
<p>Panic_NoSave</p>
</li>
</ul>
<p><strong>涉及版本</strong>：</p>
<p>ESXi 5.5 U3b or later</p>
<p>ESXi 6.0 U1b or later</p>
<h5 id="场景12：ESXi使用Broadcom网卡bnx2x驱动时可能会出现紫屏"><a href="#场景12：ESXi使用Broadcom网卡bnx2x驱动时可能会出现紫屏" class="headerlink" title="场景12：ESXi使用Broadcom网卡bnx2x驱动时可能会出现紫屏"></a>场景12：ESXi使用Broadcom网卡bnx2x驱动时可能会出现紫屏</h5><p><strong>问题现象：</strong></p>
<p>ESXi5.5.x 宕机出现紫色屏幕并出现类似信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@BlueScreen: #PF Exception 14 in world wwww:WorldName IP 0xnnnnnnnn addr 0x0</span><br><span class="line">PTEs:0xnnnnnnnn;0xnnnnnnnn;0x0;</span><br><span class="line"></span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]bnx2x_netqueue_ops@com.broadcom.bnx2x#9.2.2.0+0x54</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]netqueue_op_realloc_queue_with_attr@com.vmware.driverAPI#9.2+0x3cd</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]UplinkRxQueuesLoadBalance@vmkernel#nover+0x212c</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]UplinkLB_LoadBalanceCB@vmkernel#nover+0x8e</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]UplinkAsyncProcessCallsHelperCB@vmkernel#nover+0x223</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]helpFunc@vmkernel#nover+0x6b6</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]CpuSched_StartWorld@vmkernel#nover+0xfa</span><br></pre></td></tr></table></figure>

<p><strong>问题原因：</strong></p>
<p>此问题是由于bnx2x驱动程序处理NetQueue数据时不正确地传递一个错误的数据给VMkernel 而引起</p>
<p><strong>解决方案：</strong></p>
<p>这是一个QLogic驱动引起的问题，暂时没有解决方法。</p>
<p>要避免该问题进一步发生，请调整虚拟机延迟敏感度。</p>
<p>注意：具有高延迟敏感度的虚拟机会引发该问题</p>
<p>要更改虚拟机敏感度使用vSphere Web Client 登陆：</p>
<ol>
<li>导航至<strong>虚拟机&gt;编辑设置&gt; VM选项&gt;高级&gt;延迟灵敏度</strong>。</li>
<li>点击<strong>正常</strong>。</li>
</ol>
<p><strong>涉及版本：</strong></p>
<p>VMware ESXi 5.5.x</p>
<h5 id="场景13：VMware-ESXi-5-x主机出现指示-E1000PollRxRing和E1000DevRx的紫色诊断屏幕（紫屏）"><a href="#场景13：VMware-ESXi-5-x主机出现指示-E1000PollRxRing和E1000DevRx的紫色诊断屏幕（紫屏）" class="headerlink" title="场景13：VMware ESXi 5.x主机出现指示 E1000PollRxRing和E1000DevRx的紫色诊断屏幕（紫屏）"></a>场景13：VMware ESXi 5.x主机出现指示 E1000PollRxRing和E1000DevRx的紫色诊断屏幕（紫屏）</h5><p><strong>问题现象：</strong></p>
<ul>
<li>ESXi 5.x 主机出现故障并显示紫色诊断屏幕</li>
<li>ESXi 主机正在运行使用 E1000e 虚拟网络适配器的虚拟机</li>
<li>紫色诊断屏幕包含类似于以下内容的条目：</li>
</ul>
<p>注意： 确保在您的环境中遇到的问题符合本知识库文章中指定的症状。 知识库文章 <a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2097304">VMware ESXi 5.x 主机出现紫色诊断屏幕，提及 E1000PollRxRing、E1000DevRx 和 Net_AcceptRxList (2097304)</a> 列举了一些与本知识库文章类似的症状，并且权宜措施完全相同。 但回溯中功能的偏差不同。</p>
<p><strong>解决方案：</strong></p>
<p>该问题在以下版本中已解决：</p>
<ul>
<li>ESXi 5.0 Patch Release ESXi500-201401001。 有关详细信息，请参见 <a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2065814">VMware ESXi 5.0, Patch Release </a><a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2065814">ESXi500-201401001 (2065814)</a>。</li>
<li>ESXi 5.1 Update 2（可在 <a target="_blank" rel="noopener" href="https://https//my.vmware.com/web/vmware/info/slug/datacenter_cloud_infrastructure/vmware_vsphere/5_1">VMware Downloads</a> 上获取）。 有关详细信息，请参见 <a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2065814">VMware </a><a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2062314">VMware ESXi 5.1, Patch ESXi510-Update02: ESXi 5.1 Complete Update 2 (2062314)</a>。</li>
<li>有关 VMware ESXi 5.5 Patch Release ESXi550-201410001 (2087358) 的详细信息，请参见 <a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2087358">VMware ESXi 5.5, Patch Release ESXi550-201410001 (2087358)</a></li>
<li>ESXi 6.0 GA，可从 <a target="_blank" rel="noopener" href="https://https//my.vmware.com/web/vmware/info/slug/datacenter_cloud_infrastructure/vmware_vsphere/6_0">VMware Downloads</a> 获取。 有关详细信息，请参见 <a target="_blank" rel="noopener" href="http://www.vmware.com/support/vsphere6/doc/vsphere-esx-vcenter-server-60-release-notes.html">VMware ESXi 6.0 Release notes</a>。</li>
</ul>
<p>VMware 推荐您将 ESXi 主机升级到最新可用的版本。 要检查最新可用版本，请转到 <a target="_blank" rel="noopener" href="https://my.vmware.com/group/vmware/info?slug=datacenter_cloud_infrastructure/vmware_vsphere/6_0">VMware Downloads</a>，然后选择正使用的 ESXi 版本。</p>
<p>注意： 在更新 ESXi 主机版本后，需要更新 VMware Tools。</p>
<p>有关其他信息，请参见<a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2077966">将 VMware 产品内部版本号与更新级别关联 (2077966)</a>。</p>
<p><strong>权宜措施</strong>：</p>
<p>要临时解决此问题，请执行以下操作：</p>
<ol>
<li><p>确定在使用 E1000e 系列虚拟网络接口的虚拟机：注意： 通过 vSphere PowerCLI 确定正使用 E1000e 网络适配器的虚拟机。 有关 PowerCLI 安装和使用的详细信息，请参见</p>
<p>vSphere PowerCLI Documentation</p>
<p>。</p>
<p>打开 vSphere PowerCLI。</p>
<p>运行以下命令连接到 vCenter Server：</p>
<p>Connect-VIServer vCenterServerHostnameOrIPAddress</p>
<p>注意： 在 PowerCLI 5.5 中运行 Connect-VIServer vCenterServerHostnameOrIPAddress 命令</p>
<p>运行以下命令生成使用 E1000e 网络适配器的虚拟机列表：</p>
<p>ForEach( $VM in (Get-VM) ) { $VM|Where{ $VM|Get-NetworkAdapter|Where{ $_.ExtensionData -like “<em>e1000e</em>“ } } }</p>
<p>您会看到类似以下内容的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Name PowerState NumCPUs MemoryGB</span><br><span class="line">---- ---------- ------- --------</span><br><span class="line">VirtualMachineA PoweredOn 2 4.000</span><br><span class="line">VirtualMachineB PoweredOff 1 2.000</span><br></pre></td></tr></table></figure>

<p>此列表中的每个虚拟机都具有一个或多个 E1000e 虚拟网络接口。</p>
<p>执行其中一个选项：</p>
<ul>
<li>使用 VMXNET3 虚拟适配器并减少 E1000e 系列适配器的使用。 有关添加或修改虚拟机的虚拟网络接口的详细信息，请参见 <a target="_blank" rel="noopener" href="http://pubs.vmware.com/vsphere-55/index.jsp?topic=/com.vmware.vsphere.vm_admin.doc/GUID-3719A0BE-4B4A-44FF-8A21-290950918FBD.html">Configuring Virtual Machine Hardware in the vSphere Web Client Guide</a> 中的“在 vSphere Web Client 中更改虚拟网络适配器（网卡）配置”部分。</li>
<li>在使用 e1000e 适配器的虚拟机中，禁用 RSS 或者将客户机操作系统中的 RSS 多个 rx 队列配置为 1。 有关详细信息，请参见 <a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2093679">Windows 虚拟机上的网络性能低下或网络延迟时间较长 (2093679)</a>。</li>
</ul>
<p><strong>Additional Information</strong></p>
<p>要在更新本文时收到提醒，请在“Actions”框中单击<strong>Subscribe to Document</strong>。</p>
<p><strong>Tags</strong></p>
<p><em>简体中文 Simplified Chinese</em></p>
<p><strong>See Also</strong></p>
<p>[VMware ESXi 5.x host experiences a purple diagnostic screen mentioning E1000PollRxRing and E1000DevRx (2059053)](<a target="_blank" rel="noopener" href="https://kb.vmware.com/selfservice/microsites/">https://kb.vmware.com/selfservice/microsites/</a> <a target="_blank" rel="noopener" href="http://kb.vmware.com/kb/2059053">http://kb.vmware.com/kb/2059053</a>)</p>
</li>
</ol>
<h5 id="场景14：物理CPU内部的二级Cache缓存故障导致VMware-ESXi主机前后多次紫屏问题"><a href="#场景14：物理CPU内部的二级Cache缓存故障导致VMware-ESXi主机前后多次紫屏问题" class="headerlink" title="场景14：物理CPU内部的二级Cache缓存故障导致VMware ESXi主机前后多次紫屏问题"></a>场景14：物理CPU内部的二级Cache缓存故障导致VMware ESXi主机前后多次紫屏问题</h5><p><strong>问题现象：</strong></p>
<p>局点一台ESXi主机上虚拟机业务均中断，登陆vCenter查看到ESXi主机失去连接，且无法正常ping通业务虚拟机和ESXi管理IP，登陆到单板的带外管理虚拟远程控制台，看到紫色屏幕，如下图：</p>
<p>（提示：物理单板两颗CPU，每颗12个core，开启了超线程，每颗24个逻辑core，第一颗CPU逻辑core为：pCPU0-pCPU23，第二颗CPU逻辑core为：pCPU24-pCPU47）</p>
<p>第一次紫屏如下（pCPU33上出错，第2颗物理CPU上）</p>
<img src="/posts/22695/zh-cn_image_0261797883.png" class="">

<p><strong>处理过程：</strong></p>
<p>关注是否为ESXi软件问题导致，分析VMware日志和Coredump文件。 随后1天左右，接连又发生多次紫屏，如下图：第二次紫屏如下（pCPU32上出错，第2颗物理CPU上）：</p>
<img src="/posts/22695/zh-cn_image_0261799399.png" class="">

<p>第三次紫屏如下（pCPU25上出错，第2颗物理CPU上）：</p>
<img src="/posts/22695/zh-cn_image_0261799904.png" class="">

<p><strong>问题原因：</strong></p>
<p>通过前后发生多次紫屏，而且每次紫屏的信息完全不同，这很有可能为硬件导致。如果为ESXi软件问题，一般会在同一处出错而紫屏，而硬件问题则会引起ESXi错误信息多样化。同时发现三张紫屏错误信息中，每次发生错误都是在第二颗物理CPU上，初步判断为硬件CPU问题。虽然通过VMware侧观察到单板硬件状态信息均正常（ESXi通过CIM服务从单板BIOS获取状态信息），但无法完全确保硬件完全没有问题。</p>
<p>通过收集单板硬件日志，从硬件日志中看到物理CPU2内部的二级Cache缓存出现大量不可纠正错误，确认CPU2故障：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Hardware Error Log]:NO.1    SMI Serial NO.1   </span><br><span class="line">collect:bios(smi)    time: 2017-12-21 06:52:18 GMT    Validate(0x00)</span><br><span class="line">CPU:1 (socket:CPU2)    core:Uncore    LogType:MCA BANK19    (CBo_2_5_8_11_14_17)    MCA mode:CDC</span><br><span class="line">Error type:Uncorrected Errors-Catastrophic/Fatal</span><br><span class="line">MCACODE:0x110a (Cache Hierarchy Error: &#123;Generic&#125;CACHE&#123;Level-2&#125;_&#123;Generic-Error&#125;_ERR)</span><br></pre></td></tr></table></figure>

<p>经验总结:</p>
<p>1、排查是否存在硬件故障，建议从硬件侧日志分析确保；</p>
<p>2、同台ESXi主机多次紫屏情况下，如果紫屏错误信息多样化，一般可定界为硬件问题，详细总结请点此<a target="_blank" rel="noopener" href="http://3ms.huawei.com/km/groups/2026933/blogs/details/5291495">链接</a> 中的“同主机多次紫屏的初步定界”部分介绍。</p>
<h5 id="场景15：【RH2288H-V2】【VMware-5-5】Qle2562-HBA卡故障，导致VMware系统无法正常安装，系统紫屏"><a href="#场景15：【RH2288H-V2】【VMware-5-5】Qle2562-HBA卡故障，导致VMware系统无法正常安装，系统紫屏" class="headerlink" title="场景15：【RH2288H V2】【VMware 5.5】Qle2562 HBA卡故障，导致VMware系统无法正常安装，系统紫屏"></a>场景15：【RH2288H V2】【VMware 5.5】Qle2562 HBA卡故障，导致VMware系统无法正常安装，系统紫屏</h5><p><strong>问题现象：</strong></p>
<p>硬件配置：RH2288H V2+Qle2562+LSI2208</p>
<p>OS：VMware5.5</p>
<p>问题描述：客户反馈开局过程中有一台RH2288H V2安装VMware5.5系统失败，出现紫屏：</p>
<p>图1 VMware5.5紫屏</p>
<img src="/posts/22695/zh-cn_image_0261799959.png" class="">

<p><strong>处理过程：</strong></p>
<p>1） 分析紫屏截图，qla2x00是Qle2562 HBA卡驱动，运行qla2x00时出现VMware系统紫屏。初步分析和Qle2562 HBA卡相关，建议一线把Qle2562 HBA卡拔掉。</p>
<p>2） 一线把Qle2562 HBA卡拔掉后，可以正常安装VMware5.5系统，重启3次也没有问题；</p>
<p>3） 一线更换一个好的Qle2562 HBA卡后，可以正常安装VMware5.5系统，重启3次也没有问题；</p>
<p><strong>问题原因：</strong></p>
<p>Qle2562 HBA卡故障导致VMware系统无法正常安装。</p>
<p><strong>结论及解决方案：</strong></p>
<p>结论：</p>
<p>Qle2562 HBA卡故障导致VMware系统无法正常安装。</p>
<p>解决方案：</p>
<p>更换Qle2562 HBA卡备件。</p>
<h5 id="场景16：ESXi5-1-E1000虚拟网卡内核bug导致紫屏问题"><a href="#场景16：ESXi5-1-E1000虚拟网卡内核bug导致紫屏问题" class="headerlink" title="场景16：ESXi5.1 E1000虚拟网卡内核bug导致紫屏问题"></a>场景16：ESXi5.1 E1000虚拟网卡内核bug导致紫屏问题</h5><p><strong>问题现象：</strong></p>
<p>硬件配置： RH5885 V2 配置 Intel 82580网卡</p>
<p>软件配置： VMware 5.1</p>
<p>VMware5.1出现紫屏。如图1所示。</p>
<p>图1 VMware 5.1 紫屏</p>
<img src="/posts/22695/zh-cn_image_0261800553.png" class="">

<p><strong>处理过程</strong>：</p>
<p>联系VMware厂家分析该紫屏信息，厂家给出了如下的KnowLedgeBase 链接：</p>
<p><a target="_blank" rel="noopener" href="http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=2079118">http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=2079118</a></p>
<p>是E1000虚拟网卡开启了rss功能之后，内核中虚拟网卡与该功能处理相关的问题引发的紫屏：</p>
<img src="/posts/22695/zh-cn_image_0261800564.png" class="">

<p><strong>问题根因：</strong></p>
<p>VMware5.1 内核问题导致紫屏。</p>
<p><strong>结论及解决方案：</strong></p>
<p>结论：</p>
<p>VMware5.1内核中E1000虚拟网卡相关模块问题导致紫屏。</p>
<p>解决方案：</p>
<p>1、到如下的VMWare官网链接安装VMware vSphere Update Manager并下载Patch ESXi510-201407401-BG补丁包后升级ESXi系统：</p>
<p><a target="_blank" rel="noopener" href="http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=2079118">http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=2079118</a></p>
<h3 id="Vmkernel-amp-驱动主动触发的紫屏"><a href="#Vmkernel-amp-驱动主动触发的紫屏" class="headerlink" title="Vmkernel &amp;驱动主动触发的紫屏"></a>Vmkernel &amp;驱动主动触发的紫屏</h3><img src="/posts/22695/zh-cn_image_0258636669.png" class="">

<h4 id="原因分析-5"><a href="#原因分析-5" class="headerlink" title="原因分析"></a>原因分析</h4><p>EXSi 主机，或者驱动在某些软件异常情况下调用vmk_Panic 函数可以触发紫屏（类似linux 系统的panic）。</p>
<p>此页内容对您是否有帮助？</p>
<h4 id="定位思路-5"><a href="#定位思路-5" class="headerlink" title="定位思路"></a>定位思路</h4><p>定位这类问题，首先查看挂死时的栈信息，如果栈信息在服务器设备的驱动上面（网卡、RAID卡）等，一般都是驱动导致的问题，优先检查VMware系统是否已经使用iDriver升级过驱动，驱动是否最新，如果驱动已经是最新，联系厂家进行定位。</p>
<p>示例是emulex be3网卡的一个bug 导致VMware系统紫屏。从紫屏信息上可以看出故障的代码在 elxnet_main.c 的 elxnet_txComplProcess 函数的 4057行。代码如下：</p>
<img src="/posts/22695/zh-cn_image_0258637887.png" class="">

<p>可以看到elxnet_txComplProcess 函数调用 ELXNET_HALT_COND宏，最终调用vmk_Panic 触发VMware 系统紫屏。</p>
<img src="/posts/22695/zh-cn_image_0258637888.png" class="">

<p>如果栈信息不在任何的驱动上面，联系VMware 进行定位。</p>
<h3 id="其他类型的紫屏错误"><a href="#其他类型的紫屏错误" class="headerlink" title="其他类型的紫屏错误"></a>其他类型的紫屏错误</h3><p>以下的这些紫屏错误都跟硬件没有关系，都是VMware 系统自身的bug导致，有兴趣的同事可以去了解下。</p>
<h4 id="控制台警告"><a href="#控制台警告" class="headerlink" title="控制台警告"></a>控制台警告</h4><p>错误示例：COS Error: Oops</p>
<p>描述：ESX 主机出现故障并在出现服务控制台警告时显示紫色屏幕。与大多数紫色屏幕错误不同的是，该错误并非由 VMkernel 触发。相反，它由服务控制台触发，并发生在 Linux 级别。这些紫色屏幕错误包含来自 Linux 内核的其他信息。有关控制台警告的详细信息，请参见 Understanding an “Oops” purple diagnostic screen (1006802)。</p>
<h4 id="断言"><a href="#断言" class="headerlink" title="断言"></a>断言</h4><p>错误示例：ASSERT bora/vmkernel/main/pframe_int.h:527</p>
<p>描述：断言错误属于软件错误，因为它们都与程序所基于的假设条件有关。此类型的紫色屏幕错误主要是由软件错误导致的。有关断言错误消息的详细信息，请参见 Understanding ASSERT and NOT_IMPLEMENTED purple diagnostic screens (1019956)。</p>
<h4 id="未执行"><a href="#未执行" class="headerlink" title="未执行"></a>未执行</h4><p>错误示例：NOT_IMPLEMENTED /build/mts/release/bora-84374/bora/vmkernel/main/util.c:83</p>
<p>描述：代码遇到超出设计处理范围的情形时会出现未执行错误消息。有关详细信息，请参见 Understanding ASSERT and NOT_IMPLEMENTED purple diagnostic screens (1019956)。</p>
<h4 id="转数已超出-可能出现死锁"><a href="#转数已超出-可能出现死锁" class="headerlink" title="转数已超出/可能出现死锁"></a>转数已超出/可能出现死锁</h4><p>错误示例：Spin count exceeded (iplLock) - possible deadlock</p>
<p>描述：线程尝试在代码关键部分执行时，VMware ESX 主机可能在紫色诊断屏幕上报告转数已超出且可能出现死锁。由于线程正尝试进入关键部分，因此，它需要执行自旋锁操作，以便先轮询互斥锁，然后再执行代码。线程在执行自旋锁操作期间会继续轮询互斥锁，但是，互斥锁轮询次数存在一定限制。有关转数已超出错误的详细信息，请参见 Understanding a “Spin count exceeded” purple diagnostic screen (1020105)。</p>
<h4 id="解决措施-5"><a href="#解决措施-5" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：【CH121】【VMware-ESXi5-1】Heap内存不足导致VMware紫屏"><a href="#场景1：【CH121】【VMware-ESXi5-1】Heap内存不足导致VMware紫屏" class="headerlink" title="场景1：【CH121】【VMware ESXi5.1】Heap内存不足导致VMware紫屏"></a>场景1：【CH121】【VMware ESXi5.1】Heap内存不足导致VMware紫屏</h5><p><strong>问题现象：</strong></p>
<p>硬件配置：CH121+16<em>8G内存+2</em>E5-2620</p>
<p>软件版本：MM910:2.20；刀片服务器BIOS:V378 BMC:5.11；</p>
<p>OS：VMware5.1</p>
<p>问题描述：客户反馈在安装Trend Micro厂家的第三方安全软件dvfilter-dsa模块后，服务器运行一段时间后，多台服务器出现如图1-1的紫屏。</p>
<p>图1 dvfilter-dsa模块调用异常导致PSOD</p>
<img src="/posts/22695/zh-cn_image_0261898928.png" class="">

<p><strong>处理过程：</strong></p>
<p>1） VMware工程师分析：</p>
<p>这些主机发生紫屏时都有相似的错误信息输出,确定是同一类故障。</p>
<p>“dlmalloc.c”是内存分配相关的一段代码。</p>
<p><strong>紫屏报警信息如下:</strong></p>
<p>-—————</p>
<p>PSOD (HZ504K0601)</p>
<p>-—————</p>
<p>2015-03-29T13:48:07.558Z cpu8:4711920)@BlueScreen: PANIC bora/vmkernel/main/dlmalloc.c:4827 - Usage error in dlmalloc 2015-03-29T13:48:07.558Z cpu8:4711920)Code start: 0x41802d800000 VMK uptime: 110:08:30:31.303 2015-03-29T13:48:07.559Z cpu8:4711920)0x4122d7c1b588:[0x41802d87b31a]PanicvPanicInt@vmkernel#nover+0x61 stack: 0x3000000008 2015-03-29T13:48:07.560Z cpu8:4711920)0x4122d7c1b668:[0x41802d87bb1b]Panic@vmkernel#nover+0xae stack: 0x4100344b04a0</p>
<p>-—————</p>
<p>PSOD(HZ504K0603)</p>
<p>-—————</p>
<p>2015-03-31T02:10:17.680Z cpu45:34771)@BlueScreen: PANIC bora/vmkernel/main/dlmalloc.c:4827 - Usage error in dlmalloc 2015-03-31T02:10:17.680Z cpu45:34771)Code start: 0x418005c00000 VMK uptime: 0:18:46:14.697 2015-03-31T02:10:17.681Z cpu45:34771)0x41225f4db348:[0x418005c7b31a]PanicvPanicInt@vmkernel#nover+0x61 stack: 0x3000000008 2015-03-31T02:10:17.682Z cpu45:34771)0x41225f4db428:[0x418005c7bb1b]Panic@vmkernel#nover+0xae stack: 0x410058699b20</p>
<p><strong>检查系统kernel日志：</strong></p>
<p>这些主机在发生紫屏时都出现大量下面的告警信息:</p>
<p>-—————</p>
<p>(HZ504K0601)</p>
<p>-—————</p>
<p>2015-03-29T13:46:18.395Z cpu26:103997)WARNING: Heap: 3058: Heap_Align(dvfilter-dsa, 80/80 bytes, 64 align) failed. caller: 0x41802d819aa7 2015-03-29T13:46:18.734Z cpu31:6538979)WARNING: Heap: 2677: Heap dvfilter-dsa already at its maximum size. Cannot expand.</p>
<p>2015-03-29T13:46:19.120Z cpu29:16413)WARNING: Heap: 2677: Heap dvfilter-dsa already at its maximum size. Cannot expand.</p>
<p>-—————-</p>
<p>(HZ504K0603)</p>
<p>-—————</p>
<p>2015-03-31T02:10:17.021Z cpu37:34772)WARNING: Heap: 2677: Heap dvfilter-dsa already at its maximum size. Cannot expand.</p>
<p>2015-03-31T02:10:17.295Z cpu39:34771)WARNING: Heap: 3058: Heap_Align(dvfilter-dsa, 880/880 bytes, 8 align) failed. caller: 0x4180064742f2 2015-03-31T02:10:17.512Z cpu45:16429)WARNING: Heap: 3058: Heap_Align(dvfilter-dsa, 392/392 bytes, 8 align) failed. caller: 0x418006488890</p>
<p>2） Trend Micro厂家分析：</p>
<p>Trend Micro厂家给出了一个kb，确认该问题和Heap内存不足会导致VMware系统紫屏，官方链接：</p>
<p><a target="_blank" rel="noopener" href="http://esupport.trendmicro.com/solution/en-us/1095995.aspx">http://esupport.trendmicro.com/solution/en-us/1095995.aspx</a></p>
<p>图2 Trend Micro厂家官方说明：</p>
<img src="/posts/22695/zh-cn_image_0261898974.png" class="">

<p><strong>问题原因：</strong></p>
<p>Heap内存不足会导致VMware系统紫屏。</p>
<p><strong>结论和解决方案：</strong></p>
<p>结论：</p>
<p>Heap内存不足会导致VMware系统紫屏。</p>
<p>解决方案：</p>
<p>通过优化heap memory 分配给filter driver大小调整解决紫屏问题。参考Trend Micro厂家官方建议或者直接联系厂家解决。</p>
<p><a target="_blank" rel="noopener" href="http://esupport.trendmicro.com/solution/en-us/1095995.aspx">http://esupport.trendmicro.com/solution/en-us/1095995.aspx</a></p>
<h5 id="场景2：RH2288H-V2服务器VMware-5-5报Can-not-detect-the-last-level-cache紫屏问题"><a href="#场景2：RH2288H-V2服务器VMware-5-5报Can-not-detect-the-last-level-cache紫屏问题" class="headerlink" title="场景2：RH2288H V2服务器VMware 5.5报Can not detect the last level cache紫屏问题"></a>场景2：RH2288H V2服务器VMware 5.5报Can not detect the last level cache紫屏问题</h5><p><strong>环境说明：</strong></p>
<p>服务器：RH2288H V2；</p>
<p>操作系统：VMware 5.5；</p>
<p><strong>问题现象：</strong></p>
<p>秘鲁GMD客户反馈在RH2288H V2服务器上安装VMware 5.5时，出现以下报错：</p>
<p>“can’t detect the last level cache”</p>
<img src="/posts/22695/zh-cn_image_0261899521.png" class="">

<p><strong>问题原因：</strong></p>
<p>该问题与BIOS中的Max CPUID Value Limit选项的设置有关。</p>
<ol>
<li><p>Max CPUID Value Limit选项默认是隐藏的。RH2288H V2服务器使用BIOS版本V386以下时，可以在启动过程中按ctrl+alt+1进入高级菜单，此时才可以在BIOS中看到Max CPUID Value Limit选项；</p>
</li>
<li><p>Max CPUID Value Limit选项默认设置为Disabled，这里将其设置为Enabled；</p>
</li>
<li><p>重新安装VMware 5.5，此时问题复现，测试截图如下所示：</p>
<img src="/posts/22695/zh-cn_image_0261910114.png" class=""></li>
<li><p>将Max CPUID Value Limit<strong>选项设置为</strong>Disabled<strong>，重新启动服务器；</strong></p>
</li>
<li><p>重新安装VMware 5.5，此时可以正常安装；</p>
</li>
</ol>
<p><strong>结论和解决方案：</strong></p>
<p>这个问题与BIOS中的Max CPUID Value Limit选项的设置有关；</p>
<h5 id="场景3：VMware-5-x-ixgbe驱动bug导致紫屏"><a href="#场景3：VMware-5-x-ixgbe驱动bug导致紫屏" class="headerlink" title="场景3：VMware 5.x ixgbe驱动bug导致紫屏"></a>场景3：VMware 5.x ixgbe驱动bug导致紫屏</h5><p><strong>问题现象：</strong></p>
<p>服务器安装VMware 5.5紫屏，屏幕打印ixgbe驱动相关堆栈信息，如下截图。</p>
<img src="/posts/22695/zh-cn_image_0261899601.png" class="">

<img src="/posts/22695/zh-cn_image_0261899618.png" class="">

<p><strong>问题原因：</strong></p>
<p>Issue is seen with Driver Version: 3.19.1iov for Network adapter Intel Corporation Ethernet 10G 2P X520 Adapter.</p>
<p>The code added for Linux driver to handle SFP module hot plug affected ESX driver. The new code caused ESX driver to constantly poll for the module info if there is no module installed. Every poll constantly added a 1 second delay which eventually locked up a CPU and led to a system crash.</p>
<p><strong>结论和解决方案：</strong></p>
<p>Upgrade driver for Network adapter Intel Corporation Ethernet 10G 2P X520 Adapter Driver to version: ixgbe 3.21.4 or later.</p>
<p>You can download the driver ixgbe 3.21.4 from:</p>
<p><a target="_blank" rel="noopener" href="https://my.vmware.com/web/vmware/details?downloadGroup=DT-ESXI55-INTEL-IXGBE-3214&amp;productId=353">https://my.vmware.com/web/vmware/details?downloadGroup=DT-ESXI55-INTEL-IXGBE-3214&amp;productId=353</a></p>
<p>Guidance for installing async drivers on vmware esxi 5.0, 5.1, and 5.5:</p>
<p><a target="_blank" rel="noopener" href="http://kb.vmware.com/kb/2005205">http://kb.vmware.com/kb/2005205</a></p>
<h5 id="场景4：E9000服务器多节点故障紫屏问题"><a href="#场景4：E9000服务器多节点故障紫屏问题" class="headerlink" title="场景4：E9000服务器多节点故障紫屏问题"></a>场景4：E9000服务器多节点故障紫屏问题</h5><p><strong>问题现象描述</strong></p>
<p>NA客户E9000服务器slot2，slot4，slot11，slot12四个槽位的计算节点依次出现紫屏现象。该四个节点的操作系统为Vmware，上行业务为虚拟化集群。</p>
<p>操作系统紫屏后，重启该节点刀片，系统恢复正常。并且E9000管理界面无任何硬件告警。</p>
<img src="/posts/22695/zh-cn_image_0261899741.jpg" class="">

<img src="/posts/22695/zh-cn_image_0261899742.jpg" class="">

<p>slot4计算节点紫屏截图</p>
<img src="/posts/22695/zh-cn_image_0261899743.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p><strong>1****、初步分析</strong></p>
<p>BMC硬件分析无任何异常，且从问题现象判断与硬件相关不大。</p>
<p>已有的紫屏截图：</p>
<img src="/posts/22695/zh-cn_image_0261899744.jpg" class="">

<img src="/posts/22695/zh-cn_image_0261899640.jpg" class="">

<p>报错驱动模块为elxnet，即Emulex 网卡扣卡的驱动，出错的处理过程是txCompleProcess，即发送报文时遇到UE(Unrecoverable Error不可修复错误)故障。</p>
<p>下图为硬件信息:</p>
<img src="/posts/22695/zh-cn_image_0261899745.jpg" class="">

<p>根据VMware的commands目录下相关文件，确认驱动与固件版本分别为：</p>
<p>Driver: elxnet</p>
<p>Firmware Version: 1.1.43.34</p>
<p>Version: 10.2.309.6v</p>
<p>操作系统版本：ESXi5.5</p>
<p>刀片型号：IT11SRCD，即CH240。</p>
<p>根据版本iDriver配套表，完全不满足匹配要求。</p>
<p><strong>2****、进一步分析</strong></p>
<p>客户升级当前OS版本VMware5.5.0为VMware6.5.0后，升级对应驱动和FW配套版本。</p>
<p>CH121 CPU 2650 V2，CH240 CPU 4650 V2，联想服务器CPU 2650 V2。</p>
<p>客户反馈之前有几台虚机在E9000漂移不定，客户发现这几台虚机漂移到哪个刀片那个刀片就紫屏。</p>
<table>
<thead>
<tr>
<th><strong>厂商</strong></th>
<th><strong>型号</strong></th>
<th><strong>CPU****型号</strong></th>
<th><strong>华为</strong> <strong>TO</strong> <strong>联想</strong></th>
<th><strong>联想</strong> <strong>TO</strong> <strong>华为</strong></th>
</tr>
</thead>
<tbody><tr>
<td>华为刀片</td>
<td>CH121</td>
<td>2650V2</td>
<td>√</td>
<td>×</td>
</tr>
<tr>
<td>联想刀片</td>
<td>X240</td>
<td>2650V2</td>
<td>√</td>
<td>×</td>
</tr>
<tr>
<td><strong>厂商</strong></td>
<td><strong>型号</strong></td>
<td><strong>CPU****型号</strong></td>
<td><strong>华为</strong> <strong>TO</strong> <strong>联想</strong></td>
<td><strong>联想</strong> <strong>TO</strong> <strong>华为</strong></td>
</tr>
<tr>
<td>华为刀片</td>
<td>CH240</td>
<td>4650V2</td>
<td>√</td>
<td>×</td>
</tr>
<tr>
<td>联想刀片</td>
<td>X240</td>
<td>2650V2</td>
<td>√</td>
<td>×</td>
</tr>
<tr>
<td><strong>厂商</strong></td>
<td><strong>型号</strong></td>
<td><strong>CPU****型号</strong></td>
<td><strong>CH121 TO CH240</strong></td>
<td><strong>CH240 TO CH121</strong></td>
</tr>
<tr>
<td>华为刀片</td>
<td>CH121</td>
<td>2650V2</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>华为刀片</td>
<td>CH240</td>
<td>4650V2</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td><strong>厂商</strong></td>
<td><strong>型号</strong></td>
<td><strong>CPU****型号</strong></td>
<td><strong>BIOS****版本</strong></td>
<td><strong>网卡驱动版本</strong></td>
</tr>
<tr>
<td>华为刀片</td>
<td>CH121</td>
<td>2650V2</td>
<td>5.21</td>
<td>11.1.240.0</td>
</tr>
<tr>
<td>华为刀片</td>
<td>CH240</td>
<td>4650V2</td>
<td>5.21</td>
<td>11.1.240.0</td>
</tr>
</tbody></table>
<p>查询最新紫屏截图和错误打印，确认为VMware版本bug问题。</p>
<p><a target="_blank" rel="noopener" href="https://kb.vmware.com/articleview?docid=2147958&amp;lang=zh_CN">https://kb.vmware.com/articleview?docid=2147958&amp;lang=zh_CN</a></p>
<p>错误打印：#GP Exception 13 in world 187416:vmm3:XXXXXXXX @ 0x418021d8adc7</p>
<img src="/posts/22695/zh-cn_image_0261899641.jpg" class="">

<p><strong>结论、解决方案及效果</strong></p>
<p>结论</p>
<ol>
<li><p>最初刀片紫屏是因为网卡和RAID卡FW和驱动不配套。</p>
</li>
<li><p>刀片虚拟机迁移紫屏原因在于VMware6.5.0版本bug。</p>
</li>
</ol>
<p>解决方案</p>
<ol>
<li>升级FW和驱动至配套版本。</li>
<li>此问题在 ESX 6.5.0a（可从 VMware Downloads 获得）中已得到解决。</li>
</ol>
<p>要针对从以前版本迁移到 ESXi 6.5 主机的虚拟机临时解决此问题，请从 ESXi 6.5 主机恢复虚拟机并在所有 ESXi 6.5 主机上将 Numa.FollowCoresPerSocket 设置为 1。</p>
<h5 id="场景5：安装包损坏（Could-not-load-multiboot-modules-Bad-parameter）"><a href="#场景5：安装包损坏（Could-not-load-multiboot-modules-Bad-parameter）" class="headerlink" title="场景5：安装包损坏（Could not load multiboot modules : Bad parameter）"></a>场景5：安装包损坏（Could not load multiboot modules : Bad parameter）</h5><p><strong>问题现象描述</strong></p>
<p>客户在安装VMWare ESXi 失败（“Could not load multiboot modules : Bad parameter”），提示如下紫屏错误：</p>
<img src="/posts/22695/zh-cn_image_0261907005.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p>分析原因一般有两个：</p>
<ol>
<li>兼容性问题。</li>
<li>安装源损坏，无法加载XXX modules。</li>
</ol>
<p><strong>结论、解决方案及效果</strong></p>
<p><strong>结论：</strong></p>
<ol>
<li>查看安装的版本是否在兼容性列表。</li>
<li>重新刻制安装光盘，可以成功安装。</li>
</ol>
<h5 id="场景6：CH220-V3服务器安装VMware-ESXi-5-1-U2紫屏问题"><a href="#场景6：CH220-V3服务器安装VMware-ESXi-5-1-U2紫屏问题" class="headerlink" title="场景6：CH220 V3服务器安装VMware ESXi 5.1 U2紫屏问题"></a>场景6：CH220 V3服务器安装VMware ESXi 5.1 U2紫屏问题</h5><p><strong>问题现象描述</strong></p>
<p>CH220 V3服务器配置E5-2697 V3 CPU，安装VMware ESXi 5.1U2系统，在loading阶段出现紫屏问题，无法完成安装；</p>
<p>【环境描述】</p>
<p>OS: VMware5.1.0.update02-1483097.x86_64.iso</p>
<p>CPU: Intel(R) Xeon(R) CPU E5-2697 v3 @ 2.60GHz *2</p>
<p>内存：Samsung 16384 MB 2133 MHz</p>
<p>RAID卡：LSI2308卡</p>
<p>硬盘：THSHIBA MBF2300RC 300GB</p>
<img src="/posts/22695/zh-cn_image_0261907406.jpg" class="">

<p><strong>关键过程、根本原因分析</strong></p>
<p>该问题定位为VMware ESXi 5.1U2 bug；当CPU核数刚好等于56时，安装VMware ESXi 5.1U2过程中会出现紫屏。这个bug在VMware ESXi 5.1 Patch 5（build版本2000251），即VMware ESXi 5.1 U2a得到解决。</p>
<p>分析过程：</p>
<ol>
<li>在同一环境下，RH2288 V3 配置Intel(R) Xeon(R) CPU E5-2698 v3 @ 2.30GHz的CPU, 可以完成VMware ESXi 5.1U2系统安装；</li>
<li>在同一环境下，RH2288 V3与CH220 V3对调CPU, 进行VMware ESXi 5.1U2系统安装；在RH2288 V3配置E5-2697 V3 CPU后，安装过程中（loading阶段）也出现紫屏问题；而在CH220 V3上，配置E5-2698 V3 CPU后可以完成VMware ESXi 5.1U2系统安装。</li>
<li>遍历CPU型号，发现V3服务器配置E5-2697 V3 CPU时该紫屏问题才出现；</li>
<li>对比验证友商同代服务器，在配置了E5-2697 V3 CPU后，友商服务器可以完成VMware ESXi 5.1U2系统安装；发现友商服务器的BIOS中关闭了超线程，而华为服务器默认开启了超线程；</li>
<li>友商服务器的BIOS中开启超线程后，重新安装VMware ESXi 5.1U2，复现了紫屏问题。</li>
<li>V3服务器配置E5-2697 V3 CPU且开启超线程的情况下，CPU核数为56个核；通过定制BIOS，将E5-2698 V3 关掉2个核，即开启56个核，发现此时紫屏问题也能复现。当关掉3个核，即开启55个核或者关掉1个核，即开启57个核的情况下，都可以正常安装VMware ESXi 5.1U2；</li>
<li>使用VMware ESXi 5.1 U2a的ISO安装，发现此时即使CPU核数为56个时，都可以正常安装操作系统；</li>
<li>通过测试验证以及与VMware沟通确认，VMware答复该问题为VMware ESXi 5.1U2 bug，需要通过VMware ESXi 5.1 Patch 5（build版本2000251），即VMware ESXi 5.1 U2a解决；</li>
</ol>
<img src="/posts/22695/zh-cn_image_0261907398.jpg" class="">

<p><strong>结论、解决方案及效果</strong></p>
<p><strong>结论：</strong></p>
<p>该问题定位为VMware ESXi 5.1U2 bug。</p>
<p><strong>解决方案：</strong></p>
<p>当服务器配置E5-2697 V3 CPU时，请使用VMware ESXi 5.1 Patch 5（build版本2000251），即VMware ESXi 5.1 U2a或者ESXi 5.1 U3等更高版本来安装；</p>
<p><strong>备注：</strong></p>
<p>在VMware官网，可以通过输入build版本号获取相应VMware ESXi 5.1 U2a ISO文件，如下所示：</p>
<p><a target="_blank" rel="noopener" href="https://www.vmware.com/patchmgr/findPatchByReleaseName.portal">https://www.vmware.com/patchmgr/findPatchByReleaseName.portal</a></p>
<img src="/posts/22695/zh-cn_image_0261907399.jpg" class="">

<img src="/posts/22695/zh-cn_image_0261907400.jpg" class="">

<h5 id="场景7：RH2288-V3启动EXSi紫屏"><a href="#场景7：RH2288-V3启动EXSi紫屏" class="headerlink" title="场景7：RH2288 V3启动EXSi紫屏"></a>场景7：RH2288 V3启动EXSi紫屏</h5><p><strong>问题现象描述</strong></p>
<p>硬件配置：RH2288 V3</p>
<p>问题现象：系统启动时发生紫屏无法进入系统</p>
<p><strong>关键过程、根本原因分析</strong></p>
<p>关键过程：</p>
<p>1.系统启动界面发生紫屏。</p>
<img src="/posts/22695/zh-cn_image_0261908655.png" class="">

<p>2.NOT_IMPLEMENTED紫屏代码说明。</p>
<img src="/posts/22695/zh-cn_image_0261908544.png" class="">

<p>3.VM官网相关案例说明。</p>
<p><a target="_blank" rel="noopener" href="https://kb.vmware.com/s/article/2063837">https://kb.vmware.com/s/article/2063837</a></p>
<img src="/posts/22695/zh-cn_image_0261908665.png" class="">

<p>4.重新安装系统后紫屏现象消失。</p>
<p><strong>根本原因分析</strong>：</p>
<p>系统文件损坏导致无法系统无法启动。</p>
<p><strong>结论、解决方案及效果</strong></p>
<p>结论：</p>
<p>系统文件损坏导致无法系统无法启动。</p>
<p>解决方案：</p>
<p>重新安装系统。</p>
<h3 id="参考KB"><a href="#参考KB" class="headerlink" title="参考KB"></a>参考KB</h3><p><a target="_blank" rel="noopener" href="http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=1004250">http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=1004250</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:gaoshuais@126.com">gaoshuai</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://www.gaoshuais.top/posts/22695/">https://www.gaoshuais.top/posts/22695/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.gaoshuais.top" target="_blank">HILL</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/VMware/">VMware</a></div><div class="post_share"><div class="social-share" data-image="/img/head.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/31022/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">VMvare的HBA卡驱动存储常见案例</div></div></a></div><div class="next-post pull-right"><a href="/posts/2252/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">VMware日志分析方法</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/31022/" title="VMvare的HBA卡驱动存储常见案例"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-19</div><div class="title">VMvare的HBA卡驱动存储常见案例</div></div></a></div><div><a href="/posts/2252/" title="VMware日志分析方法"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-19</div><div class="title">VMware日志分析方法</div></div></a></div><div><a href="/posts/4901/" title="vSAN磁盘offline场景操作建议指导"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-19</div><div class="title">vSAN磁盘offline场景操作建议指导</div></div></a></div><div><a href="/posts/17395/" title="vSAN系统日志收集指导"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-19</div><div class="title">vSAN系统日志收集指导</div></div></a></div><div><a href="/posts/1686/" title="服务器VMware紫屏问题定界工具方案"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-20</div><div class="title">服务器VMware紫屏问题定界工具方案</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">gaoshuai</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/gaoshuais/"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">随缘更新</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#VMware%E7%B3%BB%E7%BB%9F%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D%E6%80%9D%E8%B7%AF"><span class="toc-number">1.</span> <span class="toc-text">VMware系统紫屏问题定位思路</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">1.1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B4%AB%E5%B1%8F%E8%A7%A3%E6%9E%90"><span class="toc-number">1.2.</span> <span class="toc-text">紫屏解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A7%E5%93%81%E5%92%8C%E5%86%85%E9%83%A8%E7%89%88%E6%9C%AC"><span class="toc-number">1.2.1.</span> <span class="toc-text">产品和内部版本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%94%99%E8%AF%AF%E6%B6%88%E6%81%AF"><span class="toc-number">1.2.2.</span> <span class="toc-text">错误消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU%E5%AF%84%E5%AD%98%E5%99%A8"><span class="toc-number">1.2.3.</span> <span class="toc-text">CPU寄存器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%A9%E7%90%86CPU"><span class="toc-number">1.2.4.</span> <span class="toc-text">物理CPU</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A0%86%E6%A0%88%E8%B7%9F%E8%B8%AA"><span class="toc-number">1.2.5.</span> <span class="toc-text">堆栈跟踪</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E6%9C%BA%E8%BF%90%E8%A1%8C%E6%97%B6%E9%95%BF"><span class="toc-number">1.2.6.</span> <span class="toc-text">主机运行时长</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E8%BD%AC%E5%82%A8"><span class="toc-number">1.2.7.</span> <span class="toc-text">核心转储</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90"><span class="toc-number">1.3.</span> <span class="toc-text">常见紫屏问题分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#NMI"><span class="toc-number">1.3.1.</span> <span class="toc-text">NMI</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">原因分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E6%80%9D%E8%B7%AF"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">定位思路</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%8E%AA%E6%96%BD"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">解决措施</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF1%EF%BC%9A3108-RAID%E5%8D%A1FW-amp-%E9%A9%B1%E5%8A%A8%E9%97%AE%E9%A2%98%E5%AF%BC%E8%87%B4VMware%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.1.3.1.</span> <span class="toc-text">场景1：3108 RAID卡FW&amp;驱动问题导致VMware紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF2%EF%BC%9ALSI3108-5288-V3%E9%85%8D%E7%BD%AE3108%E5%AE%89%E8%A3%85VMware%E8%BF%90%E8%A1%8C%E4%B8%AD%E7%B4%AB%E5%B1%8F%E6%A1%88%E4%BE%8B"><span class="toc-number">1.3.1.3.2.</span> <span class="toc-text">场景2：LSI3108-5288 V3配置3108安装VMware运行中紫屏案例</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF3%EF%BC%9ARH2288-V5%E9%85%8D%E5%90%88VMware-6-0%EF%BC%8C%E5%9C%A8%E9%95%BF%E6%9C%9F%E4%B8%9A%E5%8A%A1%E5%8E%8B%E5%8A%9B%E4%B8%8B%E5%AF%BC%E8%87%B4%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.1.3.3.</span> <span class="toc-text">场景3：RH2288 V5配合VMware 6.0，在长期业务压力下导致紫屏</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MCE"><span class="toc-number">1.3.2.</span> <span class="toc-text">MCE</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90-1"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">原因分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E6%80%9D%E8%B7%AF-1"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">定位思路</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%8E%AA%E6%96%BD-1"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">解决措施</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF1%EF%BC%9ARH5885-V3%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%86%85%E5%AD%98%E6%95%85%E9%9A%9C%E5%AF%BC%E8%87%B4Vmware%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.2.3.1.</span> <span class="toc-text">场景1：RH5885 V3服务器内存故障导致Vmware紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF2%EF%BC%9A%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E5%B1%9E%E6%80%A7%E9%97%AE%E9%A2%98%E5%AF%BC%E8%87%B4%E7%B4%AB%E5%B1%8F%E6%A1%88%E4%BE%8B"><span class="toc-number">1.3.2.3.2.</span> <span class="toc-text">场景2：地址空间属性问题导致紫屏案例</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF3%EF%BC%9AVMware%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98%E6%A1%88%E4%BE%8B"><span class="toc-number">1.3.2.3.3.</span> <span class="toc-text">场景3：VMware紫屏问题案例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Failed-to-ack-TLB-invalidate"><span class="toc-number">1.3.3.</span> <span class="toc-text">Failed to ack TLB invalidate</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90-2"><span class="toc-number">1.3.3.1.</span> <span class="toc-text">原因分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E6%80%9D%E8%B7%AF-2"><span class="toc-number">1.3.3.2.</span> <span class="toc-text">定位思路</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%8E%AA%E6%96%BD-2"><span class="toc-number">1.3.3.3.</span> <span class="toc-text">解决措施</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF1%EF%BC%9AMwait%E6%95%85%E9%9A%9C%E5%AF%BC%E8%87%B4VMware%E7%B3%BB%E7%BB%9F%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.3.3.1.</span> <span class="toc-text">场景1：Mwait故障导致VMware系统紫屏问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF2%EF%BC%9A%E3%80%90RH5885-V3%E3%80%91%E3%80%90VMware-6-0%E3%80%91Intel-Haswell-CPU%E5%B9%B3%E5%8F%B0%EF%BC%88%E5%BE%AE%E7%A0%81%E7%BC%96%E5%8F%B7%E4%B8%BAerratum-HSX54%EF%BC%8CMwait%E5%8A%9F%E8%83%BD%EF%BC%89%E7%BC%BA%E9%99%B7%E5%AF%BC%E8%87%B4ESXi6-0%E7%B4%AB%E5%B1%8F%EF%BC%8CBMC%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0CatError%E5%91%8A%E8%AD%A6%EF%BC%8CFDM%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0MCA%E9%94%99%E8%AF%AF"><span class="toc-number">1.3.3.3.2.</span> <span class="toc-text">场景2：【RH5885 V3】【VMware 6.0】Intel Haswell CPU平台（微码编号为erratum HSX54，Mwait功能）缺陷导致ESXi6.0紫屏，BMC日志打印CatError告警，FDM日志打印MCA错误</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#No-heartbeat"><span class="toc-number">1.3.4.</span> <span class="toc-text">No heartbeat</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90-3"><span class="toc-number">1.3.4.1.</span> <span class="toc-text">原因分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E6%80%9D%E8%B7%AF-3"><span class="toc-number">1.3.4.2.</span> <span class="toc-text">定位思路</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%8E%AA%E6%96%BD-3"><span class="toc-number">1.3.4.3.</span> <span class="toc-text">解决措施</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF1%EF%BC%9AVMware-6-5%E8%B7%91%E8%99%9A%E6%8B%9F%E6%9C%BANVME%E7%A1%AC%E7%9B%98%E5%8E%8B%E5%8A%9B%E5%87%BA%E7%8E%B0%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.4.3.1.</span> <span class="toc-text">场景1：VMware 6.5跑虚拟机NVME硬盘压力出现紫屏问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF2%EF%BC%9AEsxi-6-0U2-lsi-mr3%E9%A9%B1%E5%8A%A8%E5%AF%BC%E8%87%B4%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.4.3.2.</span> <span class="toc-text">场景2：Esxi_6.0U2_lsi_mr3驱动导致紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF3%EF%BC%9ARH2288-V3%E6%9C%8D%E5%8A%A1%E5%99%A8VMware%E7%B3%BB%E7%BB%9F%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.4.3.3.</span> <span class="toc-text">场景3：RH2288 V3服务器VMware系统紫屏问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF4%EF%BC%9AMZ510-FC%E9%A9%B1%E5%8A%A8%E5%92%8CFW%E4%B8%8D%E5%8C%B9%E9%85%8D%E5%AF%BC%E8%87%B4VMware%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.4.3.4.</span> <span class="toc-text">场景4：MZ510 FC驱动和FW不匹配导致VMware紫屏</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PF-Exception-14-amp-GP-Exception-13"><span class="toc-number">1.3.5.</span> <span class="toc-text">PF Exception 14 &amp; GP Exception 13</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90-4"><span class="toc-number">1.3.5.1.</span> <span class="toc-text">原因分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E6%80%9D%E8%B7%AF-4"><span class="toc-number">1.3.5.2.</span> <span class="toc-text">定位思路</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%8E%AA%E6%96%BD-4"><span class="toc-number">1.3.5.3.</span> <span class="toc-text">解决措施</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF1%EF%BC%9AVMware%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%B8%A62208%E9%A9%B1%E5%8A%A8%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.5.3.1.</span> <span class="toc-text">场景1：VMware系统自带2208驱动紫屏问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF2%EF%BC%9ACH121-V3%E6%9C%8D%E5%8A%A1%E5%99%A8EXSi%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.5.3.2.</span> <span class="toc-text">场景2：CH121 V3服务器EXSi紫屏问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF3%EF%BC%9AVMware-5-5%E8%87%AA%E5%B8%A6MZ910%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8bug%E5%AF%BC%E8%87%B4%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.5.3.3.</span> <span class="toc-text">场景3：VMware 5.5自带MZ910网卡驱动bug导致紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF4%EF%BC%9A2288H-V5%E6%9C%8D%E5%8A%A1%E5%99%A8VMware%E7%B3%BB%E7%BB%9F%E5%87%BA%E7%8E%B0%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.5.3.4.</span> <span class="toc-text">场景4：2288H V5服务器VMware系统出现紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF5%EF%BC%9AMZ910%E9%A9%B1%E5%8A%A8%E4%B8%8D%E9%85%8D%E5%A5%97%E5%AF%BC%E8%87%B4%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.5.3.5.</span> <span class="toc-text">场景5：MZ910驱动不配套导致紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF6%EF%BC%9AMZ910%E7%BD%91%E5%8D%A1%E4%B8%89%E6%AC%A1%E9%97%AA%E6%96%AD%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.5.3.6.</span> <span class="toc-text">场景6：MZ910网卡三次闪断问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF7%EF%BC%9AVMware%E4%B8%BB%E6%9C%BA%E7%B4%AB%E5%B1%8F%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.5.3.7.</span> <span class="toc-text">场景7：VMware主机紫屏异常问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF8%EF%BC%9A2288H-V5-CPU%E6%95%85%E9%9A%9C%E5%AF%BC%E8%87%B4Vmware%E7%B4%AB%E5%B1%8FPSOD"><span class="toc-number">1.3.5.3.8.</span> <span class="toc-text">场景8：2288H V5 CPU故障导致Vmware紫屏PSOD</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF9%EF%BC%9ARH2288H-V3%E4%BD%BF%E7%94%A8ESXi-6-5-U2%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8C%E5%8A%A0%E5%85%A5vsan%E9%9B%86%E7%BE%A4%E5%90%8E%E5%87%BA%E7%8E%B0%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.5.3.9.</span> <span class="toc-text">场景9：RH2288H V3使用ESXi 6.5 U2操作系统，加入vsan集群后出现紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF10%EF%BC%9AESXi-5-5-x%E5%8F%96%E6%B6%88%E5%AD%98%E5%82%A8%E6%98%A0%E5%B0%84%E5%90%8E%E5%8F%AF%E8%83%BD%E8%A7%A6%E5%8F%91%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.5.3.10.</span> <span class="toc-text">场景10：ESXi 5.5.x取消存储映射后可能触发紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF11%EF%BC%9A%E4%BD%BF%E7%94%A8Intel-Xeon-Processor-E5-v4%E3%80%81-E7-v4-%E5%92%8CD-1500%E7%B3%BB%E5%88%97%E5%A4%84%E7%90%86%E5%99%A8%E6%97%B6%EF%BC%8CESXi%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%87%BA%E7%8E%B0%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.5.3.11.</span> <span class="toc-text">场景11：使用Intel Xeon Processor E5 v4、 E7 v4,和D-1500系列处理器时，ESXi可能会出现紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF12%EF%BC%9AESXi%E4%BD%BF%E7%94%A8Broadcom%E7%BD%91%E5%8D%A1bnx2x%E9%A9%B1%E5%8A%A8%E6%97%B6%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%87%BA%E7%8E%B0%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.5.3.12.</span> <span class="toc-text">场景12：ESXi使用Broadcom网卡bnx2x驱动时可能会出现紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF13%EF%BC%9AVMware-ESXi-5-x%E4%B8%BB%E6%9C%BA%E5%87%BA%E7%8E%B0%E6%8C%87%E7%A4%BA-E1000PollRxRing%E5%92%8CE1000DevRx%E7%9A%84%E7%B4%AB%E8%89%B2%E8%AF%8A%E6%96%AD%E5%B1%8F%E5%B9%95%EF%BC%88%E7%B4%AB%E5%B1%8F%EF%BC%89"><span class="toc-number">1.3.5.3.13.</span> <span class="toc-text">场景13：VMware ESXi 5.x主机出现指示 E1000PollRxRing和E1000DevRx的紫色诊断屏幕（紫屏）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF14%EF%BC%9A%E7%89%A9%E7%90%86CPU%E5%86%85%E9%83%A8%E7%9A%84%E4%BA%8C%E7%BA%A7Cache%E7%BC%93%E5%AD%98%E6%95%85%E9%9A%9C%E5%AF%BC%E8%87%B4VMware-ESXi%E4%B8%BB%E6%9C%BA%E5%89%8D%E5%90%8E%E5%A4%9A%E6%AC%A1%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.5.3.14.</span> <span class="toc-text">场景14：物理CPU内部的二级Cache缓存故障导致VMware ESXi主机前后多次紫屏问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF15%EF%BC%9A%E3%80%90RH2288H-V2%E3%80%91%E3%80%90VMware-5-5%E3%80%91Qle2562-HBA%E5%8D%A1%E6%95%85%E9%9A%9C%EF%BC%8C%E5%AF%BC%E8%87%B4VMware%E7%B3%BB%E7%BB%9F%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E5%AE%89%E8%A3%85%EF%BC%8C%E7%B3%BB%E7%BB%9F%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.5.3.15.</span> <span class="toc-text">场景15：【RH2288H V2】【VMware 5.5】Qle2562 HBA卡故障，导致VMware系统无法正常安装，系统紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF16%EF%BC%9AESXi5-1-E1000%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E5%86%85%E6%A0%B8bug%E5%AF%BC%E8%87%B4%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.5.3.16.</span> <span class="toc-text">场景16：ESXi5.1 E1000虚拟网卡内核bug导致紫屏问题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Vmkernel-amp-%E9%A9%B1%E5%8A%A8%E4%B8%BB%E5%8A%A8%E8%A7%A6%E5%8F%91%E7%9A%84%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.6.</span> <span class="toc-text">Vmkernel &amp;驱动主动触发的紫屏</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90-5"><span class="toc-number">1.3.6.1.</span> <span class="toc-text">原因分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E6%80%9D%E8%B7%AF-5"><span class="toc-number">1.3.6.2.</span> <span class="toc-text">定位思路</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%B4%AB%E5%B1%8F%E9%94%99%E8%AF%AF"><span class="toc-number">1.3.7.</span> <span class="toc-text">其他类型的紫屏错误</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E5%8F%B0%E8%AD%A6%E5%91%8A"><span class="toc-number">1.3.7.1.</span> <span class="toc-text">控制台警告</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%AD%E8%A8%80"><span class="toc-number">1.3.7.2.</span> <span class="toc-text">断言</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%AA%E6%89%A7%E8%A1%8C"><span class="toc-number">1.3.7.3.</span> <span class="toc-text">未执行</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%AC%E6%95%B0%E5%B7%B2%E8%B6%85%E5%87%BA-%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E6%AD%BB%E9%94%81"><span class="toc-number">1.3.7.4.</span> <span class="toc-text">转数已超出&#x2F;可能出现死锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%8E%AA%E6%96%BD-5"><span class="toc-number">1.3.7.5.</span> <span class="toc-text">解决措施</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF1%EF%BC%9A%E3%80%90CH121%E3%80%91%E3%80%90VMware-ESXi5-1%E3%80%91Heap%E5%86%85%E5%AD%98%E4%B8%8D%E8%B6%B3%E5%AF%BC%E8%87%B4VMware%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.7.5.1.</span> <span class="toc-text">场景1：【CH121】【VMware ESXi5.1】Heap内存不足导致VMware紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF2%EF%BC%9ARH2288H-V2%E6%9C%8D%E5%8A%A1%E5%99%A8VMware-5-5%E6%8A%A5Can-not-detect-the-last-level-cache%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.7.5.2.</span> <span class="toc-text">场景2：RH2288H V2服务器VMware 5.5报Can not detect the last level cache紫屏问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF3%EF%BC%9AVMware-5-x-ixgbe%E9%A9%B1%E5%8A%A8bug%E5%AF%BC%E8%87%B4%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.7.5.3.</span> <span class="toc-text">场景3：VMware 5.x ixgbe驱动bug导致紫屏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF4%EF%BC%9AE9000%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%A4%9A%E8%8A%82%E7%82%B9%E6%95%85%E9%9A%9C%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.7.5.4.</span> <span class="toc-text">场景4：E9000服务器多节点故障紫屏问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF5%EF%BC%9A%E5%AE%89%E8%A3%85%E5%8C%85%E6%8D%9F%E5%9D%8F%EF%BC%88Could-not-load-multiboot-modules-Bad-parameter%EF%BC%89"><span class="toc-number">1.3.7.5.5.</span> <span class="toc-text">场景5：安装包损坏（Could not load multiboot modules : Bad parameter）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF6%EF%BC%9ACH220-V3%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E8%A3%85VMware-ESXi-5-1-U2%E7%B4%AB%E5%B1%8F%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.7.5.6.</span> <span class="toc-text">场景6：CH220 V3服务器安装VMware ESXi 5.1 U2紫屏问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF7%EF%BC%9ARH2288-V3%E5%90%AF%E5%8A%A8EXSi%E7%B4%AB%E5%B1%8F"><span class="toc-number">1.3.7.5.7.</span> <span class="toc-text">场景7：RH2288 V3启动EXSi紫屏</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83KB"><span class="toc-number">1.3.8.</span> <span class="toc-text">参考KB</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/17566/" title="Mac中用到的SSH相关命令">Mac中用到的SSH相关命令</a><time datetime="2022-04-23T12:51:44.000Z" title="发表于 2022-04-23 20:51:44">2022-04-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/23200/" title="修改 VMware Fusion 中的虚机网络 IP 地址段">修改 VMware Fusion 中的虚机网络 IP 地址段</a><time datetime="2022-04-23T12:46:18.000Z" title="发表于 2022-04-23 20:46:18">2022-04-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/42673/" title="Photoshop2020默认快捷键整理（Mac版）">Photoshop2020默认快捷键整理（Mac版）</a><time datetime="2022-04-23T12:42:09.000Z" title="发表于 2022-04-23 20:42:09">2022-04-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/56602/" title="关于 NSX-T 下的 MTU（下）">关于 NSX-T 下的 MTU（下）</a><time datetime="2022-04-22T01:47:42.000Z" title="发表于 2022-04-22 09:47:42">2022-04-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/8475/" title="关于 NSX-T 下的 MTU（上）">关于 NSX-T 下的 MTU（上）</a><time datetime="2022-04-22T01:36:07.000Z" title="发表于 2022-04-22 09:36:07">2022-04-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By gaoshuai</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '86MGRvKe88fxFgDHAqjUQBbr-gzGzoHsz',
      appKey: 'NCmk6LfPzxxN4NPnVFQEQ75H',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
      requiredFields: ["nick,mail"],
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/hideCategory.min.js"></script> - <script src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/mouse_snow.min.js"></script> - <script src="/js/live2d.min.js"></script> - <script src="/js/waifu-tips.js"></script> - <script src="https://cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener toc scroll 
  window.removeEventListener('scroll', window.tocScrollFn)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"left","width":180,"height":360},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>