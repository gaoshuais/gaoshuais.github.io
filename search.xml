<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>centos K8S容器部署-flannel网络版</title>
      <link href="/posts/64295/"/>
      <url>/posts/64295/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="centos-K8S容器部署-flannel网络版"><a href="#centos-K8S容器部署-flannel网络版" class="headerlink" title="centos K8S容器部署-flannel网络版"></a>centos K8S容器部署-flannel网络版</h1><h2 id="环境介绍"><a href="#环境介绍" class="headerlink" title="环境介绍"></a>环境介绍</h2><ul><li>CentOS7（master、slave1、slave2）</li><li>Flannel</li><li>k8s v1.16.0</li></ul><h2 id="一、安装docker-ce-18-09-9（所有机器）"><a href="#一、安装docker-ce-18-09-9（所有机器）" class="headerlink" title="一、安装docker-ce 18.09.9（所有机器）"></a>一、安装docker-ce 18.09.9（所有机器）</h2><h3 id="1、安装docker所需的工具"><a href="#1、安装docker所需的工具" class="headerlink" title="1、安装docker所需的工具"></a>1、安装docker所需的工具</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928181810294-1604216665.png" class=""><img src="/posts/64295/2565133-20210928181812862-1369349082.png" class=""><img src="/posts/64295/2565133-20210928181816031-1561312110.png" class=""><h3 id="2、配置阿里云的docker源"><a href="#2、配置阿里云的docker源" class="headerlink" title="2、配置阿里云的docker源"></a>2、配置阿里云的docker源</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928181915726-327364604.png" class=""><img src="/posts/64295/2565133-20210928181919857-1383546528.png" class=""><img src="/posts/64295/2565133-20210928181924999-129488056.png" class=""><h3 id="3、安装docker-ce"><a href="#3、安装docker-ce" class="headerlink" title="3、安装docker-ce"></a>3、安装docker-ce</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y docker-ce-18.09.9-3.el7</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928182028457-631965367.png" class=""><img src="/posts/64295/2565133-20210928182035635-1850500130.png" class=""><img src="/posts/64295/2565133-20210928182042262-285490839.png" class=""><h3 id="4、启动docker"><a href="#4、启动docker" class="headerlink" title="4、启动docker"></a>4、启动docker</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928182114620-897172606.png" class=""><img src="/posts/64295/2565133-20210928182118794-524238308.png" class=""><img src="/posts/64295/2565133-20210928182134146-1167246181.png" class=""><h2 id="二、准备k8s环境（所有机器）"><a href="#二、准备k8s环境（所有机器）" class="headerlink" title="二、准备k8s环境（所有机器）"></a>二、准备k8s环境（所有机器）</h2><p>注:最低配置2核CPU和2g内存</p><h3 id="1、关闭防火墙"><a href="#1、关闭防火墙" class="headerlink" title="1、关闭防火墙"></a>1、关闭防火墙</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable firewalld</span><br><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928182323530-1607627468.png" class=""><img src="/posts/64295/2565133-20210928182329710-1506603806.png" class=""><img src="/posts/64295/2565133-20210928182334171-141086280.png" class=""><h3 id="2、关闭selinux"><a href="#2、关闭selinux" class="headerlink" title="2、关闭selinux"></a>2、关闭selinux</h3><h4 id="2-1临时禁用selinux"><a href="#2-1临时禁用selinux" class="headerlink" title="2.1临时禁用selinux"></a>2.1临时禁用selinux</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><h4 id="2-2永久关闭-修改-etc-sysconfig-selinux文件设置"><a href="#2-2永久关闭-修改-etc-sysconfig-selinux文件设置" class="headerlink" title="2.2永久关闭 修改/etc/sysconfig/selinux文件设置"></a>2.2永久关闭 修改/etc/sysconfig/selinux文件设置</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;s/SELINUX=permissive/SELINUX=disabled/&#x27; /etc/sysconfig/selinux</span><br><span class="line">sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928182451426-1321512877.png" class=""><img src="/posts/64295/2565133-20210928182457344-1824775324.png" class=""><img src="/posts/64295/2565133-20210928182502206-504883846.png" class=""><h3 id="3、禁用交换分区"><a href="#3、禁用交换分区" class="headerlink" title="3、禁用交换分区"></a>3、禁用交换分区</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br></pre></td></tr></table></figure><h3 id="4、永久禁用，打开-etc-fstab注释掉swap那一行"><a href="#4、永久禁用，打开-etc-fstab注释掉swap那一行" class="headerlink" title="4、永久禁用，打开/etc/fstab注释掉swap那一行"></a>4、永久禁用，打开/etc/fstab注释掉swap那一行</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928182604670-2144465252.png" class=""> <img src="/posts/64295/2565133-20210928182609241-1219701353.png" class=""><img src="/posts/64295/2565133-20210928182616893-1855567873.png" class=""><h3 id="5、修改内核参数"><a href="#5、修改内核参数" class="headerlink" title="5、修改内核参数"></a>5、修改内核参数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928182650601-1338349421.png" class=""><img src="/posts/64295/2565133-20210928182656479-614922006.png" class=""><img src="/posts/64295/2565133-20210928182713982-493023550.png" class=""><h3 id="6、查看刚才配置内核参数"><a href="#6、查看刚才配置内核参数" class="headerlink" title="6、查看刚才配置内核参数"></a>6、查看刚才配置内核参数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928182857729-23892830.png" class=""><img src="/posts/64295/2565133-20210928182907346-1930208220.png" class=""><img src="/posts/64295/2565133-20210928182915967-418437983.png" class=""><h2 id="三、安装k8s-v1-16-0-master管理节点安装kubeadm、kubelet、kubectl"><a href="#三、安装k8s-v1-16-0-master管理节点安装kubeadm、kubelet、kubectl" class="headerlink" title="三、安装k8s v1.16.0 master管理节点安装kubeadm、kubelet、kubectl"></a>三、安装k8s v1.16.0 master管理节点安装kubeadm、kubelet、kubectl</h2><h3 id="1、执行配置k8s阿里云源"><a href="#1、执行配置k8s阿里云源" class="headerlink" title="1、执行配置k8s阿里云源"></a>1、执行配置k8s阿里云源</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928182942148-1873405417.png" class=""><img src="/posts/64295/2565133-20210928182946027-545854077.png" class=""><img src="/posts/64295/2565133-20210928182953949-126924336.png" class=""><h3 id="2、安装kubeadm、kubectl、kubelet"><a href="#2、安装kubeadm、kubectl、kubelet" class="headerlink" title="2、安装kubeadm、kubectl、kubelet"></a>2、安装kubeadm、kubectl、kubelet</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kubectl-1.16.0-0 kubeadm-1.16.0-0 kubelet-1.16.0-0</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928183031704-1757000332.png" class=""><img src="/posts/64295/2565133-20210928183036921-1375402027.png" class=""><img src="/posts/64295/2565133-20210928183051616-1558703530.png" class=""><h3 id="3、启动kubelet服务"><a href="#3、启动kubelet服务" class="headerlink" title="3、启动kubelet服务"></a>3、启动kubelet服务</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928183124664-1736416278.png" class=""><img src="/posts/64295/2565133-20210928183129933-836240874.png" class=""><img src="/posts/64295/2565133-20210928183143661-1700994041.png" class=""><h3 id="4、初始化k8s下载管理节点中用到的6个docker镜像"><a href="#4、初始化k8s下载管理节点中用到的6个docker镜像" class="headerlink" title="4、初始化k8s下载管理节点中用到的6个docker镜像"></a>4、初始化k8s下载管理节点中用到的6个docker镜像</h3><p>注：使用docker images查看到</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.16.0 --apiserver-advertise-address  10.0.0.2  --pod-network-cidr=10.244.0.0/16 --token-ttl 0</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928183232464-1689466585.png" class=""><img src="/posts/64295/2565133-20210928183240634-1595701589.png" class=""><h3 id="5、建kubectl用户"><a href="#5、建kubectl用户" class="headerlink" title="5、建kubectl用户"></a>5、建kubectl用户</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g%&#125; $HOME/.kube/config</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928183309237-1670904272.png" class=""><h2 id="四、安装k8s-v1-16-0-slave工作节点安装kubeadm、kubelet"><a href="#四、安装k8s-v1-16-0-slave工作节点安装kubeadm、kubelet" class="headerlink" title="四、安装k8s v1.16.0 slave工作节点安装kubeadm、kubelet"></a>四、安装k8s v1.16.0 slave工作节点安装kubeadm、kubelet</h2><h3 id="1、执行配置k8s阿里云源-1"><a href="#1、执行配置k8s阿里云源-1" class="headerlink" title="1、执行配置k8s阿里云源"></a>1、执行配置k8s阿里云源</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928183407603-464368988.png" class=""><img src="/posts/64295/2565133-20210928183414641-1345540823.png" class=""><h3 id="2、启动kubelet服务"><a href="#2、启动kubelet服务" class="headerlink" title="2、启动kubelet服务"></a>2、启动kubelet服务</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928183514582-483020085.png" class=""><img src="/posts/64295/2565133-20210928183522741-803155554.png" class=""><h3 id="3、加入集群"><a href="#3、加入集群" class="headerlink" title="3、加入集群"></a>3、加入集群</h3><p>在master节点执行下面命令查看密钥</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928183623858-1719709437.png" class=""><img src="/posts/64295/2565133-20210928183637484-157271430.png" class=""><img src="/posts/64295/2565133-20210928183646073-1267625111.png" class=""><h3 id="4、去master节点执行下面命令验证节点已经加入"><a href="#4、去master节点执行下面命令验证节点已经加入" class="headerlink" title="4、去master节点执行下面命令验证节点已经加入"></a>4、去master节点执行下面命令验证节点已经加入</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928183711902-2096610056.png" class=""><h2 id="五、安装flannel网络"><a href="#五、安装flannel网络" class="headerlink" title="五、安装flannel网络"></a>五、安装flannel网络</h2><h3 id="1、创建kube-flannel-yml文件"><a href="#1、创建kube-flannel-yml文件" class="headerlink" title="1、创建kube-flannel.yml文件"></a>1、创建kube-flannel.yml文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: policy/v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: psp.flannel.unprivileged</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default</span><br><span class="line">    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default</span><br><span class="line">    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default</span><br><span class="line">spec:</span><br><span class="line">  privileged: false</span><br><span class="line">  volumes:</span><br><span class="line">  - configMap</span><br><span class="line">  - secret</span><br><span class="line">  - emptyDir</span><br><span class="line">  - hostPath</span><br><span class="line">  allowedHostPaths:</span><br><span class="line">  - pathPrefix: &quot;/etc/cni/net.d&quot;</span><br><span class="line">  - pathPrefix: &quot;/etc/kube-flannel&quot;</span><br><span class="line">  - pathPrefix: &quot;/run/flannel&quot;</span><br><span class="line">  readOnlyRootFilesystem: false</span><br><span class="line">  # Users and groups</span><br><span class="line">  runAsUser:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  fsGroup:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  # Privilege Escalation</span><br><span class="line">  allowPrivilegeEscalation: false</span><br><span class="line">  defaultAllowPrivilegeEscalation: false</span><br><span class="line">  # Capabilities</span><br><span class="line">  allowedCapabilities: [&#x27;NET_ADMIN&#x27;, &#x27;NET_RAW&#x27;]</span><br><span class="line">  defaultAddCapabilities: []</span><br><span class="line">  requiredDropCapabilities: []</span><br><span class="line">  # Host namespaces</span><br><span class="line">  hostPID: false</span><br><span class="line">  hostIPC: false</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  hostPorts:</span><br><span class="line">  - min: 0</span><br><span class="line">    max: 65535</span><br><span class="line">  # SELinux</span><br><span class="line">  seLinux:</span><br><span class="line">    # SELinux is unused in CaaSP</span><br><span class="line">    rule: &#x27;RunAsAny&#x27;</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&#x27;extensions&#x27;]</span><br><span class="line">  resources: [&#x27;podsecuritypolicies&#x27;]</span><br><span class="line">  verbs: [&#x27;use&#x27;]</span><br><span class="line">  resourceNames: [&#x27;psp.flannel.unprivileged&#x27;]</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - nodes</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - nodes/status</span><br><span class="line">  verbs:</span><br><span class="line">  - patch</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: flannel</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: flannel</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-cfg</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">data:</span><br><span class="line">  cni-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;cbr0&quot;,</span><br><span class="line">      &quot;cniVersion&quot;: &quot;0.3.1&quot;,</span><br><span class="line">      &quot;plugins&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;type&quot;: &quot;flannel&quot;,</span><br><span class="line">          &quot;delegate&quot;: &#123;</span><br><span class="line">            &quot;hairpinMode&quot;: true,</span><br><span class="line">            &quot;isDefaultGateway&quot;: true</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;type&quot;: &quot;portmap&quot;,</span><br><span class="line">          &quot;capabilities&quot;: &#123;</span><br><span class="line">            &quot;portMappings&quot;: true</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  net-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;Network&quot;: &quot;10.244.0.0/16&quot;,</span><br><span class="line">      &quot;Backend&quot;: &#123;</span><br><span class="line">        &quot;Type&quot;: &quot;vxlan&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-ds</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: flannel</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        tier: node</span><br><span class="line">        app: flannel</span><br><span class="line">    spec:</span><br><span class="line">      affinity:</span><br><span class="line">        nodeAffinity:</span><br><span class="line">          requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">            nodeSelectorTerms:</span><br><span class="line">            - matchExpressions:</span><br><span class="line">              - key: kubernetes.io/os</span><br><span class="line">                operator: In</span><br><span class="line">                values:</span><br><span class="line">                - linux</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      priorityClassName: system-node-critical</span><br><span class="line">      tolerations:</span><br><span class="line">      - operator: Exists</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      serviceAccountName: flannel</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: install-cni</span><br><span class="line">        image: quay.io/coreos/flannel:v0.14.0</span><br><span class="line">        command:</span><br><span class="line">        - cp</span><br><span class="line">        args:</span><br><span class="line">        - -f</span><br><span class="line">        - /etc/kube-flannel/cni-conf.json</span><br><span class="line">        - /etc/cni/net.d/10-flannel.conflist</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cni</span><br><span class="line">          mountPath: /etc/cni/net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: /etc/kube-flannel/</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">        image: quay.io/coreos/flannel:v0.14.0</span><br><span class="line">        command:</span><br><span class="line">        - /opt/bin/flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">          limits:</span><br><span class="line">            cpu: &quot;100m&quot;</span><br><span class="line">            memory: &quot;50Mi&quot;</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add: [&quot;NET_ADMIN&quot;, &quot;NET_RAW&quot;]</span><br><span class="line">        env:</span><br><span class="line">        - name: POD_NAME</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.name</span><br><span class="line">        - name: POD_NAMESPACE</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: run</span><br><span class="line">          mountPath: /run/flannel</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: /etc/kube-flannel/</span><br><span class="line">      volumes:</span><br><span class="line">      - name: run</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /run/flannel</span><br><span class="line">      - name: cni</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /etc/cni/net.d</span><br><span class="line">      - name: flannel-cfg</span><br><span class="line">        configMap:</span><br><span class="line">          name: kube-flannel-cfg</span><br></pre></td></tr></table></figure><h3 id="2、创建kube-flannel网络"><a href="#2、创建kube-flannel网络" class="headerlink" title="2、创建kube-flannel网络"></a>2、创建kube-flannel网络</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f kube-flannel.yml</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928183808687-1475049573.png" class=""><h2 id="六、安装dashboard"><a href="#六、安装dashboard" class="headerlink" title="六、安装dashboard"></a>六、安装dashboard</h2><h3 id="1、创建recommended-yml-文件"><a href="#1、创建recommended-yml-文件" class="headerlink" title="1、创建recommended.yml 文件"></a>1、创建recommended.yml 文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br></pre></td><td class="code"><pre><span class="line"># Copyright 2017 The Kubernetes Authors.</span><br><span class="line">#</span><br><span class="line"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line"># you may not use this file except in compliance with the License.</span><br><span class="line"># You may obtain a copy of the License at</span><br><span class="line">#</span><br><span class="line">#     http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line">#</span><br><span class="line"># Unless required by applicable law or agreed to in writing, software</span><br><span class="line"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"># See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      nodePort: 30001</span><br><span class="line">      targetPort: 8443</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-certs</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">type: Opaque</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-csrf</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">type: Opaque</span><br><span class="line">data:</span><br><span class="line">  csrf: &quot;&quot;</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-key-holder</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">type: Opaque</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-settings</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">rules:</span><br><span class="line">  # Allow Dashboard to get, update and delete Dashboard exclusive secrets.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;secrets&quot;]</span><br><span class="line">    resourceNames: [&quot;kubernetes-dashboard-key-holder&quot;, &quot;kubernetes-dashboard-certs&quot;, &quot;kubernetes-dashboard-csrf&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;update&quot;, &quot;delete&quot;]</span><br><span class="line">    # Allow Dashboard to get and update &#x27;kubernetes-dashboard-settings&#x27; config map.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;configmaps&quot;]</span><br><span class="line">    resourceNames: [&quot;kubernetes-dashboard-settings&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;update&quot;]</span><br><span class="line">    # Allow Dashboard to get metrics.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;services&quot;]</span><br><span class="line">    resourceNames: [&quot;heapster&quot;, &quot;dashboard-metrics-scraper&quot;]</span><br><span class="line">    verbs: [&quot;proxy&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;services/proxy&quot;]</span><br><span class="line">    resourceNames: [&quot;heapster&quot;, &quot;http:heapster:&quot;, &quot;https:heapster:&quot;, &quot;dashboard-metrics-scraper&quot;, &quot;http:dashboard-metrics-scraper&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">rules:</span><br><span class="line">  # Allow Metrics Scraper to get metrics from the Metrics server</span><br><span class="line">  - apiGroups: [&quot;metrics.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;pods&quot;, &quot;nodes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: kubernetes-dashboard</span><br><span class="line">    namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: kubernetes-dashboard</span><br><span class="line">    namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kubernetes-dashboard</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kubernetes-dashboard</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: kubernetes-dashboard</span><br><span class="line">          image: kubernetesui/dashboard:v2.3.1</span><br><span class="line">          imagePullPolicy: Always</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8443</span><br><span class="line">              protocol: TCP</span><br><span class="line">          args:</span><br><span class="line">            - --auto-generate-certificates</span><br><span class="line">            - --namespace=kubernetes-dashboard</span><br><span class="line">            # Uncomment the following line to manually specify Kubernetes API server Host</span><br><span class="line">            # If not specified, Dashboard will attempt to auto discover the API server and connect</span><br><span class="line">            # to it. Uncomment only if the default does not work.</span><br><span class="line">            # - --apiserver-host=http://my-address:port</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: kubernetes-dashboard-certs</span><br><span class="line">              mountPath: /certs</span><br><span class="line">              # Create on-disk volume to store exec logs</span><br><span class="line">            - mountPath: /tmp</span><br><span class="line">              name: tmp-volume</span><br><span class="line">          livenessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              scheme: HTTPS</span><br><span class="line">              path: /</span><br><span class="line">              port: 8443</span><br><span class="line">            initialDelaySeconds: 30</span><br><span class="line">            timeoutSeconds: 30</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">            readOnlyRootFilesystem: true</span><br><span class="line">            runAsUser: 1001</span><br><span class="line">            runAsGroup: 2001</span><br><span class="line">      volumes:</span><br><span class="line">        - name: kubernetes-dashboard-certs</span><br><span class="line">          secret:</span><br><span class="line">            secretName: kubernetes-dashboard-certs</span><br><span class="line">        - name: tmp-volume</span><br><span class="line">          emptyDir: &#123;&#125;</span><br><span class="line">      serviceAccountName: kubernetes-dashboard</span><br><span class="line">      nodeSelector:</span><br><span class="line">        &quot;kubernetes.io/os&quot;: linux</span><br><span class="line">      # Comment the following tolerations if Dashboard must not be deployed on master</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: node-role.kubernetes.io/master</span><br><span class="line">          effect: NoSchedule</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: dashboard-metrics-scraper</span><br><span class="line">  name: dashboard-metrics-scraper</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8000</span><br><span class="line">      targetPort: 8000</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: dashboard-metrics-scraper</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: dashboard-metrics-scraper</span><br><span class="line">  name: dashboard-metrics-scraper</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: dashboard-metrics-scraper</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: dashboard-metrics-scraper</span><br><span class="line">      annotations:</span><br><span class="line">        seccomp.security.alpha.kubernetes.io/pod: &#x27;runtime/default&#x27;</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: dashboard-metrics-scraper</span><br><span class="line">          image: kubernetesui/metrics-scraper:v1.0.6</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8000</span><br><span class="line">              protocol: TCP</span><br><span class="line">          livenessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              scheme: HTTP</span><br><span class="line">              path: /</span><br><span class="line">              port: 8000</span><br><span class="line">            initialDelaySeconds: 30</span><br><span class="line">            timeoutSeconds: 30</span><br><span class="line">          volumeMounts:</span><br><span class="line">          - mountPath: /tmp</span><br><span class="line">            name: tmp-volume</span><br><span class="line">          securityContext:</span><br><span class="line">            allowPrivilegeEscalation: false</span><br><span class="line">            readOnlyRootFilesystem: true</span><br><span class="line">            runAsUser: 1001</span><br><span class="line">            runAsGroup: 2001</span><br><span class="line">      serviceAccountName: kubernetes-dashboard</span><br><span class="line">      nodeSelector:</span><br><span class="line">        &quot;kubernetes.io/os&quot;: linux</span><br><span class="line">      # Comment the following tolerations if Dashboard must not be deployed on master</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: node-role.kubernetes.io/master</span><br><span class="line">          effect: NoSchedule</span><br><span class="line">      volumes:</span><br><span class="line">        - name: tmp-volume</span><br><span class="line">          emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure><h3 id="2、安装recommended服务"><a href="#2、安装recommended服务" class="headerlink" title="2、安装recommended服务"></a>2、安装recommended服务</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f recommended.yml</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928184016271-1470694532.png" class=""><h3 id="3、生成dashboard登陆的token"><a href="#3、生成dashboard登陆的token" class="headerlink" title="3、生成dashboard登陆的token"></a>3、生成dashboard登陆的token</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl create serviceaccount dashboard-admin -n kube-system</span><br><span class="line">kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin</span><br><span class="line">kubectl get secret -n kube-system</span><br><span class="line"># 找到dashboard-admin-token-6b9gf</span><br><span class="line">kubectl describe secret  dashboard-admin-token-6b9gf  -n kube-system</span><br></pre></td></tr></table></figure><img src="/posts/64295/2565133-20210928184050377-1485047104.png" class=""><img src="/posts/64295/2565133-20210928184103765-51086153.png" class=""><h2 id="七、登录Kubernetes-Dashboard窗体顶端"><a href="#七、登录Kubernetes-Dashboard窗体顶端" class="headerlink" title="七、登录Kubernetes Dashboard窗体顶端"></a>七、登录Kubernetes Dashboard窗体顶端</h2><img src="/posts/64295/2565133-20210928184117060-702515631.png" class="">]]></content>
      
      
      
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> K8S </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac中用到的SSH相关命令</title>
      <link href="/posts/17566/"/>
      <url>/posts/17566/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="Mac中用到的SSH相关命令"><a href="#Mac中用到的SSH相关命令" class="headerlink" title="Mac中用到的SSH相关命令"></a>Mac中用到的SSH相关命令</h1><ul><li>SSH相关</li></ul><p>登录SSH服务器</p><p>ssh username@ip -p 端口</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh userName@192.168.1.1 -p 123</span><br></pre></td></tr></table></figure><p>直接复制SSH服务器上的数据到本地</p><ul><li>SCP远程文件操作</li></ul><p>scp [可选参数] file_source file_target</p><p>从本地复制文件到远程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scp local_file remote_username@remote_ip:remote_folder </span><br><span class="line">或者 </span><br><span class="line">scp local_file remote_username@remote_ip:remote_file </span><br><span class="line">或者 </span><br><span class="line">scp local_file remote_ip:remote_folder </span><br><span class="line">或者 </span><br><span class="line">scp local_file remote_ip:remote_file </span><br></pre></td></tr></table></figure><p> 复制目录命令格式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r local_folder remote_username@remote_ip:remote_folder </span><br><span class="line">或者 </span><br><span class="line">scp -r local_folder remote_ip:remote_folder </span><br></pre></td></tr></table></figure><p>本地复制到远程的例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//复制文件</span><br><span class="line">scp /home/space/music/1.mp3 root@www.runoob.com:/home/root/others/music </span><br><span class="line">scp /home/space/music/1.mp3 root@www.runoob.com:/home/root/others/music/001.mp3</span><br><span class="line"></span><br><span class="line">//复制目录</span><br><span class="line">scp -r /home/space/music/ root@www.runoob.com:/home/root/others/ </span><br></pre></td></tr></table></figure><p>远程复制文件到本地示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//复制单个文件</span><br><span class="line">scp root@www.runoob.com:/home/root/others/music /home/space/music/1.mp3 </span><br><span class="line"></span><br><span class="line">//复制目录</span><br><span class="line">scp -r www.runoob.com:/home/root/others/ /home/space/music/</span><br></pre></td></tr></table></figure><p>如果远程服务器防火墙有为scp命令设置了指定的端口，我们需要使用 -P 参数来设置命令的端口号，命令格式如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -P 4588 remote@www.runoob.com:/usr/local/sin.sh /home/administrator</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> SSH </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>修改 VMware Fusion 中的虚机网络 IP 地址段</title>
      <link href="/posts/23200/"/>
      <url>/posts/23200/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="修改-VMware-Fusion-中的虚机网络-IP-地址段"><a href="#修改-VMware-Fusion-中的虚机网络-IP-地址段" class="headerlink" title="修改 VMware Fusion 中的虚机网络 IP 地址段"></a>修改 VMware Fusion 中的虚机网络 IP 地址段</h1><h2 id="一、了解-VMware-Fusion-中的网络类型"><a href="#一、了解-VMware-Fusion-中的网络类型" class="headerlink" title="一、了解 VMware Fusion 中的网络类型"></a>一、了解 VMware Fusion 中的网络类型</h2><p>可用于虚拟机的网络类型有三种。每种网络类型都由其自身用途、行为和功能。</p><p>注意：使用错误的网络类型或配置设置可能会导致出现不良行为。</p><h3 id="桥接模式网络连接"><a href="#桥接模式网络连接" class="headerlink" title="桥接模式网络连接"></a>桥接模式网络连接</h3><p>　　如果您的 Mac 位于以太网、无线网或 FireWire 网络中，则使用桥接网络连接通常是使您的虚拟机可以访问该网络的最简单方法。使用桥接网络连接，虚拟机将显示为与 Mac 相同的物理以太网网络中的其他计算机。</p><p>　　使用桥接网络连接的虚拟机可能会使用在该虚拟机桥接到的网络上提供的任何服务，其中包括文件服务器、打印机和网关。同样，配置有桥接网络连接的任意物理主机或其他虚拟机可以使用虚拟机上的资源，就好像该虚拟机是同一个网络中的物理计算机。</p><p>　　桥接网络适配器称为 vmnet0。在 Fusion 3.x 及更高版本中，该适配器使用 vmnet-bridge 和 vmnet-netifup 服务。</p><h3 id="仅主机型网络-–-vmnet1"><a href="#仅主机型网络-–-vmnet1" class="headerlink" title="仅主机型网络 – vmnet1"></a>仅主机型网络 – vmnet1</h3><p>　　当使用此类型的网络连接时，虚拟机将连接到虚拟专用网络中的 Mac，这在 Mac 以外通常不可见。在同一个 Mac 中配置有仅主机网络的多个虚拟机将位于同一个网络中，并且互相可见。</p><p>　　仅主机网络适配器称为 vmnet1。在 Fusion 3.x 及更高版本中，该适配器使用 vmnet-dhcpd 服务。</p><h3 id="网络地址转换-NAT-网络-–-vmnet8"><a href="#网络地址转换-NAT-网络-–-vmnet8" class="headerlink" title="网络地址转换 (NAT) 网络 – vmnet8"></a>网络地址转换 (NAT) 网络 – vmnet8</h3><p>　　如果要使用 Mac 拨号网络连接的方法将虚拟机连接到 Internet 或其他 TCP/IP 网络，或者无法向虚拟机提供 Mac 的网络中的 IP 地址，则此类型通常是使您的虚拟机可以访问网络的最简单方法。此类型还允许虚拟机访问 Mac 已连接到的 VPN。</p><p>　　虚拟机在外部网络中没有自己的 IP 地址。相反，会在 Mac 中设置单独的专用网络。虚拟机从 VMware 虚拟 DHCP 服务器中获取该网络上的地址。除非虚拟机启动连接，否则无法直接通过除 Mac 以外的任意计算机或网站连接该虚拟机。</p><p>　　NAT 网络适配器称为 vmnet8。在 Fusion 3.x 及更高版本中，该适配器使用 vmnet-natd、vmnet-dhcpd 和 vmnet-netifup 服务。</p><h2 id="二、自定义网络-IP-地址段"><a href="#二、自定义网络-IP-地址段" class="headerlink" title="二、自定义网络 IP 地址段"></a>二、自定义网络 IP 地址段</h2><p>　　VMware Fusion 有三个网络配置文件：networking、dhcpd.conf 和 nat.conf。</p><p>全局：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Library/Preferences/VMware\ Fusion/networking</span><br></pre></td></tr></table></figure><p>vmnet1：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Library/Preferences/VMware\ Fusion/vmnet1/dhcpd.conf</span><br></pre></td></tr></table></figure><p>vmnet8：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/Library/Preferences/VMware\ Fusion/vmnet8/dhcpd.conf</span><br><span class="line">/Library/Preferences/VMware\ Fusion/vmnet8/nat.conf</span><br></pre></td></tr></table></figure><blockquote><p>本文仅以修改默认网络为例，也可以在新建网络进行自定义：“VMware Fusion” &gt; “偏好设置…” &gt; “网络” &gt; “+”，默认第一个自定义网络名称为 <code>vmnet2</code> 对应配置文件位于 <code>/Library/Preferences/VMware\Fusion/vmnet2/</code> 下。</p></blockquote><p>修改 IP 地址段步骤如下：</p><blockquote><p>本文写作时，在 VMware Fusion 11.5 版本中测试通过，现在同样适用于版本 12 系列。</p></blockquote><h3 id="1-停止-vmnet-网络服务"><a href="#1-停止-vmnet-网络服务" class="headerlink" title="1. 停止 vmnet 网络服务"></a>1. 停止 vmnet 网络服务</h3><p>执行命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /Applications/VMware\ Fusion.app/Contents/Library/vmnet-cli --stop</span><br></pre></td></tr></table></figure><p>备注：这步是可选的，直接下一步也可以。</p><h3 id="2-只需要修改-networking-配置文件"><a href="#2-只需要修改-networking-配置文件" class="headerlink" title="2. 只需要修改 networking 配置文件"></a>2. 只需要修改 networking 配置文件</h3><p>执行命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /Library/Preferences/VMware\ Fusion/networking</span><br></pre></td></tr></table></figure><p>示例：将 vmnet1 中的 IP 段修改为 192.168.1.0，将 vmnet8 中的 IP 段修改为 10.10.1.0</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">VERSION=1,0</span><br><span class="line">answer VNET_1_DHCP yes</span><br><span class="line">answer VNET_1_DHCP_CFG_HASH 305D3393C78096F94C8C979DF2321B14BEE94AB1</span><br><span class="line">answer VNET_1_HOSTONLY_NETMASK 255.255.255.0</span><br><span class="line">answer VNET_1_HOSTONLY_SUBNET 172.16.178.0  # 修改为 192.168.1.0</span><br><span class="line">answer VNET_1_VIRTUAL_ADAPTER yes</span><br><span class="line">answer VNET_8_DHCP yes</span><br><span class="line">answer VNET_8_DHCP_CFG_HASH DE662EAB01380DE3338128A859C717A8F863F3CF</span><br><span class="line">answer VNET_8_HOSTONLY_NETMASK 255.255.255.0</span><br><span class="line">answer VNET_8_HOSTONLY_SUBNET 172.16.24.0  # 修改为 10.10.1.0</span><br><span class="line">answer VNET_8_NAT yes</span><br><span class="line">answer VNET_8_VIRTUAL_ADAPTER yes</span><br></pre></td></tr></table></figure><blockquote><p>默认 IP 地址段因版本差异有所不同。</p></blockquote><h3 id="3-配置网络"><a href="#3-配置网络" class="headerlink" title="3. 配置网络"></a>3. 配置网络</h3><p>执行命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /Applications/VMware\ Fusion.app/Contents/Library/vmnet-cli --configure</span><br></pre></td></tr></table></figure><p>vmnet-cli 将根据上述修改的地址段自动修改 dhcpd.conf 和 nat.conf 中的 IP 地址。</p><p>查看 dhcpd.conf 和 nat.conf 配置文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat /Library/Preferences/VMware\ Fusion/vmnet1/dhcpd.conf</span><br><span class="line">cat /Library/Preferences/VMware\ Fusion/vmnet1/nat.conf</span><br><span class="line"></span><br><span class="line">cat /Library/Preferences/VMware\ Fusion/vmnet8/dhcpd.conf</span><br><span class="line">cat /Library/Preferences/VMware\ Fusion/vmnet8/nat.conf</span><br></pre></td></tr></table></figure><p>可以看到配置已经修改成功。</p><blockquote><p>NAT 网关的 IP 为 x.x.x.2，定义在 <code>/Library/Preferences/VMware\ Fusion/vmnet8/nat.conf</code> 配置文件中。</p><p>Fusion 12.0 开始 NAT 网关的 IP 变更为 x.x.x.1，更加符合使用习惯。</p><p>经过测试 Fusion 12.1 NAT 网关 IP 同样为 x.x.x.1，但是比较遗憾，Fusion 12.2 又修改为 .2。这降导致 12.0 和 12.1 配置的 VM 无法访问外部网络，注意编辑该配置文件恢复为 .1。</p></blockquote><h3 id="4-启动网络服务"><a href="#4-启动网络服务" class="headerlink" title="4. 启动网络服务"></a>4. 启动网络服务</h3><p>执行命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /Applications/VMware\ Fusion.app/Contents/Library/vmnet-cli --start</span><br></pre></td></tr></table></figure><h3 id="5-验证"><a href="#5-验证" class="headerlink" title="5. 验证"></a>5. 验证</h3><p>执行命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig</span><br></pre></td></tr></table></figure><p>可以看到 vmnet1 和 vmnet8 的 IP 地址已经更改成功。</p><h3 id="6-虚拟机重新获取配置"><a href="#6-虚拟机重新获取配置" class="headerlink" title="6. 虚拟机重新获取配置"></a>6. 虚拟机重新获取配置</h3><p>虚机如果是手动配置的 IP，直接修改即可。</p><p>虚机如果是 DHCP，可以直接重启 vmware fusion 和 虚机系统，也可以直接在虚机重新获取地址，比如 Linux 命令行中执行 <code>sudo dhclient -v -r eth0</code> ，eth0 为对应网卡。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> VMware </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Photoshop2020默认快捷键整理（Mac版）</title>
      <link href="/posts/42673/"/>
      <url>/posts/42673/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="Photoshop2020默认快捷键整理（Mac版）"><a href="#Photoshop2020默认快捷键整理（Mac版）" class="headerlink" title="Photoshop2020默认快捷键整理（Mac版）"></a>Photoshop2020默认快捷键整理（Mac版）</h1><p>操作工具</p><img src="/posts/42673/2565133-20211026101033653-848200788.png" class=""><p> 面板菜单</p><img src="/posts/42673/2565133-20211026101149741-1709776956.png" class=""><p>应用程序菜单</p><img src="/posts/42673/2565133-20211026101228667-2026551219.png" class="">]]></content>
      
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> Photoshop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于 NSX-T 下的 MTU（下）</title>
      <link href="/posts/56602/"/>
      <url>/posts/56602/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="关于-NSX-T-下的-MTU（下）"><a href="#关于-NSX-T-下的-MTU（下）" class="headerlink" title="关于 NSX-T 下的 MTU（下）"></a>关于 NSX-T 下的 MTU（下）</h1><p>原创 Spark go nsx很可爱的</p><p>在实施 NSX-v 或者 NSX-T 的项目时，经常听到一个词：MTU，本文着重讲讲为什么 MTU 在 NSX 环境中如此重要，如何根据不同的设计来配置/验证 MTU 等等，本文适合先收藏，后转发。</p><p>本文目录如下：</p><p>上篇：</p><ul><li>如果在 NSX 环境下 MTU 设置不正确会有什么现象？</li><li>如何验证 MTU 设置是否正确？</li><li>在 NSX-T 环境下如何设置 MTU？</li></ul><p>下篇：</p><ul><li>为什么 NSX 环境中 MTU 如此重要？有没有 workaround？</li><li>NSX 多中心架构下对于 MTU 的优化</li></ul><h2 id="为什么-NSX-环境中-MTU-如此重要？有没有-workaround？"><a href="#为什么-NSX-环境中-MTU-如此重要？有没有-workaround？" class="headerlink" title="为什么 NSX 环境中 MTU 如此重要？有没有 workaround？"></a>为什么 NSX 环境中 MTU 如此重要？有没有 workaround？</h2><p>NSX 是一种 Overlay 网络，其原理就是在已有的物理网络上构建一层虚拟的网络，为了实现虚拟网络和物理网络的解耦，需要用到一种封装协议，NSX-V 使用 vxlan，NSX-T 使用 Geneve，无论哪种，其原理都是在虚拟机的原始报文上再加一个新的包头。</p><img src="/posts/56602/640.png" class=""><p>这就导致，原始虚拟机发出的 IP 报文大小为 1500，经过封装后的报文可能变成了 1550 甚至更大。</p><p>注：1550 = （原始 IP 报文 1500 +虚拟机以太网包头 14 bytes + Geneve Header 8 bytes + UDP header 8 bytes + TEP IP header 20 bytes）。</p><p>为了避免封装后的包被底层物理网络丢弃，需要将底层网络的 MTU 调整为 ≥1600。</p><p>在 NSX-T 下，虚拟机跨主机通信的流量示意图如下：</p><img src="/posts/56602/641.png" class=""><h3 id="关于-MTU"><a href="#关于-MTU" class="headerlink" title="关于 MTU"></a>关于 MTU</h3><p>MTU 全称为 Maximum Transmission Unit，在以太网中表示数据链路层允许通过的最大 IP 报文大小。一般常见的网络设备 MTU 默认均为 1500 字节。</p><p>关于 MTU 有个形象的比喻：</p><p>如果把 IP 报文形容成<strong>货车</strong>，MTU 就等于沿途所有隧道、桥梁、高速路的<strong>限高</strong>。只要货车的高度在所有线路上都低于限高，那么货车就能顺利抵达目的地。无论沿途线路限高是多少，都不会改变货车的高度。</p><p>在 IP 网络中，MTU 就是一个<strong>当前节点的限制</strong>。虚拟机发出的 IP 包为 1500 bytes，NSX 封装后变成 &gt;1550 bytes，为了避免封装后的包被丢弃，最简单的办法就是<strong>提高沿途所有设备的 MTU</strong>。</p><h3 id="有没有-Workaround？"><a href="#有没有-Workaround？" class="headerlink" title="有没有 Workaround？"></a>有没有 Workaround？</h3><p>聪明的你可能想到，如果从源头出发，让虚拟机一开始发出的报文就比标准的 1500 小，这样不就不需要更改沿途设备的 MTU？</p><p>答案是：或许可以，但不建议。</p><p>以一个 NSX 环境下普通的 TCP 通信为例，Client 与 NSX 中的 VM 通信过程如下：</p><p>在 TCP 三次握手时，相互会通告自己的 TCP Maximum Segment Size（MSS），这个 MSS=(接口 MTU)-(IP 包头)-(TCP 包头)，一般 MTU=1500 时，MSS 为 1460。建立 TCP 连接的双方会取最小值来进行后续数据包的传输。</p><img src="/posts/56602/642.png" class=""><img src="/posts/56602/643.png" class=""><p>后续 VM 和 Client 通信的 IP 包大小为 1500，加上 Geneve 封装后的 IP 包变成 1558 bytes。这是一个正常 NSX 环境下预期的结果：</p><img src="/posts/56602/644.png" class=""><p>如果我们把虚拟机的网卡 MTU 调整成 1400：</p><img src="/posts/56602/645.png" class=""><p>再次进行 TCP 访问抓包，结果如下：</p><p>Client 发给 VM 的 MSS 依然是 1460：</p><img src="/posts/56602/646.png" class=""><p>VM 发给 Client 的 MSS 变成了 1360：</p><img src="/posts/56602/647.png" class=""><p><strong>最终 VM 和 Client 通信时的包都会等于 1400</strong>，<strong>经过 Geneve 封装后的 IP 报文变成了 1458，小于标准的 1500。</strong></p><img src="/posts/56602/648.png" class=""><p>综上：如果在 NSX 环境下使用 TCP 协议，沿途设备的 MTU 不能更改，那么将虚拟机网卡的 MTU 调整为 1400 可以避开 NSX MTU 问题。这样做的缺点是：每台在 NSX 环境中的虚拟机都得改网卡 MTU，工作量比较大，有些操作系统可能还不支持更改 MTU。</p><p>而 UDP 包的情况则复杂一些。</p><p>UDP 是一个不可靠的协议，UDP 并不管上层应用发了多大的包，只管封装 UDP 包头丢给网络层。对端能不能成功收到数据 UDP 并不管，要靠上层应用来保证。</p><p>图源：网络</p><img src="/posts/56602/649.png" class=""><p>当环境中 MTU 出现不一致时，很可能源端成功发送，但目标端未成功接收。</p><p>例如 VM MTU 设置为 1400，Client MTU 使用默认的 1500 时：</p><ul><li>VM 给 Client 发送 UDP 包时，IP 包大小为 1400，Client 可以正常接收；</li><li>但 Client 给 VM 发送 UDP 包时，IP 包大小为 1500，大于 VM 的 MTU，VM 无法接收 UDP 包。</li></ul><p>因此如果要使用 UDP 通信，应用侧要有手段来避开底层可能存在的差异。</p><p>可能的方法有：</p><ul><li>应用在发包时使用较小的报文，使得最终 IP 包远小于 1500。比如 Horizon 的 PCoIP 协议默认 Session MTU 为 1300 bytes；</li><li>使用 Path MTU Discovery 技术来发现路径中支持的最大 MTU，应用在后期传输数据时，限制包的大小（参考：RFC 8899 及 RFC 4821）；</li><li>应用通过自己的方式来确定可以发送的包大小。比如 iperf 3.1.5 开始就能自动通过 TCP 先协商出包大小，再进行 UDP 传输（对于 iperf 来说通过这种方式实现最简单，因为 iperf 的控制平面始终会使用 tcp 连接）。</li></ul><p>下图为 iperf3 自动协商 UDP 包大小的截图： </p><img src="/posts/56602/650.png" class=""><p>综上：如果在 NSX 环境下使用 UDP 协议，沿途设备的 MTU 不能更改，这时候即使改小了 VM 的 MTU，也不一定能保证 Client 到 VM 可以顺利通信，要视业务而定。</p><h3 id="有没有其他-Workaround？"><a href="#有没有其他-Workaround？" class="headerlink" title="有没有其他 Workaround？"></a>有没有其他 Workaround？</h3><p>之前和一些客户讨论 NSX MTU 问题时，会经常被问到：封装完的包如果过大时不应该会自动分片吗？</p><p>要回答这个问题，得去先了解什么情况下会出现分片，谁来执行分片。</p><p>默认情况下，如果应用层发了一个大包到传输层，TCP 会自动切分成小包再发给网络层，UDP 则直接封包丢给网络层。因此源端发送 TCP 报文时一般不会出现 IP 分片，源端发送 UDP 报文时则可能出现 <strong>IP 分片</strong>。</p><p>比如 iperf 3.1.3 及更老的版本下默认发出的包为 8192 字节，当发出后就会被底层切成很多块发送，每个 IP 包的大小 ≤ 1500 字节。</p><p><img src="https://img2020.cnblogs.com/blog/2565133/202110/2565133-20211011100548849-1596279974.gif" alt="图片"></p><p>数据包一旦从源端网卡发送出来，<strong>沿途的设备通常不会更改这个包的</strong>，如果包大小满足当前节点的 MTU 配置，包可以被正常转发；如果包大小不满足当前节点的 MTU 配置，包被丢弃。</p><p>但这里有个例外，那就是 <strong>IP 包头中的 DF 位 = 0 时，沿途的路由器（三层设备）会执行 IP 分片</strong>。当 DF 位 = 0 时，表示该 IP 包可以被分片，沿途三层设备如果发现收到的包大于自己的 L3 MTU 设置，就会根据自己的 L3 MTU 设置来进行分片然后发送，目标端收到所有报文后进行重组。</p><p>图源：Wikipedia</p><img src="/posts/56602/651.png" class=""><p>以上便是两种会分片的情况，现实中两种情况都很少遇到，上个章节中已经提到，通常 TCP 会自行协商包大小，UDP 协议下也有多种方式来尽量避开发送过大的包。</p><p>其实虽然存在 IP 分片这种技术，但并不建议使用，因为分片会存在下列问题：</p><ul><li>传输的报文数量增大，降低传输性能；</li><li>对于 TCP 这类可靠协议，如果一个 IP 分片丢失，一个会话的所有 TCP segment 都要重传，效率降低；</li><li>IP 分片存在脆弱性，不应该被使用（详见：<a href="https://tools.ietf.org/id/draft-ietf-intarea-frag-fragile-14.html#rfc.section.3%EF%BC%89">https://tools.ietf.org/id/draft-ietf-intarea-frag-fragile-14.html#rfc.section.3）</a></li></ul><p>再回到 NSX 环境，NSX 的工作原理和传统的二三层设备有很大不同，它并不去查看虚拟机发出或者收到的包是什么内容，因此传统的 IP 分片技术在 NSX 下并不奏效。对于 NSX 而言，任何经由它的数据包均是“应用层”的包，它只需要负责 GENEVE 封装，然后丢给传输层转发即可。</p><p>单纯从技术角度来看，NSX 可以视为一个新的源端，理论上 NSX 可以对收到的包重新进行加工，减少包大小，但这种设计并不值得，因为同样会存在和 IP 分片类似的问题，同时也会消耗很多服务器 CPU 资源。</p><p>与其这样，不如让沿途的其他设备来修改 MTU，真的鲜有设备不能更改 MTU。</p><p>话虽这么说，但有时候真的会碰到不能更改 MTU 的地方，比如运营商的专线。</p><h2 id="NSX-多中心架构下对于-MTU-的优化"><a href="#NSX-多中心架构下对于-MTU-的优化" class="headerlink" title="NSX 多中心架构下对于 MTU 的优化"></a>NSX 多中心架构下对于 MTU 的优化</h2><p>NSX-T 在 3.0 版本推出了全新的多数据中心网络安全解决方案：Federation（中文：联邦或者联合）。</p><p>在联邦架构下，NSX 在控制层面做了分离，跨多个数据中心的网络和安全配置统一由全局管理器（Global NSX-T Manager）来负责；而本地的网络和安全配置以及控制层面由每个中心的本地管理器负责（Local NSX-T Manager）。</p><p>在这种统一管理、分布式处理的架构能非常好的应对各种站点级故障，快速进行网络层的故障切换。</p><p><img src="https://img2020.cnblogs.com/blog/2565133/202110/2565133-20211011100548849-1596279974.gif" alt="图片"></p><p>在 NSX-T Federation 下有个小的优化：<strong>跨数据中心的网络</strong>不再强制要求为 MTU ≥ 1600，而改为<strong>建议 MTU ≥ 1700</strong>。这背后的变化便是，NSX 支持跨中心流量的“分片”了！这项功能就是为了解决多数据中心环境下使用运营商的租用线路，而租用线路无法更改 MTU 的场景。</p><p>在 Federation 架构下会存在两种 Tunnel Endpoint：</p><ul><li>一种是普通的 TEP，在本地数据中心内，业务流量在 ESXi 和 Edge 间传输时会使用 TEP 封装；</li><li>另一种是跨中心的 TEP：Remote TEP，所有跨中心的通信会经由 RTEP 封装传输，RTEP 仅存在于 Edge 节点上，ESXi 不会有 RTEP。</li></ul><img src="/posts/56602/652.png" class=""><p>前面说了一大堆 IP 分片的不好，NSX Federation 也在尽可能减少 IP 分片。</p><p>针对 TCP 流量，Federation 会修改途径流量的 MSS 来让源/目标发送的报文小于标准大小 1500，这样可以避免 IP 分片。</p><img src="/posts/56602/653.png" class=""><p>而针对 UDP 流量，直接使用了标准的 IP 分片特性。</p><img src="/posts/56602/654.png" class=""><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>其实不仅是 NSX，在容器化环境中也经常会遇到 MTU 设置问题，很多 CNI 网络插件也是 Overlay 模型，会使用 VXLAN 等协议封装容器的流量进行跨节点传输，为了避免 IP 分片等问题，创建出来的容器 MTU 都会小于标准的 1500，比如下表是 Calico 关于 MTU 设置的介绍：</p><img src="/posts/56602/656.png" class=""><p>另外目前很多 CNI 的性能测试中都会有 MTU=9000 的测试结果，在 10G 网络下 MTU 对于性能的影响还不是很大，到了25G 或者 40G 以上时，MTU 可以很大程度地提高吞吐量。目前连 AWS 公有云都支持 Jumbo Frame。</p><p>无论从哪种角度，本地数据中心都应该尽可能提高 MTU 以应对未来的各种新平台新应用。</p>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
            <tag> NSX-T </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于 NSX-T 下的 MTU（上）</title>
      <link href="/posts/8475/"/>
      <url>/posts/8475/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="关于-NSX-T-下的-MTU（上）"><a href="#关于-NSX-T-下的-MTU（上）" class="headerlink" title="关于 NSX-T 下的 MTU（上）"></a>关于 NSX-T 下的 MTU（上）</h1><p>原创 Spark go nsx很可爱的</p><p>在实施 NSX-v 或者 NSX-T 的项目时，经常听到一个词：MTU，本文着重讲讲为什么 MTU 在 NSX 环境中如此重要，如何根据不同的设计来配置/验证 MTU 等等。</p><p>本文目录如下：</p><p>上篇：</p><ul><li>如果在 NSX 环境下 MTU 设置不正确会有什么现象？</li><li>如何验证 MTU 设置是否正确？</li><li>在 NSX-T 环境下如何设置 MTU？</li></ul><p>下篇：</p><ul><li>为什么 NSX 环境中 MTU 如此重要？有没有 workaround？</li><li>NSX 多中心架构下对于 MTU 的优化</li></ul><h2 id="如果-MTU-设置不正确会有什么现象？"><a href="#如果-MTU-设置不正确会有什么现象？" class="headerlink" title="如果 MTU 设置不正确会有什么现象？"></a>如果 MTU 设置不正确会有什么现象？</h2><p>当一个 NSX-T 环境中存在 MTU 设置问题时，会有下列现象之一：</p><ul><li>虚拟机可以 Ping 通其他虚拟机，但 SSH 失败；</li><li>虚拟机可以 Ping 通其他虚拟机，部分 HTTP 访问正常，部分 HTTP 访问会显示一直加载页面；</li><li>虚拟机和其他虚拟机通信均正常，但是和外部 PC SSH 通信时有问题；</li><li>通过 Iperf 打流，发现带宽远低于物理链路的带宽，比如带宽为 10G，但 Iperf 测试下来只有几百 mbps；</li><li>多台虚拟机在同一台宿主机上运行，相互间所有通信正常；而跨主机通信时 SSH/HTTP 等服务异常；</li><li>如果临时将虚拟机网卡的 MTU 由默认的 1500 改为 1400，则所有通信恢复正常。</li></ul><h2 id="如何验证-MTU-设置是否正确？"><a href="#如何验证-MTU-设置是否正确？" class="headerlink" title="如何验证 MTU 设置是否正确？"></a>如何验证 MTU 设置是否正确？</h2><p>在 NSX 环境中会存在两层网络，一层是物理交换机、服务器、vSphere 组成的承载网络（Underlay），另一层是 NSX、vSphere、Edge 节点构成的虚拟网络（Overlay）。两层网络中都有 MTU 相关的配置，任意一层配置不对都可能造成使用 Overlay 网络的虚拟机通信异常。</p><img src="/posts/8475/641.png" class=""><p>下面列出了两种 MTU 测试方法：</p><ul><li><strong>Underlay 测试法：</strong>在 ESXi 和 Edge 底层测试 TEP 网络**；<br>**</li><li><strong>Overlay 测试法：</strong>在 VM 中模拟正常访问，测试报文是否能被正常接收，如果能被正常接收则表示底层 TEP 网络正常。</li></ul><p>项目实施时根据喜好使用其中一种测试方法进行测试即可。</p><h3 id="Underlay-测试方法"><a href="#Underlay-测试方法" class="headerlink" title="Underlay 测试方法"></a>Underlay 测试方法</h3><p>为了结果的准确性，建议对所有 ESXi 到 ESXi，ESXi 到 Edge 的 TEP 进行大包测试。</p><img src="/posts/8475/642.png" class=""><p>通过 vmkping 测试 ESXi 到 ESXi，ESXi 到 Edge 的 MTU 是否正常</p><hr><p>通过 SSH 登陆任意一台安装好 NSX 的 ESXi，运行下列命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vmkping ++netstack=vxlan -d -s 1570 &lt;Destination-TEP-IP&gt; </span><br></pre></td></tr></table></figure><p>参数说明：</p><ul><li><strong>++netstack=vxlan</strong>：使用 vxlan TCP/IP 堆栈；</li><li><strong>-d</strong> ：不进行报文的切片；</li><li><strong>-s 1570</strong>：发送的 ICMP 包载荷大小。ICMP 包头默认 8 bytes，IPv4 包头默认 20 bytes，于是发出的 IP 包大小等于 1598，刚好小于 NSX 要求的 1600，实际最大能发送的包为 1572 bytes，1570 只是为了方便记忆；</li><li>**<Destination-TEP-IP>**：其他 ESXi 主机/Edge 节点的 TEP 地址。</li></ul><p>ESXi 或者 Edge 节点的 TEP 地址可以在 NSX Manager 的下列位置获得：</p><img src="/posts/8475/643.png" class=""><img src="/posts/8475/660.png" class=""><p>通过 vmkping 测试 Edge 到 Edge，Edge 到 ESXi 的 MTU 是否正常</p><hr><p>通过 Console 或者 SSH 登陆任意 Edge 节点。运行 get logical-router，查看 TUNNEL 对应的 VRF ID，一般都为 0。</p><img src="/posts/8475/644.png" class=""><p>运行 vrf 0 进入 Tunnel vrf，执行下列命令进行测试：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping &lt;Destination-TEP-IP&gt; size 1570 dfbit enable</span><br></pre></td></tr></table></figure><img src="/posts/8475/645.png" class=""><h3 id="Overlay-测试方法"><a href="#Overlay-测试方法" class="headerlink" title="Overlay 测试方法"></a>Overlay 测试方法</h3><p>Overlay 测试法是直接在虚拟机中 Ping 大包来模拟正常访问，看 Ping 包是否会被丢弃。</p><p>为了结果的准确性，建议进行虚拟机到虚拟机，以及外部 PC 到虚拟机的访问测试。</p><img src="/posts/8475/646.png" class=""><p>Windows 系统 Ping 命令格式</p><hr><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping -f -l 1472 &lt;Destination-IP&gt;</span><br></pre></td></tr></table></figure><ul><li><strong>-f</strong> ：表示不分片；</li><li><strong>-l</strong> ：是小写的 L，表示包的大小，进行 Overlay 测试时，包大小需要设置为 1472；</li><li><strong>Destination-IP</strong>：目标虚拟机或者 PC 的 IP 地址。</li></ul><p>Linux 系统 Ping 命令格式</p><hr><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping -M do -s 1472 &lt;Destination-IP&gt;</span><br></pre></td></tr></table></figure><ul><li><strong>-s</strong> ：表示 ICMP 包大小；</li><li><strong>-M do</strong> ：表示不分片；</li><li><strong>Destination-IP</strong>：目标虚拟机或者 PC 的 IP 地址。</li></ul><p>MacOS 系统 Ping 命令格式</p><hr><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping -s 1472 -D &lt;Destination-IP&gt;</span><br></pre></td></tr></table></figure><ul><li><strong>-s</strong> ：表示 ICMP 包大小；</li><li><strong>-D</strong> ：表示不分片；</li><li><strong>Destination-IP</strong>：目标虚拟机或者 PC 的 IP 地址。</li></ul><h2 id="在-NSX-T-环境下如何设置-MTU？"><a href="#在-NSX-T-环境下如何设置-MTU？" class="headerlink" title="在 NSX-T 环境下如何设置 MTU？"></a>在 NSX-T 环境下如何设置 MTU？</h2><p>以下面两张图为例，在一个 NSX-T 环境中，所有 TEP 到 TEP 沿途的设备（包括物理交换机、虚拟交换机等）均需要将 MTU 调整为 ≥ 1600。</p><p>如果所有 TEP 在同网段，则所有相关设备的二层口需要调整 MTU（下图所有红色线对应的接口）：</p><img src="/posts/8475/647.png" class=""><p>如果 TEP 分散在多个网段，则所有相关设备的二层口，以及三层 VLAN 接口均需要调整 MTU（下图所有红色线对应的接口）：</p><img src="/posts/8475/648.png" class=""><h3 id="1、物理交换机调整-MTU"><a href="#1、物理交换机调整-MTU" class="headerlink" title="1、物理交换机调整 MTU"></a>1、物理交换机调整 MTU</h3><p>不同厂家，不同型号的交换机配置 MTU 的方法差别很大，建议在配置 MTU 时优先参考产品的配置手册。</p><p>笔者总结了一些常见设备的配置方法，供参考。</p><h4 id="华为交换机"><a href="#华为交换机" class="headerlink" title="华为交换机"></a>华为交换机</h4><hr><p>二层接口 MTU（普通接口和聚合口通用）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;HUAWEI&gt; system-view</span><br><span class="line">[HUAWEI] interface gigabitethernet 0/0/1</span><br><span class="line">[HUAWEI-GigabitEthernet0/0/1] jumboframe enable 5000</span><br></pre></td></tr></table></figure><p>三层 VLAN 接口 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[HUAWEI] interface Vlanif 100</span><br><span class="line">[HUAWEI-Vlanif100] mtu 1600</span><br></pre></td></tr></table></figure><p>三层物理接口 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[HUAWEI] interface gigabitethernet 0/0/1</span><br><span class="line">[HUAWEI-GigabitEthernet0/0/1] undo portswitch</span><br><span class="line">[HUAWEI-GigabitEthernet0/0/1] mtu 1600</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure><h4 id="华三交换机"><a href="#华三交换机" class="headerlink" title="华三交换机"></a>华三交换机</h4><hr><p>二层接口 MTU（普通接口和聚合口通用）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">interface G1/1</span><br><span class="line"> jumboframe enable 600</span><br></pre></td></tr></table></figure><p>三层 VLAN 接口 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">interface Vlanif 100</span><br><span class="line"> mtu 1600</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure><p>注意：在某些软件版本下，需要通过 ip mtu 1600 来调整三层接口 MTU。</p><h4 id="思科交换机（C4506-C2906-C3560-C3750-等老型号交换机）"><a href="#思科交换机（C4506-C2906-C3560-C3750-等老型号交换机）" class="headerlink" title="思科交换机（C4506/C2906/C3560/C3750 等老型号交换机）"></a>思科交换机（C4506/C2906/C3560/C3750 等老型号交换机）</h4><hr><p>全局配置二层接口的 MTU（FastEthernet）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">system mtu 1600 </span><br></pre></td></tr></table></figure><p>全局配置二层接口的 MTU（GigabitEthernet）：</p><p>````</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">system mtu jumbo 1600 </span><br></pre></td></tr></table></figure><p>全局配置三层 VLAN 接口 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">system mtu routing 1600</span><br></pre></td></tr></table></figure><p>配置指定三层 VLAN 接口的 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">interface vlan 100</span><br><span class="line"> mtu 1600 </span><br></pre></td></tr></table></figure><h4 id="思科交换机（Nexus-3k-5k-等）"><a href="#思科交换机（Nexus-3k-5k-等）" class="headerlink" title="思科交换机（Nexus 3k/5k 等）"></a>思科交换机（Nexus 3k/5k 等）</h4><hr><p>通过 QoS 策略全局调整二层接口的 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">policy-map type network-qos jumbo</span><br><span class="line">  class type network-qos class-default</span><br><span class="line">      mtu 9216</span><br><span class="line">system qos</span><br><span class="line">  service-policy type network-qos jumbo</span><br></pre></td></tr></table></figure><p>配置三层 VLAN 接口的 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Switch(config%&#125;#interface vlan 1</span><br><span class="line">Switch(config-if)#mtu 9216</span><br></pre></td></tr></table></figure><p>配置三层物理接口的 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Switch(config%&#125;#interface ethernet 1/1</span><br><span class="line">Switch(config-if)#no switchport</span><br><span class="line">Switch(config-if)#mtu 9216</span><br></pre></td></tr></table></figure><h4 id="思科交换机（Nexus-7k-9k-等）"><a href="#思科交换机（Nexus-7k-9k-等）" class="headerlink" title="思科交换机（Nexus 7k/9k 等）"></a>思科交换机（Nexus 7k/9k 等）</h4><hr><p>Nexus 7k/9k 不仅支持通过 QoS 策略全局调整 MTU，也支持为部分接口配置 MTU。</p><p>通过 QoS 策略全局调整二层接口的 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">policy-map type network-qos jumbo</span><br><span class="line">  class type network-qos class-default</span><br><span class="line">      mtu 9216</span><br><span class="line">system qos</span><br><span class="line">  service-policy type network-qos jumbo</span><br></pre></td></tr></table></figure><p>配置部分二层接口的 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Switch(config%&#125;#interface ethernet 1/1</span><br><span class="line">Switch(config-if)#mtu 9216</span><br></pre></td></tr></table></figure><p>配置三层 VLAN 接口的 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Switch(config%&#125;#interface vlan 1</span><br><span class="line">Switch(config-if)#mtu 9216</span><br></pre></td></tr></table></figure><p>配置三层物理接口的 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Switch(config%&#125;#interface ethernet 1/1</span><br><span class="line">Switch(config-if)#no switchport</span><br><span class="line">Switch(config-if)#mtu 9216</span><br></pre></td></tr></table></figure><h4 id="思科交换机（Nexus-2k）"><a href="#思科交换机（Nexus-2k）" class="headerlink" title="思科交换机（Nexus 2k）"></a>思科交换机（Nexus 2k）</h4><hr><p>Nexus 2k 的 MTU 一般需要在父交换机上进行配置，部分父交换机支持在 FPC 口下配置 MTU，部分交换机则需要通过 network-qos 配置 MTU。</p><p>Per-Port Fabric Port Channel (FPC) 配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">interface port-channel136</span><br><span class="line">  switchport mode fex-fabric</span><br><span class="line">  fex associate 136</span><br><span class="line">  vpc 136</span><br><span class="line">  mtu 9216</span><br></pre></td></tr></table></figure><p>通过 network-qos 配置 MTU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">policy-map type network-qos jumbo</span><br><span class="line">  class type network-qos class-default</span><br><span class="line">    mtu 9216</span><br><span class="line">system qos</span><br><span class="line">  service-policy type network-qos jumbo</span><br></pre></td></tr></table></figure><h3 id="2、修改-Edge-VM-所使用-vSS-vDS-的-MTU"><a href="#2、修改-Edge-VM-所使用-vSS-vDS-的-MTU" class="headerlink" title="2、修改 Edge VM 所使用 vSS/vDS 的 MTU"></a>2、修改 Edge VM 所使用 vSS/vDS 的 MTU</h3><p>如果环境中使用虚拟机版本的 Edge 节点，那就需要将 Edge 节点 TEP 使用的虚拟交换机 MTU 调大。</p><p>比如在我的环境中使用 seg-vlan2-edge-vtep 这个 NSX VLAN Segment 作为 Edge VM 的 TEP 网卡。</p><img src="/posts/8475/649.png" class=""><p>而此 Segment 在 vDS-DC2 中，那么修改 vDS-DC2 的 MTU 即可：</p><img src="/posts/8475/650.png" class=""><img src="/posts/8475/651.png" class=""><p>如果使用的是标准交换机，参照下图配置 MTU 即可：</p><img src="/posts/8475/652.png" class=""><h3 id="3、（NSX-T-3-0-之后）修改-VDS-的-MTU"><a href="#3、（NSX-T-3-0-之后）修改-VDS-的-MTU" class="headerlink" title="3、（NSX-T 3.0 之后）修改 VDS 的 MTU"></a>3、（NSX-T 3.0 之后）修改 VDS 的 MTU</h3><p>在 NSX-T 3.0 之前，所有安装了 NSX 的 ESXi 只能使用 N-VDS（可以简单理解为 NSX 管理的 VDS），而在 3.0+vSphere7.0 之后，ESXi 既可以使用 N-VDS，也可以使用 vCenter VDS：</p><img src="/posts/8475/653.png" class=""><p>使用 N-VDS 不需要额外的配置，但使用 vCenter VDS 时，需要全局将 VDS MTU 调整为 1600：</p><img src="/posts/8475/6454.png" class=""><img src="/posts/8475/655.png" class=""><h3 id="4、NSX-上行链路配置文件调整-MTU"><a href="#4、NSX-上行链路配置文件调整-MTU" class="headerlink" title="4、NSX 上行链路配置文件调整 MTU"></a>4、NSX 上行链路配置文件调整 MTU</h3><p>在部署 NSX-T 时会用到“上行链路配置文件”，默认 NSX-T 下所有上行链路配置文件的 MTU 均为 1600，不要手动修改这个值，保持默认即可。</p><img src="/posts/8475/656.png" class=""><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>一般在实施虚拟化项目时，建议将硬件网络和虚拟网络的 MTU 都调整为最大，比如一般交换机最大支持 9216，虚拟交换机最大支持 9000，vmkernel 最大支持 9000。调大 MTU 可以显著提高 vMotion、vSAN 等网络的性能，原因是传输同等大小的数据，更大的 MTU 会产生更少的 IP 包，TCP/IP 封装/解封装的开销更少，系统处理的中断也会更少。</p><p>部分很老的交换机更改 MTU 后需要重启设备或者端口才能生效，一般新生产的交换机都支持在线更改 MTU，更改 MTU 不会对网络造成影响。现在国内很多交换机出厂就会开启 Jumbo Frame，这应该也是迎合最终用户的需求做出的优化。</p>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
            <tag> NSX-T </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>虚拟云网络专辑｜多云时代的网络安全</title>
      <link href="/posts/59508/"/>
      <url>/posts/59508/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="虚拟云网络专辑｜多云时代的网络安全"><a href="#虚拟云网络专辑｜多云时代的网络安全" class="headerlink" title="虚拟云网络专辑｜多云时代的网络安全"></a>虚拟云网络专辑｜多云时代的网络安全</h1><img src="/posts/59508/640.gif" class=""><p>　　在过去的十年中，越来越多的企业开始采用多云的战略。企业逐步将工作负载部署到多个云上，这些云包括企业内部的私有云，也包括原生的公有云，甚至使用多个公有云，形成了一个混合云的架构；同时在这种混合云的架构下，云上和云下也有互通性需求，应用的部署同时利用了公有云的弹性和私有云的安全性等优势。</p><p>　　对于一个多层的应用来说，应用的前端更多的部署在公有云上，数据库部署在私有云的环境中，云上和云下网络的互通采用了 site to site VPN 技术或者 AWS 的 Direct Connect 以及 Azure 的 Express Route。在这种情况下，暴露了巨大的攻击面，云上的安全威胁也会泛洪到云下的环境，所以需要在这种多云的环境下对云上和云下的工作负载进行安全防护。</p><p>　　<img src="/posts/59508/640.png" class=""></p><p>　　从上图可以看出，云上的攻击者向云下发起了攻击。为了避免这种攻击的发生，可以在云下对工作负载进行安全策略的部署，同时在云上通过安全组实现云上的安全策略的部署。通过这种方式虽然可以进行安全策略部署，但是运维起来非常的复杂：第一，私有云、公有云的安全策略独立规划，独立的部署，不同的管理界面，而且每朵云都有各自的管理方式，形成了架构孤岛；第二，在多云的应用场景中，由于采用不同的云基础设施，需要花费大量的时间学习这些云基础设施安全策略的特点，非常高的学习成本，同时也增加了管理成本。<strong>这是目前安全运维面临两大主要挑战</strong>。</p><p> 　众所周知，<strong>VMware NSX-T Data Center 提供了在私有云环境下的网络和安全</strong>。它在几年前就开始提供在私有云环境下微分段能力，实现了 L4-L7 的安全防护能力，安全策略可以应用到虚拟机的虚拟网卡级别，并且在私有云环境下通过一个管理界面提供了网络安全策略的部署，同时通过虚拟机名称或虚拟机标记等虚拟机属性创建动态的安全组，简化了安全策略的部署以及梳理工作，也不关心应用是跑在虚拟机、容器还是物理机的环境。</p><p> 　然而<strong>在多云的时代，NSX-T Data Center 也扩展到了原生的公有云</strong>，比如 AWS 和 Azure，在这种多云的环境中，我们称为 <strong>NSX Cloud</strong>。NSX Cloud 提供了一种新的多云网络安全的管理模式，为在原生公有云中运行的工作负载跨多个公有云提供一致的网络和安全策略。</p><p> 　与 NSX-T Data Center 一起，我们可以获得应用到所有工作负载的网络服务和安全策略的统一视图，无论是像今天私有云中运行的虚拟机，还是运行在 AWS 和 Azure 上的工作负载。</p><p>　　<img src="/posts/59508/641.png" class=""></p><p>　　<strong>接下来将为大家介绍一下 NSX Cloud 的特点及使用场景，后续也会给大家介绍 NSX Cloud 组件及实现方式。</strong></p><p>　　<strong>第一，NSX Cloud 使用与 NSX-T Data Center 一样的管理和控制平台。</strong></p><p>　　因此在多云的环境中，只需要部署一套安全解决方案就可以管理从私有云到公有云的安全策略，安全策略只需要定义一次，就可以应用到任何位置的工作负载，包括云端、Region、AZ等。安全策略将根据应用属性和用户定义的标记以动态方式应用于每个工作负载。如下图所示：</p><p>　　<img src="/posts/59508/642.png" class=""></p><p>　　<strong>第二，在公有云上可以对现有的计算实例实施微段安全策略，提供 L4-L7 的状态化分布式防火墙。</strong></p><p>　　在云上有多个 VPC 或 VNET 的情况下，只须在一个 VPC 或 VNET 中部署冗余的 Public Cloud Gateway（简称PCG）就可以实现整个云上的微分段安全策略，其它 VPC 或 VNET 可以共享 PCG，同时不改变云上的网络架构，支持代理模式和无代理模式，如下所示：</p><p>　　<img src="/posts/59508/643.png" class=""></p><p>　　<strong>第三，提供端到端运维的可见性。</strong></p><p>　　可能通过 IPFIX、traceflow 和 syslog 获取流和数据包的信息，同时提供了在多云环境下的网络拓扑，如下图所示：</p><p>　　<img src="/posts/59508/644.png" class=""></p><p>　　<strong>我们可以通过 NSX Cloud 实现在多云环境下的安全策略的管理，那么它的架构是什么样的，具体在实际的生产环境中如何部署呢？</strong></p><p>　　接下来，我们先来看一下 NSX Cloud 架构，如下图所示：</p><p>　　<img src="/posts/59508/645.png" class=""></p><p> 　<strong>Cloud Service Manager（CSM）</strong></p><p>　　提供了私有云和公有云 VPC/VNET 以及实例的视图以及安全策略的统一视图，同时通过 CSM 在 VPC或 VNET 中部署 PCG设备（是一个虚拟机），提供 PCG 生命周期的管理，CSM 属于控制平面的组件。</p><p>　　<strong>NSX Manager</strong></p><p>　　提供了私有云和公有云网络和安全策略部署的统一视图，所有的策略配置都在 NSX Manager 中提供，并下发的实例运行的地方。</p><p>　　<strong>Public Cloud Gateway（PCG）</strong></p><p>　　它是公有云中的 NSX 本地控制平面，它是由 CSM 部署，它在 VPC/VNET 中执行资源清单的发现，也包括云中的标记的发现，以 active-standby 方式部署在云端。</p><p>　　<strong>NSX Tools</strong></p><p>　　属于数据平面的组件，通过它执行分布式防火墙的策略，相当于实例中的代理，PCG 做为控制平面，将 NSX Manager 中配置的安全策略下发的 NSX Tools 执行安全策略。另外，也支持无代理的方式，即不需要在计算实例中安装任何代理，PCG 通过 API 调用原生公有云安全组实现安全策略。</p><p> 　接下来让我们再来看一下 NSX Cloud 在生产环境的网络拓扑以及最佳实践。如下图所示：</p><p>　　<img src="/posts/59508/646.png" class=""></p><p> 　<strong>要通过 NSX Cloud 交付云上云下一致的网络安全策略，需要提前做一些准备工作。</strong></p><p>　　1、客户数据中心与 AWS/Azure 通过 site to site VPN 或DirectConnect/ExpressRoute 实现云上和云下的互通，以路由方式互通即可。</p><p>　　2、部署 PCG 的 VPC/VNET（称为 Transit VPC/Transit VNET）创建三个 subnets，分别用于 PCG 的管理、上联和下联网络，并且要求PCG 的管理 subnet 能够访问 internet，可以通过代理或 NAT 网关实现。</p><p>　　3、云上的 VPC/VNET 之间需要 Peering，或者使用 TGW/VGW 实现hub-spoken 的架构。</p><p>　　4、通过 VMware 提供的脚本创建 AWS/Azure 的帐号权限。</p><p>　　<strong>以上四个条件具备了之后，这时我们就可以部署 NSX Cloud 了。</strong></p><p>　　部署步骤如下：</p><p>　　1、如果已经在数据中心部署了 NSX-T Data Center，并实现了在数据中心内部的微分段，这时我们就直接在数据中心内部部署 CSM。部署 CSM使用的 OVA 与 NSX-T Manager Appliance 是一样的，在部署过程中选择部署 CSM 即可。如果没有部署 NSX-T Data Center，先部署 NSX-T Data Center，完成部署 CSM 后，在 CSM 的页面中加入 NSX-T Data Center 的帐号，然后在加入 AWS 和 Azure 的帐号同步云上的资源清单，如下图所示 ：</p><p>　　<img src="/posts/59508/647.png" class=""></p><p>　　2、点击 instances 或 VPC/VNET，可以查看到云上的详细信息。</p><p>　　<img src="/posts/59508/648.png" class=""></p><p>　　<strong>3、</strong>在 AWS/Azure 的 Transit VPC/VNET 中部署 PCG，部署 PCG 的时候，选择 PCG 所使用的 subnet。</p><p>　　<img src="/posts/59508/649.png" class=""></p><p> 　PCG 部署成功后，如下图所示：</p><p>　　<img src="/posts/59508/650.png" class=""></p><p>　　<strong>4、</strong>如果采用代理方式，需要在实例中安装 NSX tools，如下图所示：</p><p>　　<img src="/posts/59508/651.png" class=""></p><p>　　<strong>5、</strong>在实例中安装 NSX tools 后，这个实例成为了 NSX managed 的实例，这时我们就可以在 NSX 的界面中发现这个实例以及实例上的标记，在 NSX 可以针对标记创建动态安全组来实现微分段的策略。</p><p>　　<strong>6、</strong>如果其它 VPC/VNET 中的实例也需要一致的安全策略，这时需要将其它的计算 VPC/VNET 链接到 Transit VPC/VNET 来共享 PCG，然后在计算 VPC/VNET 中的实例中安装 NSX tools。如下图所示：</p><p>　　<img src="/posts/59508/652.png" class=""></p><p>　　<strong>总结</strong></p><p>　　在应用迁移到了公有云的进程中，如果客户数据中心已经使用了 NSX 的微分段来实施安全策略，那么我们就可以通过 NSX Cloud 将私有云、原生公有云上的工作负载统一实施安全策略，不需要对私有云以及公有云的网络架构进行修改，就可以实现私有云和公有云一致的安全策略交付，简化了安全的运维工作，同时提供了安全的可视性。</p>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
            <tag> NSX-T </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vSAN 版本目录更新</title>
      <link href="/posts/35722/"/>
      <url>/posts/35722/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="vSAN-版本目录更新"><a href="#vSAN-版本目录更新" class="headerlink" title="vSAN 版本目录更新"></a>vSAN 版本目录更新</h1><p>本文介绍了在 <strong>vSAN vSAN Health Service 中检查 vSAN 内部版本建议 - vSAN 版本目录最新版本</strong>并详细说明可能报告错误的原因。<br>该 vSAN 目录维护有关可用版本、首选版本顺序以及每个版本所需的关键修补程序的信息。vSAN 主机版本目录托管在 VMware Cloud：<a href="https://vcsa.vmware.com/ph/api/v1/results?deploymentId=2d02e861-7e93-4954-9a73-b08692a330d1&collectorId=VsanCloudHealth.6_5&objectId=0c3e9009-ba5d-4e5f6-bae8-f25ec506d219&type=vsan-updates-json">here</a>（右键单击并另存为文件）</p><p><strong>问：最新版本 vSAN 目录最新版本检查有什么用？</strong></p><p>vSAN 版本目录提供关键信息vSAN内部版本建议引擎。在有新版本或关键修补程序时，将更新该版本。确保本地副本保持最新状态非常重要。</p><p>此检查是为了确保 vSAN 目录的本地副本是最新的。</p><p><strong>问：如果该检查处于错误状态，意味着什么？</strong></p><p>此检查使用 90 天或 180 天的使用期限阈值来分别显示警告或错误。</p><p><strong>问：如何排除故障并修复错误状态？</strong></p><p>检查并还原 Internet 连接访问版本目录。如果没有 Internet 连接，可以将 vSAN 内部版本目录直接上载到 vCenter Server。在 vSphere Client 中，单击 <strong>Cluster &gt; Monitor &gt;</strong> <strong>vSAN &gt; Skyline 运行状况 &gt; vSAN 内部版本建议 &gt; vSAN 版本目录最新版本</strong> 单击 更新自 VSAN 版本目录信息中的文件 。vSAN 版本目录可以访问<a href="https://vcsa.vmware.com/ph/api/v1/results?deploymentId=2d02e861-7e93-4954-9a73-b08692a330d1&collectorId=VsanCloudHealth.6_5&objectId=0c3e9009-ba5d-4e5f6-bae8-f25ec506d219&type=vsan-updates-json">此处</a> 下载，右键单击并另存为文件。</p><p>本文来源：<a href="https://kb.vmware.com/s/article/58891?lang=zh_cn">https://kb.vmware.com/s/article/58891?lang=zh_cn</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
            <tag> vSAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vSAN 删除不可访问的对象</title>
      <link href="/posts/50626/"/>
      <url>/posts/50626/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="vSAN-删除不可访问的对象"><a href="#vSAN-删除不可访问的对象" class="headerlink" title="vSAN 删除不可访问的对象"></a>vSAN 删除不可访问的对象</h1><ol><li>使用SSH客户端软件（例如xShell）登录到其中一台ESXi主机（需要在这台主机启动SSH服务）</li><li>在登录到shell界面后，先执行cd /vmfs/volumes/vsanDatastore命令进入vSAN数据存储，</li><li>然后使用objtool命令依次删除 vsan中 无法访问的对象（记录对象的UUID）。</li></ol><blockquote><p>objtool 在/usr/lib/vmware/osfs/bin/目录中</p></blockquote><blockquote><p>例子：在SSH中依次执行如下的命令（在vSAN数据存储根目录下）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/usr/lib/vmware/osfs/bin/objtool delete -f -u db6f235b-b856-89dd-6324-0010181a9981</span><br><span class="line">/usr/lib/vmware/osfs/bin/objtool delete -f -u 6238115c-0828-2cc6-3dd3-b8aeedb7689f</span><br><span class="line">/usr/lib/vmware/osfs/bin/objtool delete -f -u c19a245b-f031-9b4f-9b10-b8aeedb7689f</span><br></pre></td></tr></table></figure></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
            <tag> vSAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>删除vSAN中故障磁盘设备</title>
      <link href="/posts/32451/"/>
      <url>/posts/32451/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="命令行删除vSAN中故障磁盘设备"><a href="#命令行删除vSAN中故障磁盘设备" class="headerlink" title="命令行删除vSAN中故障磁盘设备"></a>命令行删除vSAN中故障磁盘设备</h1><ul><li><p>SSH或者ESXi Shell登录到有SSD设备故障的主机；</p></li><li><p>执行如下命令确认故障SSD设备ID：esxcli vsan storage list此时，会看到naa.xxxxxx开头的设备；</p></li><li><p>执行如下命令，从Disk Group删除掉设备：esxcli vsan storage remove -s naa.xxxxx</p></li><li><p>然后，拿掉主机上的这块坏掉的SSD设备，添加新的设备进去后，重新执行扫描，添加进去；</p></li><li><p>Unknown</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Device: Unknown</span><br><span class="line">Display Name: Unknown</span><br><span class="line">通过UUID删除</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br></pre></td><td class="code"><pre><span class="line">[root@esxi168:~] esxcli vsan storage list</span><br><span class="line">naa.5000c500b809705f</span><br><span class="line">   Device: naa.5000c500b809705f</span><br><span class="line">   Display Name: naa.5000c500b809705f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 520e9aae-a9dc-b35e-13bd-8d24ac6c68be</span><br><span class="line">   VSAN Disk Group UUID: 5245f864-1b44-1dff-07b4-dbf4e7907753</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dd84</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 13736057332562856016</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:15 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b84429eb</span><br><span class="line">   Device: naa.5000c500b84429eb</span><br><span class="line">   Display Name: naa.5000c500b84429eb</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 5214cfb4-a9e1-1c8f-1c36-9d677770ac39</span><br><span class="line">   VSAN Disk Group UUID: 526d65a3-34a4-80b9-5168-0686ca6de94a</span><br><span class="line">   VSAN Disk Group Name:</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: false</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 17835052590214055526</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:32 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b8095bdf</span><br><span class="line">   Device: naa.5000c500b8095bdf</span><br><span class="line">   Display Name: naa.5000c500b8095bdf</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 5229ffc4-00e9-8545-e6a8-c4394d6cbcd0</span><br><span class="line">   VSAN Disk Group UUID: 5245f864-1b44-1dff-07b4-dbf4e7907753</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dd84</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 12360461569146510039</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:15 2018</span><br><span class="line"></span><br><span class="line">naa.500a07511be0dd84</span><br><span class="line">   Device: naa.500a07511be0dd84</span><br><span class="line">   Display Name: naa.500a07511be0dd84</span><br><span class="line">   Is SSD: true</span><br><span class="line">   VSAN UUID: 5245f864-1b44-1dff-07b4-dbf4e7907753</span><br><span class="line">   VSAN Disk Group UUID: 5245f864-1b44-1dff-07b4-dbf4e7907753</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dd84</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 6994986707959962499</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: false</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:15 2018</span><br><span class="line"></span><br><span class="line">naa.5000c50098124733</span><br><span class="line">   Device: naa.5000c50098124733</span><br><span class="line">   Display Name: naa.5000c50098124733</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 5256f1fe-a43e-a39e-8edd-34c4c57f51fd</span><br><span class="line">   VSAN Disk Group UUID: 529c367d-3886-40f4-2aa7-3cbc244fcd15</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dc70</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 4856239252862720943</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue May  7 02:39:24 2019</span><br><span class="line"></span><br><span class="line">naa.5000c500b844305b</span><br><span class="line">   Device: naa.5000c500b844305b</span><br><span class="line">   Display Name: naa.5000c500b844305b</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 525bf335-3463-cf2d-2e5b-971922f3ac79</span><br><span class="line">   VSAN Disk Group UUID: 526d65a3-34a4-80b9-5168-0686ca6de94a</span><br><span class="line">   VSAN Disk Group Name:</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: false</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 1599653935973913322</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:32 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b8093baf</span><br><span class="line">   Device: naa.5000c500b8093baf</span><br><span class="line">   Display Name: naa.5000c500b8093baf</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 526763a8-e972-68f4-a577-3577af1ff06b</span><br><span class="line">   VSAN Disk Group UUID: 529c367d-3886-40f4-2aa7-3cbc244fcd15</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dc70</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 13911735673214752242</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:09:59 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b8092923</span><br><span class="line">   Device: naa.5000c500b8092923</span><br><span class="line">   Display Name: naa.5000c500b8092923</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52863d88-e34e-4feb-ba82-1f34b721679b</span><br><span class="line">   VSAN Disk Group UUID: 529c367d-3886-40f4-2aa7-3cbc244fcd15</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dc70</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 14979827010222722567</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:09:59 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b844318f</span><br><span class="line">   Device: naa.5000c500b844318f</span><br><span class="line">   Display Name: naa.5000c500b844318f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 528fac97-329a-9b3b-1070-600db714bbcf</span><br><span class="line">   VSAN Disk Group UUID: 529c367d-3886-40f4-2aa7-3cbc244fcd15</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dc70</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 622639443268996496</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:09:59 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b8442227</span><br><span class="line">   Device: naa.5000c500b8442227</span><br><span class="line">   Display Name: naa.5000c500b8442227</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 5294424a-a32d-5368-58d3-90f17337385e</span><br><span class="line">   VSAN Disk Group UUID: 526d65a3-34a4-80b9-5168-0686ca6de94a</span><br><span class="line">   VSAN Disk Group Name:</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: false</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 13626091087589283952</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:32 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b8441d57</span><br><span class="line">   Device: naa.5000c500b8441d57</span><br><span class="line">   Display Name: naa.5000c500b8441d57</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 529bf03a-0322-0f39-91bc-607cacc91e3f</span><br><span class="line">   VSAN Disk Group UUID: 526d65a3-34a4-80b9-5168-0686ca6de94a</span><br><span class="line">   VSAN Disk Group Name:</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: false</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 15140885931762138084</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:32 2018</span><br><span class="line"></span><br><span class="line">naa.500a07511be0dc70</span><br><span class="line">   Device: naa.500a07511be0dc70</span><br><span class="line">   Display Name: naa.500a07511be0dc70</span><br><span class="line">   Is SSD: true</span><br><span class="line">   VSAN UUID: 529c367d-3886-40f4-2aa7-3cbc244fcd15</span><br><span class="line">   VSAN Disk Group UUID: 529c367d-3886-40f4-2aa7-3cbc244fcd15</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dc70</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 12793321740773517731</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: false</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:09:59 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b809373f</span><br><span class="line">   Device: naa.5000c500b809373f</span><br><span class="line">   Display Name: naa.5000c500b809373f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52a1e909-8d52-0fbe-e127-d12ace600afe</span><br><span class="line">   VSAN Disk Group UUID: 5245f864-1b44-1dff-07b4-dbf4e7907753</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dd84</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 14687421811095597583</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:15 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b8442b87</span><br><span class="line">   Device: naa.5000c500b8442b87</span><br><span class="line">   Display Name: naa.5000c500b8442b87</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52a88aca-ea74-8702-56e5-65277c5bd824</span><br><span class="line">   VSAN Disk Group UUID: 5245f864-1b44-1dff-07b4-dbf4e7907753</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dd84</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 15108214459231231674</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:15 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b844293f</span><br><span class="line">   Device: naa.5000c500b844293f</span><br><span class="line">   Display Name: naa.5000c500b844293f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52a93739-3579-7229-a025-2e4fb8d5806c</span><br><span class="line">   VSAN Disk Group UUID: 5245f864-1b44-1dff-07b4-dbf4e7907753</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dd84</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 4367308253417995353</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:15 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b80958c7</span><br><span class="line">   Device: naa.5000c500b80958c7</span><br><span class="line">   Display Name: naa.5000c500b80958c7</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52ac41d9-6cd8-3042-77a7-a5849ddcc565</span><br><span class="line">   VSAN Disk Group UUID: 529c367d-3886-40f4-2aa7-3cbc244fcd15</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dc70</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 15599908734375047539</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:09:59 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b8092ef3</span><br><span class="line">   Device: naa.5000c500b8092ef3</span><br><span class="line">   Display Name: naa.5000c500b8092ef3</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52b0d65d-7e8b-cdcd-f510-43b39f20615b</span><br><span class="line">   VSAN Disk Group UUID: 5245f864-1b44-1dff-07b4-dbf4e7907753</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dd84</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 3302907336919914664</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:15 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b8097067</span><br><span class="line">   Device: naa.5000c500b8097067</span><br><span class="line">   Display Name: naa.5000c500b8097067</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52b1543f-050b-1f39-bf4e-1668c83da627</span><br><span class="line">   VSAN Disk Group UUID: 5245f864-1b44-1dff-07b4-dbf4e7907753</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dd84</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 3685325171695791538</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:15 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b80943cf</span><br><span class="line">   Device: naa.5000c500b80943cf</span><br><span class="line">   Display Name: naa.5000c500b80943cf</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52b266bd-0941-2d23-2bec-8c92b2bf868c</span><br><span class="line">   VSAN Disk Group UUID: 529c367d-3886-40f4-2aa7-3cbc244fcd15</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dc70</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 8938634346772624631</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:09:59 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b8094b5f</span><br><span class="line">   Device: naa.5000c500b8094b5f</span><br><span class="line">   Display Name: naa.5000c500b8094b5f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52ba6a7c-ea32-4028-66c9-44fddb6266a9</span><br><span class="line">   VSAN Disk Group UUID: 529c367d-3886-40f4-2aa7-3cbc244fcd15</span><br><span class="line">   VSAN Disk Group Name: naa.500a07511be0dc70</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 4055968825279276154</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:09:59 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b8442b53</span><br><span class="line">   Device: naa.5000c500b8442b53</span><br><span class="line">   Display Name: naa.5000c500b8442b53</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52c021bb-ed18-4c74-0c19-33f4647deb6c</span><br><span class="line">   VSAN Disk Group UUID: 526d65a3-34a4-80b9-5168-0686ca6de94a</span><br><span class="line">   VSAN Disk Group Name:</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: false</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 3172464568355573609</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:32 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b809568f</span><br><span class="line">   Device: naa.5000c500b809568f</span><br><span class="line">   Display Name: naa.5000c500b809568f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52d0e00a-66b6-ce24-a5fc-74dd84924178</span><br><span class="line">   VSAN Disk Group UUID: 526d65a3-34a4-80b9-5168-0686ca6de94a</span><br><span class="line">   VSAN Disk Group Name:</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: false</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 17450323340495659076</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:32 2018</span><br><span class="line"></span><br><span class="line">naa.5000c500b80957bb</span><br><span class="line">   Device: naa.5000c500b80957bb</span><br><span class="line">   Display Name: naa.5000c500b80957bb</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52d87de7-ed68-47f7-855c-7d495d374a90</span><br><span class="line">   VSAN Disk Group UUID: 526d65a3-34a4-80b9-5168-0686ca6de94a</span><br><span class="line">   VSAN Disk Group Name:</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: false</span><br><span class="line">   On-disk format version: 7</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 7196727146034522797</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption Metadata Checksum OK: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Is Mounted: true</span><br><span class="line">   Creation Time: Tue Nov  6 16:10:32 2018</span><br><span class="line">[root@esxi168:~]</span><br><span class="line">[root@esxi168:~] esxcli vsan storage list | grep Display</span><br><span class="line">   Display Name: naa.5000c500b809705f</span><br><span class="line">   Display Name: naa.5000c500b84429eb</span><br><span class="line">   Display Name: naa.5000c500b8095bdf</span><br><span class="line">   Display Name: naa.500a07511be0dd84</span><br><span class="line">   Display Name: naa.5000c50098124733</span><br><span class="line">   Display Name: naa.5000c500b844305b</span><br><span class="line">   Display Name: naa.5000c500b8093baf</span><br><span class="line">   Display Name: naa.5000c500b8092923</span><br><span class="line">   Display Name: naa.5000c500b844318f</span><br><span class="line">   Display Name: naa.5000c500b8442227</span><br><span class="line">   Display Name: naa.5000c500b8441d57</span><br><span class="line">   Display Name: naa.500a07511be0dc70</span><br><span class="line">   Display Name: naa.5000c500b809373f</span><br><span class="line">   Display Name: naa.5000c500b8442b87</span><br><span class="line">   Display Name: naa.5000c500b844293f</span><br><span class="line">   Display Name: naa.5000c500b80958c7</span><br><span class="line">   Display Name: naa.5000c500b8092ef3</span><br><span class="line">   Display Name: naa.5000c500b8097067</span><br><span class="line">   Display Name: naa.5000c500b80943cf</span><br><span class="line">   Display Name: naa.5000c500b8094b5f</span><br><span class="line">   Display Name: naa.5000c500b8442b53</span><br><span class="line">   Display Name: naa.5000c500b809568f</span><br><span class="line">   Display Name: naa.5000c500b80957bb</span><br><span class="line">[root@esxi168:~] esxcli vsan storage list | grep Display | wc -l 23</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br></pre></td><td class="code"><pre><span class="line">[root@vsan13:~] esxcli vsan storage list</span><br><span class="line">naa.5000c500a00f1a8b</span><br><span class="line">   Device: naa.5000c500a00f1a8b</span><br><span class="line">   Display Name: naa.5000c500a00f1a8b</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID:</span><br><span class="line">   VSAN Disk Group UUID:</span><br><span class="line">   VSAN Disk Group Name:</span><br><span class="line">   Used by this host: false</span><br><span class="line">   In CMMDS: false</span><br><span class="line">   On-disk format version: &lt;Unknown&gt;</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum:</span><br><span class="line">   Checksum OK: false</span><br><span class="line">   Is Capacity Tier: false</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f1b4f</span><br><span class="line">   Device: naa.5000c500a00f1b4f</span><br><span class="line">   Display Name: naa.5000c500a00f1b4f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 5200584e-8bad-2601-a9af-094291ac722d</span><br><span class="line">   VSAN Disk Group UUID: 52365b5c-770b-47cf-c52b-35c0c128a2aa</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a793</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 11624927080897558569</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f1cbf</span><br><span class="line">   Device: naa.5000c500a00f1cbf</span><br><span class="line">   Display Name: naa.5000c500a00f1cbf</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 5209d99f-fe04-9561-4890-bd4740a604f5</span><br><span class="line">   VSAN Disk Group UUID: 52c135c7-7e04-46b8-310f-cf9bcb8d2f67</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a74f</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 3882115191772923228</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c5009ff7e28f</span><br><span class="line">   Device: naa.5000c5009ff7e28f</span><br><span class="line">   Display Name: naa.5000c5009ff7e28f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 520bb8c4-9489-e0c9-f258-cf705687d0dc</span><br><span class="line">   VSAN Disk Group UUID: 52f1f7d7-e958-5bc4-ec17-0dc2c37827c2</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2ab2b</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 7962989713887510116</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c5009ff7e7db</span><br><span class="line">   Device: naa.5000c5009ff7e7db</span><br><span class="line">   Display Name: naa.5000c5009ff7e7db</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 5223ca80-409a-5a34-5f82-39f74ab79ed9</span><br><span class="line">   VSAN Disk Group UUID: 52365b5c-770b-47cf-c52b-35c0c128a2aa</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a793</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 2771050927993134266</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f1dff</span><br><span class="line">   Device: naa.5000c500a00f1dff</span><br><span class="line">   Display Name: naa.5000c500a00f1dff</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 5228cbc4-955b-0be0-c254-ac0a76ee6b3d</span><br><span class="line">   VSAN Disk Group UUID: 52c135c7-7e04-46b8-310f-cf9bcb8d2f67</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a74f</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 5919060905867089777</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f1c9f</span><br><span class="line">   Device: naa.5000c500a00f1c9f</span><br><span class="line">   Display Name: naa.5000c500a00f1c9f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 5232736c-231f-0297-77cf-b2760cc622b1</span><br><span class="line">   VSAN Disk Group UUID: 52365b5c-770b-47cf-c52b-35c0c128a2aa</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a793</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 1999326320923239864</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.55cd2e414dc2a793</span><br><span class="line">   Device: naa.55cd2e414dc2a793</span><br><span class="line">   Display Name: naa.55cd2e414dc2a793</span><br><span class="line">   Is SSD: true</span><br><span class="line">   VSAN UUID: 52365b5c-770b-47cf-c52b-35c0c128a2aa</span><br><span class="line">   VSAN Disk Group UUID: 52365b5c-770b-47cf-c52b-35c0c128a2aa</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a793</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 15262382003459667763</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: false</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f159f</span><br><span class="line">   Device: naa.5000c500a00f159f</span><br><span class="line">   Display Name: naa.5000c500a00f159f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52662c05-71b7-c0a7-365e-2a8ad218966a</span><br><span class="line">   VSAN Disk Group UUID: 52c135c7-7e04-46b8-310f-cf9bcb8d2f67</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a74f</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 6760414608772866716</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f1e67</span><br><span class="line">   Device: naa.5000c500a00f1e67</span><br><span class="line">   Display Name: naa.5000c500a00f1e67</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 5267794b-00f7-54c6-dc90-4d59957ff8e3</span><br><span class="line">   VSAN Disk Group UUID: 52f1f7d7-e958-5bc4-ec17-0dc2c37827c2</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2ab2b</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 15545171813325471852</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f2a23</span><br><span class="line">   Device: naa.5000c500a00f2a23</span><br><span class="line">   Display Name: naa.5000c500a00f2a23</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52941cca-fcfb-c438-a019-0e90aa432fb4</span><br><span class="line">   VSAN Disk Group UUID: 52f1f7d7-e958-5bc4-ec17-0dc2c37827c2</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2ab2b</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 10430866802188591318</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f1b6b</span><br><span class="line">   Device: naa.5000c500a00f1b6b</span><br><span class="line">   Display Name: naa.5000c500a00f1b6b</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 529e3c65-9d00-2c8f-644f-5067e3e0d088</span><br><span class="line">   VSAN Disk Group UUID: 52c135c7-7e04-46b8-310f-cf9bcb8d2f67</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a74f</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 11097355537749729337</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f153f</span><br><span class="line">   Device: naa.5000c500a00f153f</span><br><span class="line">   Display Name: naa.5000c500a00f153f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52a2510b-bb61-7872-dd43-809c6bd828c3</span><br><span class="line">   VSAN Disk Group UUID: 52f1f7d7-e958-5bc4-ec17-0dc2c37827c2</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2ab2b</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 13296496943739866255</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c5009ff7dd1f</span><br><span class="line">   Device: naa.5000c5009ff7dd1f</span><br><span class="line">   Display Name: naa.5000c5009ff7dd1f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52b1a600-c030-4e14-35b2-7b57633d2b04</span><br><span class="line">   VSAN Disk Group UUID: 52365b5c-770b-47cf-c52b-35c0c128a2aa</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a793</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 15823456994777709316</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c5009ff7e7d3</span><br><span class="line">   Device: naa.5000c5009ff7e7d3</span><br><span class="line">   Display Name: naa.5000c5009ff7e7d3</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52b7dc26-4d27-2f3d-bd32-3ca432e12c40</span><br><span class="line">   VSAN Disk Group UUID: 52365b5c-770b-47cf-c52b-35c0c128a2aa</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a793</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 611224759886110838</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f1a67</span><br><span class="line">   Device: naa.5000c500a00f1a67</span><br><span class="line">   Display Name: naa.5000c500a00f1a67</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52baed5a-dd43-162e-d9a4-37fd0d105a19</span><br><span class="line">   VSAN Disk Group UUID: 52c135c7-7e04-46b8-310f-cf9bcb8d2f67</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a74f</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 12162743074844331869</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">Unknown</span><br><span class="line">   Device: Unknown</span><br><span class="line">   Display Name: Unknown</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52bcc0f0-20bf-9809-0497-10dd1095be21</span><br><span class="line">   VSAN Disk Group UUID:</span><br><span class="line">   VSAN Disk Group Name:</span><br><span class="line">   Used by this host: false</span><br><span class="line">   In CMMDS: false</span><br><span class="line">   On-disk format version: &lt;Unknown&gt;</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum:</span><br><span class="line">   Checksum OK: false</span><br><span class="line">   Is Capacity Tier: false</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.55cd2e414dc2a74f</span><br><span class="line">   Device: naa.55cd2e414dc2a74f</span><br><span class="line">   Display Name: naa.55cd2e414dc2a74f</span><br><span class="line">   Is SSD: true</span><br><span class="line">   VSAN UUID: 52c135c7-7e04-46b8-310f-cf9bcb8d2f67</span><br><span class="line">   VSAN Disk Group UUID: 52c135c7-7e04-46b8-310f-cf9bcb8d2f67</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a74f</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 7048580772559521847</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: false</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c5009ff7ce3f</span><br><span class="line">   Device: naa.5000c5009ff7ce3f</span><br><span class="line">   Display Name: naa.5000c5009ff7ce3f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52c327cc-eada-56d1-42dc-6929b84febc2</span><br><span class="line">   VSAN Disk Group UUID: 52f1f7d7-e958-5bc4-ec17-0dc2c37827c2</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2ab2b</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 10423011473630675163</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c5009ff7df2f</span><br><span class="line">   Device: naa.5000c5009ff7df2f</span><br><span class="line">   Display Name: naa.5000c5009ff7df2f</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52c38b0f-2f48-8bb2-d553-9ba61597dce9</span><br><span class="line">   VSAN Disk Group UUID: 52365b5c-770b-47cf-c52b-35c0c128a2aa</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a793</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 7799784318771514205</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f1cff</span><br><span class="line">   Device: naa.5000c500a00f1cff</span><br><span class="line">   Display Name: naa.5000c500a00f1cff</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52c72b87-28bc-5d8f-5836-24fbb2877ebc</span><br><span class="line">   VSAN Disk Group UUID: 52c135c7-7e04-46b8-310f-cf9bcb8d2f67</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a74f</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 6569778864705005501</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f18bf</span><br><span class="line">   Device: naa.5000c500a00f18bf</span><br><span class="line">   Display Name: naa.5000c500a00f18bf</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52c783e7-cbb6-a744-610c-c6ae2e60f3b7</span><br><span class="line">   VSAN Disk Group UUID: 52f1f7d7-e958-5bc4-ec17-0dc2c37827c2</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2ab2b</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 7411470762398268100</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c5009ff7de27</span><br><span class="line">   Device: naa.5000c5009ff7de27</span><br><span class="line">   Display Name: naa.5000c5009ff7de27</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52e18440-c49c-840c-015c-dacd4c628bbe</span><br><span class="line">   VSAN Disk Group UUID: 52365b5c-770b-47cf-c52b-35c0c128a2aa</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2a793</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 8746191856592791521</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.55cd2e414dc2ab2b</span><br><span class="line">   Device: naa.55cd2e414dc2ab2b</span><br><span class="line">   Display Name: naa.55cd2e414dc2ab2b</span><br><span class="line">   Is SSD: true</span><br><span class="line">   VSAN UUID: 52f1f7d7-e958-5bc4-ec17-0dc2c37827c2</span><br><span class="line">   VSAN Disk Group UUID: 52f1f7d7-e958-5bc4-ec17-0dc2c37827c2</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2ab2b</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 10413205729763414046</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: false</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line"></span><br><span class="line">naa.5000c500a00f145b</span><br><span class="line">   Device: naa.5000c500a00f145b</span><br><span class="line">   Display Name: naa.5000c500a00f145b</span><br><span class="line">   Is SSD: false</span><br><span class="line">   VSAN UUID: 52f816d8-3fae-ab01-4a26-5ac21a14ef03</span><br><span class="line">   VSAN Disk Group UUID: 52f1f7d7-e958-5bc4-ec17-0dc2c37827c2</span><br><span class="line">   VSAN Disk Group Name: naa.55cd2e414dc2ab2b</span><br><span class="line">   Used by this host: true</span><br><span class="line">   In CMMDS: true</span><br><span class="line">   On-disk format version: 5</span><br><span class="line">   Deduplication: false</span><br><span class="line">   Compression: false</span><br><span class="line">   Checksum: 3336449902296012883</span><br><span class="line">   Checksum OK: true</span><br><span class="line">   Is Capacity Tier: true</span><br><span class="line">   Encryption: false</span><br><span class="line">   DiskKeyLoaded: false</span><br><span class="line">   Creation Time: Unknown</span><br><span class="line">[root@vsan13:~]</span><br><span class="line">[root@vsan13:~]</span><br><span class="line">[root@vsan13:~]</span><br><span class="line">[root@vsan13:~] esxcli vsan storage remove</span><br><span class="line">No option provided</span><br><span class="line">[root@vsan13:~] esxcli vsan storage remove --help</span><br><span class="line">Usage: esxcli vsan storage remove [cmd options]</span><br><span class="line"></span><br><span class="line">Description:</span><br><span class="line">  remove                Remove physical disks from vSAN disk groups.</span><br><span class="line"></span><br><span class="line">Cmd options:</span><br><span class="line">  -d|--disk=&lt;str&gt;       Specify individual hdd to remove from vSAN usage.e.g.: mpx.vmhba2:C0:T1:L0</span><br><span class="line">  -m|--evacuation-mode=&lt;str&gt;</span><br><span class="line">                        Action the vSAN service must take before the host can enter maintenance mode (default noAction). Allowed values are:</span><br><span class="line">                            ensureObjectAccessibility: Evacuate data from the disk to ensure object accessibility in the vSAN cluster, before removing the disk.</span><br><span class="line">                            evacuateAllData: Evacuate all data from the disk before removing it.</span><br><span class="line">                            noAction: Do not move vSAN data out of the disk before removing it.</span><br><span class="line">  -s|--ssd=&lt;str&gt;        Specify a disk group&#x27;s fronting ssd to remove the ssd and each backing hdd from vSAN usage.e.g.: mpx.vmhba2:C0:T1:L0</span><br><span class="line">  -u|--uuid=&lt;str&gt;       Specify UUID of vSAN disk.e.g.: 52afa1de-4240-d5d6-17f9-8af1ec8509e5</span><br><span class="line">[root@vsan13:~] esxcli vsan storage remove --uuid=52bcc0f0-20bf-9809-0497-10dd1095be21</span><br><span class="line">[root@vsan13:~] esxcli vsan storage list | grep UUID |grep 0497</span><br><span class="line">[root@vsan13:~]</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
            <tag> vSAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vSAN集群 无法识别磁盘处理</title>
      <link href="/posts/28638/"/>
      <url>/posts/28638/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="vSAN集群-无法识别磁盘处理"><a href="#vSAN集群-无法识别磁盘处理" class="headerlink" title="vSAN集群 无法识别磁盘处理"></a>vSAN集群 无法识别磁盘处理</h1><p>搭建联想服务器vSAN集群，搭建过程中遇到了SD卡RAID问题一些问题，搭建过程中有3台服务器都顺利加入vSAN集群，磁盘组缓存层和容量层都正常并且正常使用。最后再新增2个节点时出现2个节点只能识别部分磁盘，其中无法识别的磁盘中包括SSD，导致无法创建磁盘组，无法并入vsandatastore。</p><p>单节点共计8个磁盘，vSAN磁盘组无法识别闪存盘，但是节点物理层可以识别出闪存盘</p><img src="/posts/28638/24772838-f98ca7af76969157.png" class=""><img src="/posts/28638/24772838-5f3c3f5176326f58.png" class=""><p>尝试了很多种方法都没能解决，最后突然之间想到可能是由于vSAN集群是重建的，这块盘虽然现在没有被使用，但是它以前曾经被作为datastore，可能还有遗留的分区表。</p><p>SSH连接ESXI,查看磁盘信息</p><p>运行以下命令，获取所有磁盘信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">esxcli storage core device list</span><br></pre></td></tr></table></figure><img src="/posts/28638/24772838-7fa25a4e8a02f79e.png" class=""><p>获取SSD磁盘信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">partedUtil get /vmfs/devices/disks/naa.600605b00c30f7e027e6d4c16c0d55ff</span><br></pre></td></tr></table></figure><img src="/posts/28638/24772838-0216793671cb58ff.png" class=""><p>删除残留分区信息表</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">partedUtil delete /vmfs/devices/disks/naa.600605b00c30f7e027e6d4c16c0d55ff 1</span><br><span class="line"></span><br><span class="line">partedUtil delete /vmfs/devices/disks/naa.600605b00c30f7e027e6d4c16c0d55ff 2</span><br><span class="line"></span><br><span class="line">partedUtil delete /vmfs/devices/disks/naa.600605b00c30f7e027e6d4c16c0d55ff 3</span><br></pre></td></tr></table></figure><img src="/posts/28638/24772838-ad24094d15b4b2b7.png" class=""><p>另外一个节点出现2个磁盘无法识别，情况不太一样，报</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: The primary GPT table states that the backup GPT is located beyond the end of disk.</span><br></pre></td></tr></table></figure><img src="/posts/28638/24772838-6e62e9f1be804dc6.png" class=""><p>需要重做分区，命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">partedUtil mklabel /vmfs/devices/disks/naa.600605b00cc7ae8027e8b92329e47a6b msdos</span><br><span class="line"></span><br><span class="line">partedUtil get /vmfs/devices/disks/naa.600605b00cc7ae8027e8b92329e47a6b</span><br></pre></td></tr></table></figure><img src="/posts/28638/24772838-7cfa986f81250532.png" class=""><p>可以配置vSAN磁盘组</p>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
            <tag> vSAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>离线更新vSAN HCL数据库</title>
      <link href="/posts/23344/"/>
      <url>/posts/23344/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="离线更新vSAN-HCL数据库"><a href="#离线更新vSAN-HCL数据库" class="headerlink" title="离线更新vSAN HCL数据库"></a>离线更新vSAN HCL数据库</h1><p>从VSAN 6.0起，VSAN提供了Health Check功能，其中就包括VSAN HCL数据库，通过此运行状况检查验证用于 HCL 检查的 VMware 兼容性指南数据库是否是最新的。这些 VCG 检查并非根据 VMware 网站上的 HCL 执行，而是根据存储在 vCenter Server 上的副本执行。运行状况功能的初始版本随发布当时最新的 HCL 数据库的副本提供。随着时间的推移，此数据库副本将过时。 向 VCG 添加合作伙伴的新认证后尤其如此。 硬件供应商会定期更新驱动程序，VMware 会为这些驱动程序添加认证。甚至可能会从 VCG 删除旧驱动程序以反映发现的问题。 因此，保持本地副本是最新版本非常重要。</p><p>在VSAN的配置中的运行状况，可以看到HCL数据库的上次更新日期，同时右侧有两种更新方式，如果你的环境中允许vCenter Server连接到互联网可以定期联网获取最新版本，如果环境中不允许联网，这时候可以通过离线的文件进行更新；问题是这个离线的数据库在哪里下载？</p><img src="/posts/23344/wKioL1bgFZ7ivxZeAAELZodljAs742.png" class=""><p>下载离线VSAN HCL文件实际上只是一个JSON文件,你只需要上面的URL加载到web浏览器,然后保存文件。</p><p>在浏览器中打开以下网址:</p><p><a href="http://partnerweb.vmware.com/service/vsan/all.json">http://partnerweb.vmware.com/service/vsan/all.json</a></p><p>打开后如下，其实细心观察就可以发现这就是一个记录着相关HCL的一些信息，只需要将这个从Web另存为保存即可，你会得到一个.json文件</p><p>PS：突发奇想，在现在VMware VSAN的官方兼容性列表中没有单独配件的兼容性和列表，之后其合作伙伴验证过的Ready Node，那么我们是否可以直接在这个网页中查找型号的配置，如某种阵列卡，而去查找兼容性信息</p><img src="/posts/23344/wKioL1bgFvbBzUNVAAEKJu8-pEM769.png" class="wKioL1bgFoDzrt4nAAW0d81C2Uk064.png%然后返回到VSAN的配置界面，选择从文件更新，选择刚才另存为的文件 {%asset_img"><p>上传成功后可以发现其更新日期已经更改为今天   </p><img src="/posts/23344/wKiom1bgFoSytYqoAADTHbwkmUw239.png" class=""><p>并且在VSAN的运行状况中，VSAN HCL数据库最新版本也显示通过了</p><img src="/posts/23344/wKiom1bgFrKD_bt2AAEJk6jAzc4700.png" class="">]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
            <tag> vSAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos7安装Zabbix 5.0 LTS 版本安装</title>
      <link href="/posts/43194/"/>
      <url>/posts/43194/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="Centos7安装Zabbix-5-0-LTS-版本安装"><a href="#Centos7安装Zabbix-5-0-LTS-版本安装" class="headerlink" title="Centos7安装Zabbix 5.0 LTS 版本安装"></a>Centos7安装Zabbix 5.0 LTS 版本安装</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Zabbix是一款开源免费的服务器监控管理软件，其功能强大、配置简单、可外接Grafana图形可视化，是企业运维监控软件的首选。</p><p><a href="https://www.zabbix.com/documentation/current/manual/introduction/whatsnew500">zabbix 5.0</a> 版本于 5 月 11 日正式发布，是最新的 LTS（长期支持）版本，5.0 带来很多功能和特性，详细见官方文档。</p><h2 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h2><ul><li>Centos 7.8</li><li>PHP 7.2 （从Zabbix 5.0开始）</li><li>MariaDB或者Mysql5.7版本以上</li></ul><p><strong>硬件配置</strong></p><table><thead><tr><th>名称</th><th>平台</th><th>CPU /内存</th><th>数据库</th><th>监控主机</th></tr></thead><tbody><tr><td>小</td><td>CentOS</td><td>虚拟设备</td><td>MySQL的InnoDB</td><td>100</td></tr><tr><td>中</td><td>CentOS</td><td>2个CPU核心/ 2GB</td><td>MySQL的InnoDB</td><td>500</td></tr><tr><td>大</td><td>红帽企业Linux</td><td>4个CPU核心/ 8GB</td><td>RAID10 MySQL InnoDB或PostgreSQL</td><td>&gt; 1000</td></tr><tr><td>很大</td><td>红帽企业Linux</td><td>8个CPU核心/ 16GB</td><td>快速RAID10 MySQL InnoDB或PostgreSQL</td><td>&gt; 10000</td></tr></tbody></table><h2 id="YUM-安装"><a href="#YUM-安装" class="headerlink" title="YUM 安装"></a>YUM 安装</h2><p>关闭防火墙和 selinux 并重启</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;s/SELINUX=enforcing/SELINUX=disabled/&#x27; /etc/selinux/config</span><br><span class="line">systemctl disable --now firewalld</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><p>安装 zabbix rpm 源,鉴于国内网络情况，使用阿里云 zabbix 源</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm -Uvh https://mirrors.aliyun.com/zabbix/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm</span><br><span class="line">sed -i &#x27;s#http://repo.zabbix.com#https://mirrors.aliyun.com/zabbix#&#x27; /etc/yum.repos.d/zabbix.repo</span><br><span class="line">yum clean all</span><br></pre></td></tr></table></figure><p>安装 zabbix server 和 agent</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install zabbix-server-mysql zabbix-agent -y</span><br></pre></td></tr></table></figure><p>安装 Software Collections，便于后续安装高版本的 php，默认 yum 安装的 php 版本为 5.4 过低</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install centos-release-scl -y</span><br></pre></td></tr></table></figure><p>启用 zabbix 前端源，修改vi /etc/yum.repos.d/zabbix.repo，将[zabbix-frontend]下的 enabled 改为 1</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">enabled=1</span><br></pre></td></tr></table></figure><p>安装 zabbix 前端和相关环境</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install zabbix-web-mysql-scl zabbix-apache-conf-scl -y</span><br></pre></td></tr></table></figure><p>yum 安装 centos7 默认的 mariadb 数据库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install mariadb-server -y</span><br></pre></td></tr></table></figure><p>启动数据库，并配置开机自动启动</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable --now mariadb</span><br></pre></td></tr></table></figure><p>使用 root 用户进入 mysql，并建立 zabbix 数据库，注意数据库编码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create database zabbix character set utf8 collate utf8_bin;</span><br><span class="line">create user zabbix@localhost identified by &#x27;password&#x27;;</span><br><span class="line">grant all privileges on zabbix.* to zabbix@localhost;</span><br><span class="line">quit;</span><br></pre></td></tr></table></figure><p>使用以下命令导入 zabbix 数据库，zabbix 数据库用户为 zabbix，密码为 password</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix</span><br></pre></td></tr></table></figure><p>修改 zabbix server 配置文件vi /etc/zabbix/zabbix_server.conf 里的数据库密码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DBPassword=password</span><br></pre></td></tr></table></figure><p>修改 zabbix 的 php 配置文件vi /etc/opt/rh/rh-php72/php-fpm.d/zabbix.conf 里的时区，改成 Asia/Shanghai</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">php_value[date.timezone] = Asia/Shanghai</span><br></pre></td></tr></table></figure><p>启动相关服务，并配置开机自动启动</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart zabbix-server zabbix-agent httpd rh-php72-php-fpm</span><br><span class="line">systemctl enable zabbix-server zabbix-agent httpd rh-php72-php-fpm</span><br></pre></td></tr></table></figure><p>使用浏览器访问<a href="http://ip/zabbix">http://ip/zabbix</a> 即可访问 zabbix 的 web 页面</p><h2 id="WEB-初始化"><a href="#WEB-初始化" class="headerlink" title="WEB 初始化"></a>WEB 初始化</h2><img src="/posts/43194/image-38.png" class=""><p>检查各个组件配置是否正常</p><img src="/posts/43194/image-40.png" class=""><p>输入刚配置的数据库 zabbix 用户的密码</p><img src="/posts/43194/image-42.png" class=""><p>下一步</p><img src="/posts/43194/image-43.png" class=""><p>下一步</p><img src="/posts/43194/image-45.png" class=""><img src="/posts/43194/image-46.png" class=""><p>登录账号为 <strong>Admin</strong>，密码：<strong>zabbix</strong></p><img src="/posts/43194/image-48.png" class=""><p>首页</p><img src="/posts/43194/image-50.png" class="">]]></content>
      
      
      
        <tags>
            
            <tag> Zabbix </tag>
            
            <tag> CentOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac book 配置内外网路由</title>
      <link href="/posts/22210/"/>
      <url>/posts/22210/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="Mac-book-配置内外网路由"><a href="#Mac-book-配置内外网路由" class="headerlink" title="Mac book 配置内外网路由"></a>Mac book 配置内外网路由</h1><h2 id="外网："><a href="#外网：" class="headerlink" title="外网："></a>外网：</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">网关：192.168.0.1</span><br><span class="line">本机ip：192.168.0.2</span><br></pre></td></tr></table></figure><h2 id="内网："><a href="#内网：" class="headerlink" title="内网："></a>内网：</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">网关：172.16.0.1</span><br><span class="line">本机ip：172.16.0.2 </span><br></pre></td></tr></table></figure><p>1、在终端里输入 ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -nr  #查看现在的路由表</span><br></pre></td></tr></table></figure><p>2、查看默认路由：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route get 0.0.0.0 #查看0.0.0.0路由表 </span><br></pre></td></tr></table></figure><p>3、删掉所有的默认路由：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo route -n delete default 0.0.0.0</span><br></pre></td></tr></table></figure><p>4、再重新添加需要的默认路由，一般是走公网的网关：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo route add -net 0.0.0.0 192.168.0.1 #输入你的管理员密码。192.168.0.1根据自己外网网关修改。 </span><br></pre></td></tr></table></figure><p>5、再加上内网的路由，到内网服务器地址，走内网网关：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo route add -net 172.16.0.0 172.16.0.1 #输入你的管理员密码。172.16.0.1根据自己内网网关修改。</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> route </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>windows 配置内外网路由</title>
      <link href="/posts/60862/"/>
      <url>/posts/60862/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="windows-配置内外网路由"><a href="#windows-配置内外网路由" class="headerlink" title="windows 配置内外网路由"></a>windows 配置内外网路由</h1><p>外网：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">网关：192.168.0.1</span><br><span class="line">本机ip：192.168.0.2</span><br></pre></td></tr></table></figure><p>内网：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">网关：172.16.0.1</span><br><span class="line">本机ip：172.16.0.2</span><br></pre></td></tr></table></figure><p>1、在终端里输入 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route print -4 #查看IPv4路由表</span><br></pre></td></tr></table></figure><p>2、删掉所有的默认路由：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route delete 0.0.0.0</span><br></pre></td></tr></table></figure><p>4、再重新添加需要的默认路由，一般是走公网的网关：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route add 0.0.0.0 mask 0.0.0.0 192.168.0.1</span><br></pre></td></tr></table></figure><p>5、再加上内网的路由，到内网服务器地址，走内网网关：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route add 10.0.0.0 mask 255.0.0.0 172.16.0.1</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> route </tag>
            
            <tag> windows </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>主流系统和产品添加静态路由的方法</title>
      <link href="/posts/51142/"/>
      <url>/posts/51142/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="主流系统和产品添加静态路由的方法"><a href="#主流系统和产品添加静态路由的方法" class="headerlink" title="主流系统和产品添加静态路由的方法"></a>主流系统和产品添加静态路由的方法</h1><p>本文描述主流系统和产品添加静态路由的方法，一些具备 WEB 管理界面的产品不在讨论范围，比如防火墙、路由器等多数产品具备直观的操作界面。</p><h2 id="macOS"><a href="#macOS" class="headerlink" title="macOS"></a>macOS</h2><p>1、添加路由命令（临时）</p><blockquote><p>与 Linux 类似，但是网关没有 gw 参数（同 FreeBSD）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 查看当前路由表</span><br><span class="line">netstat -rn</span><br><span class="line"></span><br><span class="line"># 获取默认路由</span><br><span class="line">route get 0.0.0.0</span><br><span class="line"></span><br><span class="line"># 删除默认路由</span><br><span class="line">sudo route -n delete default 10.2.0.1</span><br><span class="line"></span><br><span class="line"># 添加默认路由</span><br><span class="line">sudo route add -net 0.0.0.0 10.2.0.1</span><br><span class="line"></span><br><span class="line"># 添加静态路由</span><br><span class="line">sudo route add -net 10.16.0.0 10.18.18.10</span><br><span class="line">sudo route add -net 10.16.0.0/16 10.18.18.10</span><br><span class="line">sudo route -n add -net 192.168.2.0 -netmask 255.255.255.0 192.168.5.254</span><br></pre></td></tr></table></figure></blockquote><p>2、使用 networksetup 命令设置永久静态路由</p><p>可以适用于 macOS Big Sur。</p><p>macOS 提供了一个名为 networksetup 的命令行界面，它允许您进行各种网络配置。</p><p>可以通过 networksetup –help 查看具体的帮助。其实它就是 “系统偏好设置” 中网络设置工具的命令行版本，但是功能更为强大一些。</p><p>使用 networksetup 命令添加永久静态路由，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 语法</span><br><span class="line">networksetup -getadditionalroutes &lt;networkservice&gt;</span><br><span class="line">networksetup -setadditionalroutes &lt;networkservice&gt; [ &lt;dest&gt; &lt;mask&gt; &lt;gateway&gt; ]</span><br><span class="line"></span><br><span class="line"># 查看 &lt;networkservice&gt;</span><br><span class="line">networksetup -listallnetworkservices</span><br><span class="line"># 这里显示如下</span><br><span class="line">Wi-Fi</span><br><span class="line">iPhone USB</span><br><span class="line">Bluetooth PAN</span><br><span class="line">Thunderbolt Bridge</span><br><span class="line"></span><br><span class="line"># 添加静态路由</span><br><span class="line">networksetup -setadditionalroutes &quot;Wi-Fi&quot; 10.18.1.0 255.255.255.0 192.168.1.1</span><br><span class="line">networksetup -setadditionalroutes &quot;Wi-Fi&quot; 10.16.0.0 255.255.0.0 192.168.1.1</span><br></pre></td></tr></table></figure><p>解释：</p><ul><li>“Wi-Fi” 指定路由走哪个设备（使用命令 networksetup -listallnetworkservices 查看当前的设备）</li><li>10.18.1.0/24 和 10.16.0.0 都指向 192.169.1.1</li></ul><p>验证：</p><p>使用 netstat -nr 查看路由表。</p><p>清空路由：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">networksetup -setadditionalroutes Wi-Fi</span><br></pre></td></tr></table></figure><p>再次用 netstat -rn 查看路由可以看到添加的路由没有了。</p><h2 id="FreeBSD"><a href="#FreeBSD" class="headerlink" title="FreeBSD"></a>FreeBSD</h2><p>临时：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route add -net 10.10.1.0/24 10.10.1.1</span><br></pre></td></tr></table></figure><blockquote><p>与 Linux 类似，但是网关没有 gw 参数（同 macOS）</p></blockquote><p>永久：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/rc.conf</span><br></pre></td></tr></table></figure><p>Set default router IP to 60.1.2.3:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">defaultrouter=``&quot;60.1.2.3&quot;</span><br></pre></td></tr></table></figure><p>Create static routing for lan network 192.168.1.0/24, append following two lines:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">static_routes=``&quot;lan&quot;``route_lan=``&quot;-net 192.168.1.0/24 192.168.1.254&quot;</span><br></pre></td></tr></table></figure><p>How do I add multiple static routes?</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">      network                             router IP</span><br><span class="line">lan (192.168.1.0/24)                192.168.1.254</span><br><span class="line">mumoffice (10.0.0.0/8)        10.30.110.5</span><br><span class="line">foo 169.254.1.1                        via loopback (lo0)</span><br></pre></td></tr></table></figure><p>Add following to /etc/rc.conf</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">static_routes=``&quot;lan mumoffice foo&quot;``route_lan=``&quot;-net 192.168.1.0/24 192.168.1.254&quot;``route_mumoffice=``&quot;-net 10.0.0.0/8 10.30.110.5&quot;``route_foo=``&quot;-host 169.254.1.1 -iface lo0&quot;</span><br></pre></td></tr></table></figure><h2 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route add -p 10.0.0.0 mask 255.0.0.0 10.10.16.1``// -p 参数永久添加，不用 -p 为临时生效``route add -p 10.10.11.0 mask 255.255.255.0 10.10.12.1``route add -p 10.10.13.0 mask 255.255.255.0 10.10.12.1``route add -p 10.10.14.0 mask 255.255.255.0 10.10.12.1</span><br></pre></td></tr></table></figure><h2 id="Cisco"><a href="#Cisco" class="headerlink" title="Cisco"></a>Cisco</h2><h3 id="Cisco-IOS、IOS-XE"><a href="#Cisco-IOS、IOS-XE" class="headerlink" title="Cisco IOS、IOS-XE"></a>Cisco IOS、IOS-XE</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip route 10.0.0.0 255.0.0.0 10.10.200.2254</span><br><span class="line">ip route 10.10.11.0 255.255.255.0 10.10.12.1</span><br></pre></td></tr></table></figure><h3 id="Cisco-NX-OS"><a href="#Cisco-NX-OS" class="headerlink" title="Cisco NX-OS"></a>Cisco NX-OS</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">N7K(config)#vrf context management</span><br><span class="line">N7K(config-vrf)# ip route 0.0.0.0/0 &lt;下一跳 IP&gt;</span><br></pre></td></tr></table></figure><h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><h3 id="Linux（通用，临时）"><a href="#Linux（通用，临时）" class="headerlink" title="Linux（通用，临时）"></a>Linux（通用，临时）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route add -net 10.10.11.0/24 gw 10.10.1.1</span><br></pre></td></tr></table></figure><h3 id="CentOS（永久）"><a href="#CentOS（永久）" class="headerlink" title="CentOS（永久）"></a>CentOS（永久）</h3><p>推荐方式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">echo &#x27;</span><br><span class="line">10.10.12.0/24 via 10.10.15.1</span><br><span class="line">10.10.13.0/24 via 10.10.15.1</span><br><span class="line">10.10.14.0/24 via 10.10.15.1</span><br><span class="line">10.10.15.0/24 via 10.10.15.1</span><br><span class="line">10.10.16.0/24 via 10.10.15.1</span><br><span class="line">&#x27; &gt; /etc/sysconfig/network-scripts/route-eth0</span><br></pre></td></tr></table></figure><p>另外一种方法：使用 network.service（CentOS7 默认，CentOS8 需要 <code>yum install network-scripts</code>）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">echo &#x27;</span><br><span class="line">any net 10.10.13.0/24 gw 10.10.15.1</span><br><span class="line">any net 10.10.14.0/24 gw 10.10.15.1</span><br><span class="line">any net 10.10.15.0/24 gw 10.10.15.1</span><br><span class="line">any net 10.10.16.0/24 gw 10.10.15.1</span><br><span class="line">&#x27; &gt; /etc/sysconfig/static-routes</span><br></pre></td></tr></table></figure><p>验证</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip route</span><br></pre></td></tr></table></figure><h3 id="Debian（永久）"><a href="#Debian（永久）" class="headerlink" title="Debian（永久）"></a>Debian（永久）</h3><p>Debian 11：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#添加</span><br><span class="line">cat &gt;&gt; /etc/network/interfaces &lt;&lt;EOF</span><br><span class="line"># static routes</span><br><span class="line">up ip route add 10.10.12.0/24 via 10.10.1.1 dev eth0</span><br><span class="line">up ip route add 10.10.13.0/24 via 10.10.1.1 dev eth0</span><br><span class="line">up ip route add 10.10.14.0/24 via 10.10.1.1 dev eth0</span><br><span class="line">up ip route add 10.10.15.0/24 via 10.10.1.1 dev eth0</span><br><span class="line">up ip route add 10.10.16.0/24 via 10.10.1.1 dev eth0</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#重启网络</span><br><span class="line">systemctl restart networking</span><br><span class="line"></span><br><span class="line">#验证</span><br><span class="line">ip route</span><br></pre></td></tr></table></figure><h3 id="Ubuntu-16-04（永久）"><a href="#Ubuntu-16-04（永久）" class="headerlink" title="Ubuntu 16.04（永久）"></a>Ubuntu 16.04（永久）</h3><p>16.04</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#添加</span><br><span class="line">cat &gt;&gt; /etc/network/interfaces &lt;&lt;EOF</span><br><span class="line"># static routes</span><br><span class="line">up route add -net 10.10.12.0/24 gw 10.10.15.1 dev eth0</span><br><span class="line">up route add -net 10.10.13.0/24 gw 10.10.15.1 dev eth0</span><br><span class="line">up route add -net 10.10.14.0/24 gw 10.10.15.1 dev eth0</span><br><span class="line">up route add -net 10.10.15.0/24 gw 10.10.15.1 dev eth0</span><br><span class="line">up route add -net 10.10.16.0/24 gw 10.10.15.1 dev eth0</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#重启网络</span><br><span class="line">service networking restart</span><br><span class="line"></span><br><span class="line">#验证</span><br><span class="line">ip route</span><br></pre></td></tr></table></figure><h3 id="NetPlan（永久）"><a href="#NetPlan（永久）" class="headerlink" title="NetPlan（永久）"></a><a href="https://netplan.io/examples">NetPlan</a>（永久）</h3><p>Ubuntu 18.04、20.04 及以上</p><p>18.04: /etc/netplan/50-cloud-init.yaml</p><p>20.04：/etc/netplan/00-installer-config.yaml</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  ethernets:</span><br><span class="line">    eth0:</span><br><span class="line">      addresses:</span><br><span class="line">      - 10.10.15.5/24</span><br><span class="line">      gateway4: 10.10.15.1</span><br><span class="line">      nameservers:</span><br><span class="line">        addresses:</span><br><span class="line">        - 10.10.15.11</span><br><span class="line">        - 10.10.15.12</span><br><span class="line">        search:</span><br><span class="line">        - sysin.org</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 注释 gateway4</span><br><span class="line">sed -i &#x27;s/gateway4.*/#&amp;/&#x27; /etc/netplan/00-installer-config.yaml</span><br><span class="line"># 追加静态路由</span><br><span class="line">cat &gt;&gt; /etc/netplan/00-installer-config.yaml &lt;&lt;EOF</span><br><span class="line">      routes:</span><br><span class="line">        - to: 0.0.0.0/0</span><br><span class="line">          via: 10.10.15.254</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 10.10.12.0/24</span><br><span class="line">          via: 10.10.15.1</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 10.10.13.0/24</span><br><span class="line">          via: 10.10.15.1</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 10.10.14.0/24</span><br><span class="line">          via: 10.10.15.1</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 10.10.15.0/24</span><br><span class="line">          via: 10.10.15.1</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 10.10.16.0/24</span><br><span class="line">          via: 10.10.15.1</span><br><span class="line">          metric: 100</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>metric：为路由指定所需跃点数的整数值（范围是 1 ~ 9999），Metric 的值越小，优先级越高。</p><p>完整配置示例（&gt; 覆盖）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/netplan/00-installer-config.yaml &lt;&lt;EOF</span><br><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  ethernets:</span><br><span class="line">    eth0:</span><br><span class="line">      addresses:</span><br><span class="line">        - 10.10.15.57/24</span><br><span class="line">      #gateway4: 10.10.15.254</span><br><span class="line">      nameservers:</span><br><span class="line">        addresses:</span><br><span class="line">          - 10.10.15.11</span><br><span class="line">          - 10.10.15.12</span><br><span class="line">        search:</span><br><span class="line">          - sysin.org</span><br><span class="line">      routes:</span><br><span class="line">        - to: 0.0.0.0/0</span><br><span class="line">          via: 10.10.15.254</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 10.10.12.0/24</span><br><span class="line">          via: 10.10.15.1</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 10.10.13.0/24</span><br><span class="line">          via: 10.10.15.1</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 10.10.14.0/24</span><br><span class="line">          via: 10.10.15.1</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 10.10.15.0/24</span><br><span class="line">          via: 10.10.15.1</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 10.10.16.0/24</span><br><span class="line">          via: 10.10.15.1</span><br><span class="line">          metric: 100</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>多网关</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: networkd</span><br><span class="line">  ethernets:</span><br><span class="line">    eth0:</span><br><span class="line">      addresses:</span><br><span class="line">        - 9.0.0.9/24</span><br><span class="line">        - 10.0.0.10/24</span><br><span class="line">        - 11.0.0.11/24</span><br><span class="line">      #gateway4:  # unset, since we configure routes below</span><br><span class="line">      routes:</span><br><span class="line">        - to: 0.0.0.0/0</span><br><span class="line">          via: 9.0.0.1</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 0.0.0.0/0</span><br><span class="line">          via: 10.0.0.1</span><br><span class="line">          metric: 100</span><br><span class="line">        - to: 0.0.0.0/0</span><br><span class="line">          via: 11.0.0.1</span><br><span class="line">          metric: 100</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netplan apply</span><br></pre></td></tr></table></figure><p>补充：yaml 基础</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">大小写敏感</span><br><span class="line">使用缩进表示层级关系</span><br><span class="line">缩进时不允许使用 Tab 键，只允许使用空格</span><br><span class="line">缩进的空格数目不重要，只要相同层级的元素左侧对齐即可</span><br></pre></td></tr></table></figure><p>缩进建议使用 2 个空格，使用短横线 “-” 表示列表时，”- “后面的条目需要对齐，如果使用超过 2 个空格缩进，格式将有误。</p><h2 id="VMware"><a href="#VMware" class="headerlink" title="VMware"></a>VMware</h2><h3 id="VMware-ESXi"><a href="#VMware-ESXi" class="headerlink" title="VMware ESXi"></a>VMware ESXi</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#查看路由</span><br><span class="line">esxcfg-route -l</span><br><span class="line">#添加</span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.15.1 --network 10.10.12.0/24</span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.15.1 --network 10.10.13.0/24</span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.15.1 --network 10.10.14.0/24</span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.15.1 --network 10.10.15.0/24</span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.15.1 --network 10.10.16.0/24</span><br><span class="line">#删除默认路由</span><br><span class="line">esxcli network ip route ipv4 remove -n 0.0.0.0/0 -g 10.10.15.1</span><br><span class="line">#恢复默认路由</span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.15.254 --network 0.0.0.0/0</span><br><span class="line">#查看路由</span><br><span class="line">esxcfg-route -l</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">esxcfg-route -l</span><br><span class="line"></span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.14.1 --network 10.10.12.0/24</span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.14.1 --network 10.10.13.0/24</span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.14.1 --network 10.10.14.0/24</span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.14.1 --network 10.10.15.0/24</span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.14.1 --network 10.10.16.0/24</span><br><span class="line"></span><br><span class="line">esxcli network ip route ipv4 remove -n 0.0.0.0/0 -g 10.10.14.1</span><br><span class="line"></span><br><span class="line">esxcli network ip route ipv4 add --gateway 10.10.14.254 --network 0.0.0.0/0</span><br><span class="line"></span><br><span class="line">esxcfg-route -l</span><br></pre></td></tr></table></figure><h3 id="NSX-T"><a href="#NSX-T" class="headerlink" title="NSX-T"></a>NSX-T</h3><p>基于 Ubuntu，但不可手动编辑，以下为 nsxcli (使用 admin 账号登录)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">set route prefix 0.0.0.0/0 gateway 10.10.15.254 interface eth0</span><br><span class="line"></span><br><span class="line">set route prefix 10.10.12.0/24 gateway 10.10.15.1 interface eth0</span><br><span class="line">set route prefix 10.10.13.0/24 gateway 10.10.15.1 interface eth0</span><br><span class="line">set route prefix 10.10.14.0/24 gateway 10.10.15.1 interface eth0</span><br><span class="line">set route prefix 10.10.15.0/24 gateway 10.10.15.1 interface eth0</span><br><span class="line">set route prefix 10.10.16.0/24 gateway 10.10.15.1 interface eth0</span><br><span class="line"></span><br><span class="line">get route</span><br></pre></td></tr></table></figure><h3 id="VMware-vRealize-Network-Insight"><a href="#VMware-vRealize-Network-Insight" class="headerlink" title="VMware vRealize Network Insight"></a>VMware vRealize Network Insight</h3><p>基于 Ubunt 16.04，与 Ubuntu 相同</p><p>使用 support 账号登录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#添加</span><br><span class="line">cat &gt;&gt; /etc/network/interfaces &lt;&lt;EOF</span><br><span class="line"># static routes</span><br><span class="line">up route add -net 10.10.12.0/24 gw 10.10.15.1 dev eth0</span><br><span class="line">up route add -net 10.10.13.0/24 gw 10.10.15.1 dev eth0</span><br><span class="line">up route add -net 10.10.14.0/24 gw 10.10.15.1 dev eth0</span><br><span class="line">up route add -net 10.10.15.0/24 gw 10.10.15.1 dev eth0</span><br><span class="line">up route add -net 10.10.16.0/24 gw 10.10.15.1 dev eth0</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#重启网络</span><br><span class="line">service networking restart</span><br><span class="line"></span><br><span class="line">#验证</span><br><span class="line">ip route</span><br></pre></td></tr></table></figure><h3 id="VMware-Photon-OS"><a href="#VMware-Photon-OS" class="headerlink" title="VMware Photon OS"></a>VMware Photon OS</h3><p>vCenter Server 6.x/7.0</p><p>用于 vRealize 8.x 系列产品（3.0），vSphere_Replication（2.0），SRM（2.0）</p><p>编辑 <code>/etc/systemd/network/10-eth0.network</code></p><p>添加如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Route]</span><br><span class="line">Destination=10.1.0.0/16</span><br><span class="line">Gateway=10.5.0.1</span><br><span class="line">GatewayOnlink=true #可选</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/systemd/network/10-eth0.network &lt;&lt;EOF</span><br><span class="line"></span><br><span class="line">[Route]</span><br><span class="line">Destination=10.10.12.0/24</span><br><span class="line">Gateway=10.10.15.1</span><br><span class="line">GatewayOnlink=true</span><br><span class="line"></span><br><span class="line">[Route]</span><br><span class="line">Destination=10.10.13.0/24</span><br><span class="line">Gateway=10.10.15.1</span><br><span class="line">GatewayOnlink=true</span><br><span class="line"></span><br><span class="line">[Route]</span><br><span class="line">Destination=10.10.14.0/24</span><br><span class="line">Gateway=10.10.15.1</span><br><span class="line">GatewayOnlink=true</span><br><span class="line"></span><br><span class="line">[Route]</span><br><span class="line">Destination=10.10.15.0/24</span><br><span class="line">Gateway=10.10.15.1</span><br><span class="line">GatewayOnlink=true</span><br><span class="line"></span><br><span class="line">[Route]</span><br><span class="line">Destination=10.10.16.0/24</span><br><span class="line">Gateway=10.10.15.1</span><br><span class="line">GatewayOnlink=true</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>重启网络</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart systemd-networkd</span><br></pre></td></tr></table></figure><p>验证</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip route</span><br></pre></td></tr></table></figure><h3 id="VMware-Cloud-Director-Availability-4-0"><a href="#VMware-Cloud-Director-Availability-4-0" class="headerlink" title="VMware Cloud Director Availability 4.0"></a>VMware Cloud Director Availability 4.0</h3><p>注意：手动修改网络配置后，WebUI 中显示错误无法直接配置。</p><p>基于 Photon OS，但是网卡名称不一样。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/systemd/network/ens160.network &lt;&lt;EOF</span><br><span class="line"></span><br><span class="line">[Route]</span><br><span class="line">Destination=10.10.12.0/24</span><br><span class="line">Gateway=10.10.15.1</span><br><span class="line">GatewayOnlink=true</span><br><span class="line"></span><br><span class="line">[Route]</span><br><span class="line">Destination=10.10.13.0/24</span><br><span class="line">Gateway=10.10.15.1</span><br><span class="line">GatewayOnlink=true</span><br><span class="line"></span><br><span class="line">[Route]</span><br><span class="line">Destination=10.10.14.0/24</span><br><span class="line">Gateway=10.10.15.1</span><br><span class="line">GatewayOnlink=true</span><br><span class="line"></span><br><span class="line">[Route]</span><br><span class="line">Destination=10.10.15.0/24</span><br><span class="line">Gateway=10.10.15.1</span><br><span class="line">GatewayOnlink=true</span><br><span class="line"></span><br><span class="line">[Route]</span><br><span class="line">Destination=10.10.16.0/24</span><br><span class="line">Gateway=10.10.15.1</span><br><span class="line">GatewayOnlink=true</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>重启网络</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart systemd-networkd</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> route </tag>
            
            <tag> VMware </tag>
            
            <tag> windows </tag>
            
            <tag> FreeBSD </tag>
            
            <tag> Cisco </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>windows 镜像下载地址</title>
      <link href="/posts/62746/"/>
      <url>/posts/62746/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="windows-镜像下载地址"><a href="#windows-镜像下载地址" class="headerlink" title="windows 镜像下载地址"></a>windows 镜像下载地址</h1><h3 id="windows-10"><a href="#windows-10" class="headerlink" title="windows 10"></a>windows 10</h3><p><strong>官网下载</strong>微软提供的 Windows 官方正式版本，更新速度快，稳定安全，推荐使用此渠道获取 Windows 系统镜像。镜像为多版本合一，安装时可选择家庭版、专业版等。</p><p>不过 Windows 官网提供的镜像版本很新，不支持选择旧版本。</p><img src="/posts/62746/2565133-20211027143046829-1021281306.png" class=""><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.microsoft.com/zh-cn/software-download/windows10</span><br></pre></td></tr></table></figure><p><strong>旧版本下载</strong>以下旧版本可能已经停止支持，安全性没有保障，不推荐使用。这里仅提供磁力链接，请使用磁链下载工具下载。</p><p><strong>64位</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">21H1 版本</span><br><span class="line">ed2k://|file|zh-cn_windows_10_consumer_editions_version_21h1_updated_aug_2021_x64_dvd_4de56d76.iso|5831573504|B5E8A86D6C148A11292EBE45C81773AB|/</span><br><span class="line"></span><br><span class="line">20H2 版本</span><br><span class="line">ed2k://|file|cn_windows_10_consumer_editions_version_20h2_updated_april_2021_x64_dvd_ace7e59c.iso|6330411008|94F8A6EF403063C48EC5267133B7A3E1|/</span><br><span class="line"></span><br><span class="line">2004 版本</span><br><span class="line">ed2k://|file|cn_windows_10_consumer_editions_version_2004_updated_sep_2020_x64_dvd_049d70ee.iso|5424910336|9100F2CD41FED19B3314FFCF182DF026|/</span><br><span class="line"></span><br><span class="line">1909 版本</span><br><span class="line">magnet:?xt=urn:btih:3930A26F87080C3996AF0C67CAB04A02739EE006&amp;dn=cn_windows_10_consumer_editions_version_1909_updated_april_2020_x64_dvd_d4f1cee8.iso&amp;xl=5536696320</span><br><span class="line"></span><br><span class="line">1903 版本</span><br><span class="line">ed2k://|file|cn_windows_10_consumer_editions_version_1903_updated_nov_2019_x64_dvd_055b3530.iso|5409650688|EBA2C4E4A7B30C55FA9C042DB7461675|/</span><br><span class="line"></span><br><span class="line">1809 版本</span><br><span class="line">ed2k://|file|cn_windows_10_consumer_editions_version_1809_updated_sept_2019_x64_dvd_ecb7b897.iso|5571874816|915CADD0234B759920255AA8CC5984FB|/</span><br><span class="line"></span><br><span class="line">1803 版本</span><br><span class="line">ed2k://|file|cn_windows_10_consumer_editions_version_1803_updated_sept_2019_x64_dvd_56edef2c.iso|5427798016|5F38E07E290ED1FBD6D612579A104DBA|/</span><br></pre></td></tr></table></figure><p>32位</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">21H1 版本</span><br><span class="line">ed2k://|file|zh-cn_windows_10_consumer_editions_version_21h1_updated_aug_2021_x86_dvd_f699a023.iso|4223684608|9F7B716FB3FF1989C6958514442C6B0D|/</span><br><span class="line"></span><br><span class="line">20H2 版本</span><br><span class="line">ed2k://|file|cn_windows_10_consumer_editions_version_2004_updated_sep_2020_x86_dvd_8a8fe8c0.iso|3893041152|B6C95CA453EE875C0C4A6F19125FC5D2|/</span><br><span class="line"></span><br><span class="line">2004 版本</span><br><span class="line">ed2k://|file|cn_windows_10_consumer_editions_version_2004_updated_sep_2020_x86_dvd_8a8fe8c0.iso|3893041152|B6C95CA453EE875C0C4A6F19125FC5D2|/</span><br><span class="line"></span><br><span class="line">1909 版本</span><br><span class="line">magnet:?xt=urn:btih:C23F238C81BAB1444646A37018031DFEDB0CA65D&amp;dn=cn_windows_10_consumer_editions_version_1909_updated_april_2020_x86_dvd_1a597dcc.iso&amp;xl=4001820672</span><br><span class="line"></span><br><span class="line">1903 版本</span><br><span class="line">ed2k://|file|cn_windows_10_business_editions_version_1903_updated_july_2019_x86_dvd_81a0945b.iso|3703326720|575FF245531FAD9D2C9661CABA83F3C2|/</span><br><span class="line"></span><br><span class="line">1809 版本</span><br><span class="line">ed2k://|file|cn_windows_10_consumer_edition_version_1809_updated_may_2019_x86_dvd_42f826ad.iso|3925567488|663AEA7751416BC598D05505E14B9A9D|/</span><br><span class="line"></span><br><span class="line">1803 版本</span><br><span class="line">ed2k://|file|cn_windows_10_consumer_edition_version_1803_updated_march_2019_x86_dvd_6fdd5a7b.iso|4163999744|FA6EC68A5D86553F1380765067752412|/</span><br></pre></td></tr></table></figure><p><strong>长期服务版</strong>长期服务版是微软官方提供给企业的版本，每 2 至 3 年发布一次。功能上与Windows 10 企业版类似，但不会接受功能更新也不会强制更新，以及无法使用某些功能（如 Microsoft Store）。</p><p>适合养老用户，建议选择 LTSC 2019。</p><p><strong>LTSC 2019</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ed2k://|file|cn_windows_10_enterprise_ltsc_2019_x64_dvd_9c09ff24.iso|4478906368|E7C526499308841A4A6D116C857DB669|/</span><br></pre></td></tr></table></figure><p> <strong>LTSB 2016</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ed2k://|file|cn_windows_10_enterprise_2016_ltsb_x64_dvd_9060409.iso|3821895680|FF17FF2D5919E3A560151BBC11C399D1|/</span><br></pre></td></tr></table></figure><h3 id="Windows-11"><a href="#Windows-11" class="headerlink" title="Windows 11"></a>Windows 11</h3><p>Windows 11 是微软于 2021 年推出的 Windows NT 系列操作系统，为 Windows 10 的后继者。</p><p>截止本文更新时（2021/9/9），Windows 11 正式版还未发行，这里提供的版本为（Build 22000.132），测试版并不代表最终品质，一切请以官方正式版为准。</p><img src="/posts/62746/640.png" class=""><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ed2k://|file|zh-cn_windows_11_business_editions_version_21h2_updated_october_2021_x64_dvd_a84e149f.iso|5419143168|B0C4BE7271CD65B2173326239D4F8BA2|/</span><br></pre></td></tr></table></figure><h3 id="Windows-8-1"><a href="#Windows-8-1" class="headerlink" title="Windows 8.1"></a>Windows 8.1</h3><p><strong>官网下载</strong></p><img src="/posts/62746/641.png" class=""><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.microsoft.com/zh-cn/software-download/windows8ISO</span><br></pre></td></tr></table></figure><p><strong>旧版本（Windows 8）</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ed2k://|file|cn_windows_8_x64_dvd_915407.iso|3652950016|5C7F8C212BD3A1827866563773A431C2|/</span><br></pre></td></tr></table></figure><h3 id="Windows-7"><a href="#Windows-7" class="headerlink" title="Windows 7"></a>Windows 7</h3><img src="/posts/62746/642.png" class=""><p><strong>64位</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ed2k://|file|cn_windows_7_ultimate_with_sp1_x64_dvd_u_677408.iso|3420557312|B58548681854236C7939003B583A8078|/</span><br></pre></td></tr></table></figure><p><strong>32位</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ed2k://|file|cn_windows_7_ultimate_with_sp1_x86_dvd_u_677486.iso|2653276160|7503E4B9B8738DFCB95872445C72AEFB|/</span><br></pre></td></tr></table></figure><h3 id="Windows-VISTA"><a href="#Windows-VISTA" class="headerlink" title="Windows VISTA"></a>Windows VISTA</h3><img src="/posts/62746/644.png" class=""><p><strong>64位</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ed2k://|file|cn_windows_vista_enterprise_with_sp2_x64_dvd_x15-40402.iso|3104415744|D0CF708192BF9596CC603DF53ABDB76D|/ </span><br></pre></td></tr></table></figure><h3 id="Windows-XP"><a href="#Windows-XP" class="headerlink" title="Windows XP"></a>Windows XP</h3><img src="/posts/62746/645.png" class=""><p><strong>32位</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ed2k://|file|zh-hans_windows_xp_professional_with_service_pack_3_x86_cd_vl_x14-74070.iso|630237184|EC51916C9D9B8B931195EE0D6EE9B40E|/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> windows </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>服务器VMware紫屏问题定界工具方案</title>
      <link href="/posts/1686/"/>
      <url>/posts/1686/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="服务器VMware紫屏问题定界工具方案"><a href="#服务器VMware紫屏问题定界工具方案" class="headerlink" title="服务器VMware紫屏问题定界工具方案"></a>服务器VMware紫屏问题定界工具方案</h1><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h2><p>本文的目的是对服务器VMware紫屏问题提出系统性的定界方案，支撑该类问题定界工具的开发。</p><p>VMware紫屏问题是一类较常见且难以快速定位定界的问题，主要是由于VMware系统闭源，除了参考VMware官网公开的资料以及历史处理该类问题的经验外，无法进一步解析。而服务器作为ICT基础设施的底层设备，常常需要配合定界该类问题，或澄清紫屏问题是否由硬件问题引起。因此，为了有效提升VMware紫屏问题的定界定位能力，需要提炼出可以工具化的需求，系统性的支撑VMware紫屏定界工具的开发。</p><h2 id="2-VMware系统介绍"><a href="#2-VMware系统介绍" class="headerlink" title="2 VMware系统介绍"></a>2 VMware系统介绍</h2><p>VMware vSphere 是 VMware 的虚拟化平台，可将数据中心转换为包括 CPU、存储和网络资源的聚合计算基础架构。vSphere 将这些基础架构作为一个统一的运行环境进行管理，并提供工具来管理加入该环境的数据中心。</p><p><a href="https://docs.vmware.com/cn/VMware-vSphere/images/GUID-5EB66614-1EE8-4F39-8C8B-1E97EEE76791-high.png">https://docs.vmware.com/cn/VMware-vSphere/images/GUID-5EB66614-1EE8-4F39-8C8B-1E97EEE76791-high.png</a></p><p>vSphere 的两个核心组件是 ESXi和vCenter Server。ESXi是用于创建并运行虚拟机和虚拟设备的虚拟化平台。vCenter Server是一项服务，用于管理网络中连接的多个主机，并将主机资源池化。</p><h2 id="3-VMware紫屏（PSOD）解读"><a href="#3-VMware紫屏（PSOD）解读" class="headerlink" title="3 VMware紫屏（PSOD）解读"></a>3 VMware紫屏（PSOD）解读</h2><p>本章提供了解码 ESX/ESXi 主机紫色屏幕错误的相关信息。</p><p>ESX/ESXi 紫色屏幕错误大致如下所示：</p><img src="/posts/1686/zh-cn_image_0000001192618655.png" class=""><img src="/posts/1686/icon-note.png" class=""> **说明：**<p>本文将使用此紫色屏幕中的信息作为示例。</p><h3 id="3-1-什么是VMkernel？"><a href="#3-1-什么是VMkernel？" class="headerlink" title="3.1 什么是VMkernel？"></a>3.1 什么是VMkernel？</h3><p>VMkernel就是ESX/ESXi的操作系统核心。内核负责处理资源调度和设备IO事宜。设备IO由VMware网络和存储堆栈处理，后者也是虚拟文件系统、网络设备和控制物理设备的设备驱动程序之间的层。</p><h3 id="3-2-解释紫色诊断屏幕"><a href="#3-2-解释紫色诊断屏幕" class="headerlink" title="3.2 解释紫色诊断屏幕"></a>3.2 解释紫色诊断屏幕</h3><p>如果VMkernel出错，错误会显示在紫色诊断屏幕中。紫色诊断屏幕大致如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VMware ESX Server [Releasebuild-98103 PCPU 1 locked up.Failed to ack TLB invalidate. frame=0x3a37d98 ip=0x625e94 cr2=0x0 cr3=0x40c66000 cr4=0x16c es=0xffffffff ds=0xffffffff fs=0xffffffff gs=0xffffffff eax=0xffffffff ebx=0xffffffff ecx=0xffffffff edx=0xffffffff ebp=0x3a37ef4 esi=0xffffffff edi=0xffffffff err=-1 eflags=0xffffffff *0:1037/helper1-4 1:1107/vmm0:Fagi 2:1121/vmware-vm 3:1122/mks:Franc 0x3a37ef4:[0x625e94]Panic+0x17 stack: 0x833ab4, 0x3a37f10, 0x3a37f48 0x3a37f04:[0x625e94]Panic+0x17 stack: 0x833ab4, 0x1, 0x14a03a0 0x3a37f48:[0x64bfa4]TLBDoInvalidate+0x38f stack: 0x3a37f54, 0x40, 0x2 0x3a37f70:[0x66da4d]XMapForceFlush+0x64 stack: 0x0, 0x4d3a, 0x0 0x3a37fac:[0x652b8b]helpFunc+0x2d2 stack: 0x1, 0x14a4580, 0x0 0x3a37ffc:[0x750902]CpuSched_StartWorld+0x109 stack: 0x0, 0x0, 0x0 0x3a38000:[0x0]blk_dev+0xfd76461f stack: 0x0, 0x0, 0x0 VMK uptime: 7:05:43:45.014 TSC: 1751259712918392 Starting coredump to disk Starting coredump to disk Dumping using slot 1 of 1...using slot 1 of 1... log</span><br></pre></td></tr></table></figure><p>下文会分解上述紫色诊断屏幕每个部分的内容：</p><ul><li><p>产品和内部版本：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VMware ESX Server [Releasebuild-98103]  </span><br></pre></td></tr></table></figure><p>紫色诊断屏幕中的此部分表示出错的产品和内部版本。在本示例中，产品是 VMware ESX Server 内部版本 98103。</p></li><li><p>错误消息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PCPU 1 locked up.Failed to ack TLB invalidate  </span><br></pre></td></tr></table></figure><p>紫色诊断屏幕的此部分表示报告的错误消息。只能报告有限数量的错误消息。本文稍后会讨论这些错误消息。</p></li><li><p>CPU寄存器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frame=0x3a37d98 ip=0x625e94 cr2=0x0 cr3=0x40c66000 cr4=0x16c es=0xffffffff ds=0xffffffff fs=0xffffffff gs=0xffffffff eax=0xffffffff ebx=0xffffffff ecx=0xffffffff edx=0xffffffff ebp=0x3a37ef4 esi=0xffffffff edi=0xffffffff err=-1 eflags=0xffffffff  </span><br></pre></td></tr></table></figure><p>出错时，这些值存储在物理 CPU 寄存器中。这些寄存器中的信息千差万别，具体取决于出现的 VMkernel 错误。这些寄存器只能用于内部调试 VMkernel 错误的核心转储。有关这些寄存器的详细信息，请参见 <a href="http://www.intel.com/products/processor/manuals/%EF%BC%88%E9%92%88%E5%AF%B9">http://www.intel.com/products/processor/manuals/（针对</a> Intel）和 <a href="http://support.amd.com/us/psearch/Pages/psearch.aspx%EF%BC%88%E9%92%88%E5%AF%B9">http://support.amd.com/us/psearch/Pages/psearch.aspx（针对</a> AMD）。在 AMD 网站中，搜索特定类型处理器的架构程序员手册。</p></li><li><p>物理CPU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*0:1037/helper1-4 1:1107/vmm0:Fagi 2:1121/vmware-vm 3:1122/mks:Franc  </span><br></pre></td></tr></table></figure><p>紫色诊断屏幕的此部分表示VMkernel出错期间运行指令的物理CPU。在本示例中，0 旁边的 * 表示发生故障时物理CPU 0正在运行操作。新版本 ESX 不再使用 *，而是使用前缀字母CPU。例如，如果新版本 VMware ESX 同样出现上述错误，则同一行会显示为： CPU0:1037/helper1-4 cpu1:1107/vmm0:Fagi cpu2:1121/vmware-vm cpu3:1122/mks:Franc。 紫色诊断屏幕的此部分还描述了出错时CPU上运行的环境（进程）。在上述示例中，用户环境正在运行 helper1-4。</p><img src="/posts/1686/icon-note.png" class=""> **说明：**<p>进程名称可能已截断。</p></li><li><p>堆栈跟踪：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0x3a37ef4:[0x625e94]Panic+0x17 stack: 0x833ab4, 0x3a37f10, 0x3a37f48 0x3a37f04:[0x625e94]Panic+0x17 stack: 0x833ab4, 0x1, 0x14a03a0 0x3a37f48:[0x64bfa4]TLBDoInvalidate+0x38f stack: 0x3a37f54, 0x40, 0x2 0x3a37f70:[0x66da4d]XMapForceFlush+0x64 stack: 0x0, 0x4d3a, 0x0 0x3a37fac:[0x652b8b]helpFunc+0x2d2 stack: 0x1, 0x14a4580, 0x0 0x3a37ffc:[0x750902]CpuSched_StartWorld+0x109 stack: 0x0, 0x0, 0x0 0x3a38000:[0x0]blk_dev+0xfd76461f stack: 0x0, 0x0, 0x0  </span><br></pre></td></tr></table></figure><p>堆栈表示出错时，VMkernel正在执行的操作。在本示例中，VMkernel正在尝试清除内存页表 (TLB)。此信息是一个重要工具，有助于通过评估出错时内核所执行的操作来诊断紫色屏幕错误。</p></li><li><p>正常运行时间：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VMK uptime: 7:05:43:45.014 TSC: 1751259712918392  </span><br></pre></td></tr></table></figure><p>此部分表示自上次启动以来服务器运行的时间。在本示例中，ESX 主机已运行了7天5小时43分45.014 秒。TSC值是服务器启动之后经过的CPU时钟频率循环次数。</p></li><li><p>核心转储：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Starting coredump to disk Starting coredump to disk Dumping using slot 1 of 1...using slot 1 of 1... log  </span><br></pre></td></tr></table></figure><p>紫色诊断屏幕的此部分表示正复制到vmkcore分区的VMkernel内存内容。</p></li></ul><h3 id="3-3-错误消息"><a href="#3-3-错误消息" class="headerlink" title="3.3 错误消息"></a>3.3 错误消息</h3><p>紫色屏幕生成的VMkernel错误消息可用于确定问题原因。不过，产生的错误消息数是有限的。以下是已知的VMkernel错误消息列表。</p><ul><li><p>类型：控制台警告</p><p><strong>错误示例</strong>：COS Error: Oops</p><p><strong>描述</strong>：ESX主机出现故障并在出现服务控制台警告时显示紫色屏幕。与大多数紫色屏幕错误不同的是，该错误并非由VMkernel触发。相反，它由服务控制台触发，并发生在Linux级别。这些紫色屏幕错误包含来自Linux内核的其他信息。有关控制台警告的详细信息，请参见<a href="https://kb.vmware.com/s/article/1006802">Understanding an “Oops” purple diagnostic screen (1006802)</a>。</p></li><li><p>类型：检测信号丢失</p><p><strong>错误示例</strong>：Lost Heartbeat</p><p><strong>描述</strong>：ESX VMkernel 和服务控制台 Linux 内核同时在 ESX 上运行。服务控制台 Linux 内核会运行一个称为 vmnixhbd 的进程，只要 VMkernel 能够分配和释放内存页，该进程便会向 VMkernel 发送检测信号。如果在 30 分钟超时时间之前未收到检测信号，VMkernel 会触发 COS 严重错误以及表明检测信号丢失的紫色诊断屏幕。有关检测信号丢失的详细信息，请参见 <a href="https://kb.vmware.com/s/article/1009525">Understanding a “Lost Heartbeat” purple diagnostic screen (1009525)</a>。</p></li><li><p>类型：断言</p><p><strong>错误示例</strong>：ASSERT bora/vmkernel/main/pframe_int.h:527</p><p><strong>描述</strong>：断言错误属于软件错误，因为它们都与程序所基于的假设条件有关。此类型的紫色屏幕错误主要是由软件错误导致的。有关断言错误消息的详细信息，请参见<a href="https://kb.vmware.com/s/article/1019956">Understanding ASSERT and NOT_IMPLEMENTED purple diagnostic screens (1019956)</a>。</p></li><li><p>类型：未执行</p><p><strong>错误示例</strong>：NOT_IMPLEMENTED /build/mts/release/bora-84374/bora/vmkernel/main/util.c:83</p><p><strong>描述</strong>：代码遇到超出设计处理范围的情形时会出现未执行错误消息。有关详细信息，请参见 <a href="https://kb.vmware.com/s/article/1019956">Understanding ASSERT and NOT_IMPLEMENTED purple diagnostic screens (1019956)</a>。</p></li><li><p>类型：转数已超出/可能出现死锁</p><p><strong>错误示例</strong>：Spin count exceeded (iplLock) - possible deadlock</p><p><strong>描述</strong>：线程尝试在代码关键部分执行时，VMware ESX 主机可能在紫色诊断屏幕上报告转数已超出且可能出现死锁。由于线程正尝试进入关键部分，因此，它需要执行自旋锁操作，以便先轮询互斥锁，然后再执行代码。线程在执行自旋锁操作期间会继续轮询互斥锁，但是，互斥锁轮询次数存在一定限制。有关转数已超出错误的详细信息，请参见<a href="https://kb.vmware.com/s/article/1020105">Understanding a “Spin count exceeded” purple diagnostic screen (1020105)</a>。</p></li><li><p>类型：无法确认 TLB 是否失效</p><p><strong>错误示例</strong>：PCPU 1 locked up.Failed to ack TLB invalidate.</p><p><strong>描述</strong>：物理CPU在尝试清除内存页表时出现故障。有关详细信息，请参见<a href="https://kb.vmware.com/s/article/1020214">Understanding a Failed to ack TLB invalidate purple diagnostic screen (1020214)</a>。</p></li></ul><p>紫色诊断屏幕还会以异常的形式出现。异常处理程序是一种计算机硬件机制，旨在处理正常执行流（除零、页面错误等）发生变动的某些情形。该处理程序并无跟踪机制，因此您需要通过日志记录确定处理程序是否出现问题（或通过单步调试）。以下是常见异常列表：</p><ul><li><p>类型：异常13（一般保护错误）</p><p><strong>错误示例</strong>：#GP Exception(13) in world 4130:helper13-0 @ 0x41803399e303</p><p><strong>描述</strong>：在以下任一情况下都会出现一般保护错误（异常 13）：正在请求的页面不属于请求该页的程序（未映射到程序内存中），或者程序无权在页面上执行读取或写入操作。有关异常13或页面错误的详细信息，请参见<a href="https://kb.vmware.com/s/article/1020181">Understanding Exception 13 and Exception 14 purple diagnostic screen events (1020181)</a>。</p></li><li><p>类型：异常14（页面错误）</p><p><strong>错误示例</strong>：#PF Exception type 14 in world 136:helper0-0 @ 0x4a8e6e</p><p><strong>描述</strong>：正在请求的页面未成功加载到内存时出现页面错误（异常 14）。有关异常14或页面错误的详细信息，请参见<a href="https://kb.vmware.com/s/article/1020181">Understanding Exception 13 and Exception 14 purple diagnostic screen events (1020181)</a>。</p></li><li><p>类型：异常18（计算机检查异常）</p><p><strong>错误示例</strong>：Machine Check Exception: Unable to continue</p><p><strong>错误示例</strong>：Hardware (Machine) Error</p><p><strong>描述</strong>：计算机检查异常 (MCE) 由硬件生成并通过主机进行报告。出现MCE事件时，请咨询您的硬件供应商。通过评估显示的信息，可以确定报告错误的单个组件。有关MCE的详细信息，请参见<a href="https://kb.vmware.com/s/article/1005184">Decoding Machine Check Exception (MCE) output after a purple screen error (1005184)</a>。</p></li></ul><p>如果VMware ESX或ESXi主机遇到类似于其中一个错误，但未指向以上参考的一般文章，请在<a href="http://kb.vmware.com/">Knowledge Base</a>中搜索错误消息和堆栈跟踪信息。如果错误未记录在知识库中，请从VMware ESX主机收集诊断信息，然后提交支持请求。有关详细信息，请参见<a href="https://kb.vmware.com/s/article/1008524">Collecting diagnostic information for VMware products (1008524)</a>和<a href="http://www.vmware.com/support/policies/howto.html">How to Submit a Support Request</a>。</p><p>有关详细信息，请参见：</p><ul><li><a href="https://kb.vmware.com/s/article/1008524">Collecting diagnostic information for VMware products (1008524)</a></li><li><a href="http://www.vmware.com/support/policies/howto.html">How to Submit a Support Request</a></li></ul><h3 id="3-4-模式分析"><a href="#3-4-模式分析" class="headerlink" title="3.4 模式分析"></a>3.4 模式分析</h3><p>同一 VMware ESX 主机上出现多个紫色诊断屏幕时，可以使用多个紫色诊断屏幕示例确定问题与硬件还是与软件有关。为此，请确定紫色诊断屏幕的以下部分是否存在一些模式：</p><ul><li><p>错误消息和堆栈跟踪：</p><ul><li>如果多个 vmkernel 错误中的错误消息和堆栈变化很大，则表明同一错误并不总是软件造成的。尽管不是十分确凿，但这很可能意味着硬件问题。</li><li>如果多个 vmkernel 中的错误消息和堆栈始终相同，则表明同一错误都是由软件造成的。尽管不是十分确凿，但这很可能意味着软件问题。</li><li>有关出现的错误消息的详细信息，请参见上述特定错误消息部分。</li></ul></li><li><p>物理CPU：</p><ul><li>如果多个 vmkernel 错误中的物理 CPU 值始终相同，则表明软件总是在同一个物理 CPU 上出现错误。尽管不是十分确凿，但这很可能意味着 CPU 问题。</li><li>有关详细信息，请参见 <a href="https://kb.vmware.com/s/article/1003560">Determining if virtual machine and ESX host unresponsiveness is caused by hardware issues (1003560)</a>。</li></ul></li><li><p>环境：</p><p>如果多个 vmkernel 错误中的环境值始终相同，则表明 vmkernel 从同一环境接收指令时出现错误。尽管不是十分确凿，但这很可能意味着发送指令的环境可能触发了 VMkernel 错误。</p></li></ul><p>Related Information</p><p>以下是完整的异常列表：</p><ul><li>异常类型0 #DE：除法错误（Divide Error）</li><li>异常类型1 #DB：调试异常</li><li>异常类型2 NMI：不可屏蔽中断</li><li>异常类型3 #BP：断点异常</li><li>异常类型4 #OF：溢出（INTO 指令）</li><li>异常类型5 #BR：界限检查（BOUND 指令）</li><li>异常类型6 #UD：Opcode 无效</li><li>异常类型7 #NM：协处理器不可用</li><li>异常类型8 #DF：双重故障</li><li>异常类型10 #TS：TSS 无效</li><li>异常类型11 #NP：分段不存在</li><li>异常类型12 #SS：堆栈分段错误</li><li>异常类型13 #GP：一般保护错误</li><li>异常类型14 #PF：页面错误</li><li>异常类型16 #MF：协处理器错误</li><li>异常类型17 #AC：对齐检查</li><li>异常类型18 #MC：计算机检查异常</li><li>异常类型19 #XF：SIMD 浮点异常</li><li>异常类型20-31：预留</li><li>异常类型32-255：用户定义（时钟调度程序）</li></ul><p>有关这些异常的详细信息，请参见<a href="http://www.intel.com/Assets/PDF/manual/253665.pdf">Intel 64 and IA-32 Architectures Software Developer’s Manual, Volume 1: Basic Architecture</a>的<em>Call and Return Operation for Interrupt or Exception Handling Procedures</em>部分，以及<a href="http://www.intel.com/Assets/PDF/manual/253668.pdf">Intel 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</a>的<em>Chapter 6: Interrupts and Exception Handling</em>。</p>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vSAN系统日志收集指导</title>
      <link href="/posts/17395/"/>
      <url>/posts/17395/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="vSAN系统日志收集指导"><a href="#vSAN系统日志收集指导" class="headerlink" title="vSAN系统日志收集指导"></a>vSAN系统日志收集指导</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在定位vSAN及ESXi相关问题时，维护人员需要依赖各类系统日志进行问题分析，本指导书对vmware官网文档和知识库KB中的日志收集方法进行了归纳，用于指导一线维护人员在遇到客户问题时应该收集哪些日志以及如何收集。此外，本文档中提到的方法不仅适用于vSAN产品，也适用于VMware其它产品的日志收集。</p><h2 id="系统日志类别"><a href="#系统日志类别" class="headerlink" title="系统日志类别"></a>系统日志类别</h2><p>vSAN解决方案收集的系统日志主要包括ESXi主机上的vm-support日志、vCenter上的vc-support日志以及rvc日志，大多数情况下这几种日志基本可以满足维护人员的需求；如果需要针对客户vSAN集群性能进行分析，还可以额外收集主机和集群的性能日志。以上这些日志的基本用途如下表所示：</p><table><thead><tr><th>序号</th><th>名称</th><th>用途</th><th>必要性</th></tr></thead><tbody><tr><td>1</td><td>主机vm-support日志</td><td>从主机层面查看vSAN节点状态</td><td>高</td></tr><tr><td>2</td><td>集群vc-support日志</td><td>从集群层面查看vSAN整体状态</td><td>高</td></tr><tr><td>3</td><td>集群rvc日志</td><td>从集群内部查看vSAN主机、VM和磁盘信息</td><td>中</td></tr><tr><td>4</td><td>集群性能日志</td><td>检测集群性能状态</td><td>中</td></tr></tbody></table><p>在日志收集过程中，vmware通常会提供UI页面操作和命令行操作两种方式，但经过实践，很多情况下UI页面操作方式经常会失败，因此本指导书后面都推荐使用命令行方式进行操作。</p><h2 id="主机vm-support日志收集"><a href="#主机vm-support日志收集" class="headerlink" title="主机vm-support日志收集"></a>主机vm-support日志收集</h2><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>所有的故障场景都需要收集ESXi主机日志，由于通常会使用vm-support命令进行收集，所以主机系统日志通常也被称为vm-support日志。</p><h4 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h4><p>通过SSH方式登录ESXi主机后台，直接执行<strong>vm-support</strong>命令，系统会在默认路径下自动生成一个后缀为.tgz的日志压缩包，如下图所示：</p><img src="/posts/17395/zh-cn_image_0000001116624053.png" class=""><p>如果需要手动指定日志生成路径，可以在<strong>vm-support</strong>命令后添加**-w /path/to/file/location** 。如果要收集多台主机的vm-support日志，需要分别登录执行以上操作。</p><h2 id="集群vc-support日志收集"><a href="#集群vc-support日志收集" class="headerlink" title="集群vc-support日志收集"></a>集群vc-support日志收集</h2><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><p>在收集客户日志信息时，很多客户集群的主机数量较多，且每台主机的vm-support日志又较大，所以维护人员通常只能收集到其中几台主机的日志，因此非常有必要通过收集集群整体状态相关的日志来快速对集群进行诊断，下一步针对故障的主机再进一步去分析主机日志，这样有助于缩小问题排查范围。</p><h4 id="操作步骤-1"><a href="#操作步骤-1" class="headerlink" title="操作步骤"></a>操作步骤</h4><p>该日志的收集方式与主机日志收集方式非常相似，首先通过SSH方式登录vCenter虚拟机后台，直接执行<strong>vc-support</strong>命令即可，系统会在默认路径下生产一个后缀为.tgz的日志压缩包，如下图所示：</p><img src="/posts/17395/zh-cn_image_0000001116227111.png" class=""><p>由于一个集群只有一个vcenter，因此无论集群中有多少台主机，只需要收集一份该日志即可。</p><h2 id="集群rvc日志收集"><a href="#集群rvc日志收集" class="headerlink" title="集群rvc日志收集"></a>集群rvc日志收集</h2><h4 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h4><p>rvc日志对维护人员了解vSAN集群的内部状态时非常有用，尤其是查看和虚拟机、磁盘相关的信息，可以作为vc-support日志的补充。</p><h4 id="操作步骤-2"><a href="#操作步骤-2" class="headerlink" title="操作步骤"></a>操作步骤</h4><p>首先通过SSH方式登录vCenter虚拟机后台，然后执行以下命令：</p><p><strong>rvc -c “vsan.support_information 1” -c “quit” <a href="mailto:&#97;&#100;&#109;&#105;&#x6e;&#x69;&#115;&#116;&#114;&#x61;&#x74;&#111;&#114;&#64;&#x76;&#x73;&#x70;&#x68;&#x65;&#114;&#x65;&#x2e;&#x6c;&#111;&#x63;&#x61;&#x6c;">&#97;&#100;&#109;&#105;&#x6e;&#x69;&#115;&#116;&#114;&#x61;&#x74;&#111;&#114;&#64;&#x76;&#x73;&#x70;&#x68;&#x65;&#114;&#x65;&#x2e;&#x6c;&#111;&#x63;&#x61;&#x6c;</a>@localhost &gt; /tmp/rvc.log</strong></p><img src="/posts/17395/zh-cn_image_0000001116624427.png" class=""><p>其中：<a href="mailto:&#97;&#x64;&#109;&#105;&#110;&#105;&#x73;&#x74;&#114;&#x61;&#116;&#x6f;&#114;&#64;&#x76;&#115;&#x70;&#104;&#101;&#114;&#101;&#x2e;&#x6c;&#x6f;&#99;&#x61;&#108;">&#97;&#x64;&#109;&#105;&#110;&#105;&#x73;&#x74;&#114;&#x61;&#116;&#x6f;&#114;&#64;&#x76;&#115;&#x70;&#104;&#101;&#114;&#101;&#x2e;&#x6c;&#x6f;&#99;&#x61;&#108;</a>是vcenter的登录账户；localhost指代本机；/tmp/rvc.log是输出日志的路径。</p><p>执行命令后屏幕不会出现输出，但是需要用户输入密码。如果客户第一次执行的话， 需要接受SSL认证（同样不会有输出），需要先输入“y”,点击回车，然后再输入密码（示例中为Huawei@123）。整个收集过程大约2分钟左右，完成后需要检查/tmp/rvc.log有正确的输出，收集到的rvc.log示例如下：</p><img src="/posts/17395/zh-cn_image_0000001116227113.png" class=""><h2 id="集群性能日志收集"><a href="#集群性能日志收集" class="headerlink" title="集群性能日志收集"></a>集群性能日志收集</h2><h4 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h4><p>集群性能日志一般情况下无需收集，该日志主要用来协助维护人员排查vSAN性能相关的问题。</p><h4 id="操作步骤-3"><a href="#操作步骤-3" class="headerlink" title="操作步骤"></a>操作步骤</h4><ol><li><p>通过SSH方式登录vCenter虚拟机后台，并用域账户和密码登录rvc，示例如下：</p><img src="/posts/17395/zh-cn_image_0000001116444185.png" class=""></li><li><p>然后用<strong>cd</strong>和<strong>ls</strong>命令进入vsan集群目录，用以下命令开启Observer服务：</p><p><strong>vsan.observer 0 –run-webserver –force –generate-html-bundle /tmp –interval 30 –max-runtime 1</strong></p><img src="/posts/17395/zh-cn_image_0000001116508603.png" class=""><p>其中：0代表当前vsan集群的目录名；/tmp为输出日志，设置收集时间为1小时。</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
            <tag> vSAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vSAN磁盘offline场景操作建议指导</title>
      <link href="/posts/4901/"/>
      <url>/posts/4901/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="vSAN磁盘offline场景操作建议指导"><a href="#vSAN磁盘offline场景操作建议指导" class="headerlink" title="vSAN磁盘offline场景操作建议指导"></a>vSAN磁盘offline场景操作建议指导</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>目前vSAN现网维护的过程中，经常收到客户反馈vSAN集群发生磁盘offline，具体表现为RAID卡发送命令超时、磁盘组性能下降导致业务io卡顿、磁盘出现故障导致踢盘等，当磁盘offline情况严重时会影响客户业务稳定性甚至数据可用性，因此本指导书主要针对vSAN磁盘offline这类场景给出通用的定界定位方法、测试方案及建议。</p><h2 id="踢盘问题定界定位流程"><a href="#踢盘问题定界定位流程" class="headerlink" title="踢盘问题定界定位流程"></a>踢盘问题定界定位流程</h2><h3 id="问题现象及告警"><a href="#问题现象及告警" class="headerlink" title="问题现象及告警"></a>问题现象及告警</h3><p>踢盘现象通常代表相关磁盘处于absent或者degrade的状态，产生的原因有很多，例如磁盘硬件故障、磁盘物理拔出、主机上下电、磁盘容量已满等，判断该问题是否是由于IO超时导致须综合多方面因素来分析。当vSAN集群出现磁盘offline时，客户现场可以从监控页面、vCenter后台、RAID卡信息等多个层面查看是否有异常告警。</p><h4 id="监控页面告警"><a href="#监控页面告警" class="headerlink" title="监控页面告警"></a>监控页面告警</h4><p>首先客户的vSphere Client监控页面上一定会发出“Errors occurred on the disks of a vSAN host”的告警，如下图：</p><img src="/posts/4901/zh-cn_image_0000001115391425.png" class=""><p>此外，“Configure”选项卡的“Disk management”可查看集群中的一台或多台主机上会出现磁盘组状态为“Unhealthy”，如下图：</p><img src="/posts/4901/zh-cn_image_0000001115186897.png" class=""><h4 id="vCenter后端告警"><a href="#vCenter后端告警" class="headerlink" title="vCenter后端告警"></a>vCenter后端告警</h4><p>直接登录vCenter虚拟机后台上也可以观察踢盘现象，通过调用vSphere控制台命令行工具（rvc），首先在诊断项“Physical disk”可以看到所有故障磁盘涉及的主机、磁盘id等信息，如下图：</p><img src="/posts/4901/zh-cn_image_0000001115549907.png" class=""><p>此外，为了评估offline磁盘是否对客户业务造成影响，在状态检查项中检查是否有不可访问的虚拟机或者数据对象，如下图：</p><img src="/posts/4901/zh-cn_image_0000001115326953.png" class=""><h4 id="RAID卡信息告警"><a href="#RAID卡信息告警" class="headerlink" title="RAID卡信息告警"></a>RAID卡信息告警</h4><p>当发生磁盘踢盘时，RAID卡的alilog日志中也通常会出现CO:FPE TW b开头的告警信息，并伴随有Command timeout，如下图：</p><img src="/posts/4901/zh-cn_image_0000001115391429.png" class=""><h4 id="告警分析"><a href="#告警分析" class="headerlink" title="告警分析"></a>告警分析</h4><p>如果vSAN集群中发生了由于IO超时导致的踢盘故障并影响到客户虚拟机业务时，以上<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115186857.html">监控页面告警</a>~<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115186859.html">RAID卡信息告警</a>的所有现象和日志信息都应该是必现的；但在实际处理现网问题过程中，由于客户有时不能及时察觉导致重要告警信息被忽略、客户监控页面不能截图等种种原因，通常不能收集充分的信息，在这种情况下就需要通过能够长时间保存的日志来定位问题，例如主机上的vobd.log和RAID卡日志，其中RAID卡日志最能够说明是否出现IO超时，而vobd.log中可以捕获到很长时间范围内的磁盘踢盘现象。</p><h3 id="日志收集"><a href="#日志收集" class="headerlink" title="日志收集"></a>日志收集</h3><p>本章节主要介绍vSAN系统日志和RAID卡日志收集步骤，如还需收集系统性能日志信息可参考《<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001117328489.html">vSAN系统日志收集指导</a>》。</p><h4 id="系统日志收集"><a href="#系统日志收集" class="headerlink" title="系统日志收集"></a>系统日志收集</h4><p>vSAN现网问题分析最重要的系统日志包括ESXi主机上的vm-support日志和vCenter上的vc-support日志，主要功能如下表：</p><table><thead><tr><th>序号</th><th>名称</th><th>用途</th><th>必要性</th></tr></thead><tbody><tr><td>1</td><td>主机vm-support日志</td><td>从主机层面查看vSAN节点状态</td><td>高</td></tr><tr><td>2</td><td>集群vc-support日志</td><td>从集群层面查看vSAN整体状态</td><td>高</td></tr></tbody></table><ul><li><p>vm-support日志收集</p><p>通过SSH方式登录ESXi主机后台，直接执行<strong>vm-support</strong>命令，系统会在默认路径下自动生成一个后缀为.tgz的日志压缩包，如下图所示：</p><img src="/posts/4901/zh-cn_image_0000001115186899.png" class=""></li><li><p>vc-support日志收集</p><p>该日志的收集方式与主机日志收集方式非常相似，首先通过SSH方式登录vCenter虚拟机后台，直接执行<strong>vc-support</strong>命令即可，系统会在默认路径下生产一个后缀为.tgz的日志压缩包，由于一个集群只有一个vcenter，因此无论集群中有多少台主机，只需要收集一份该日志即可，如下图所示：</p><img src="/posts/4901/zh-cn_image_0000001115549909.png" class=""></li></ul><h4 id="RAID卡日志收集"><a href="#RAID卡日志收集" class="headerlink" title="RAID卡日志收集"></a>RAID卡日志收集</h4><ul><li>预置工具：博通RAID卡工具storcli64，具体下载及使用方法请参照《<a href="https://support.huawei.com/enterprise/zh/doc/EDOC1000163568">华为V5服务器 RAID控制卡 用户指南</a>》——OS命令行工具。</li><li>使用方法：在OS下使用storcli64工具收集RAID卡日志并重定向至文件，具体命令为storcli64 /c*<strong>controller_id*</strong> show alilog &gt; *<strong>file_name*</strong></li></ul><table><thead><tr><th>参数</th><th>参数说明</th><th>取值</th></tr></thead><tbody><tr><td>*<strong>Controller_id*</strong></td><td>控制器ID</td><td>默认从0开始</td></tr><tr><td>*<strong>File_name*</strong></td><td>重定向的文件名称</td><td>自定义</td></tr></tbody></table><img src="/posts/4901/zh-cn_image_0000001115549911.png" class=""><h4 id="iBMC硬件日志收集"><a href="#iBMC硬件日志收集" class="headerlink" title="iBMC硬件日志收集"></a>iBMC硬件日志收集</h4><p>此外，该类场景下可能还会涉及硬件问题，硬件iBMC日志一键收集可参考链接：</p><p><a href="http://3ms.huawei.com/km/groups/1004825/blogs/details/8189905">http://3ms.huawei.com/km/groups/1004825/blogs/details/8189905</a></p><h3 id="集群信息检查"><a href="#集群信息检查" class="headerlink" title="集群信息检查"></a>集群信息检查</h3><p>在分析任何的vSAN现网问题时，首先需要对集群的节点配置有整体了解，通过<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115186863.html">系统日志收集</a>收集的vc-support日志可以查看集群和主机视图、集群所有磁盘信息、是否不可用的虚拟机或对象、是否存在大量数据重建io等。解压vc-support日志包，然后进入commands目录，打开日志文件python_usrlibvmware-vpxvsan-healthvsan-vc-health-statuspy-rvc-basic-support-information.txt即可查看，如下所示：</p><img src="/posts/4901/zh-cn_image_0000001115326955.png" class=""><h3 id="集群健康状态诊断"><a href="#集群健康状态诊断" class="headerlink" title="集群健康状态诊断"></a>集群健康状态诊断</h3><p>获取集群基本信息后，下一步须检查集群存在哪些异常告警，通过查看vc-support日志的commands目录下python_usrlibvmware-vpxvsan-healthvsan-vc-health-statuspy-cluster-health.txt文件可以对日志收集时间点的集群状态进行完全的健康诊断，即集群在那一刻的所有异常告警最终都会反映在该日志文件中，用户可根据给出的告警信息缩小故障主机范围，并进一步通过主机日志去分析根因。</p><p>但该日志文件格式较复杂，例如查看到一些磁盘状态处于absent，如下图所示：</p><img src="/posts/4901/zh-cn_image_0000001115391431.png" class=""><p>如上图所示，该日志维护人员难以阅读，因此需要采用可视化工具进行分析，具体详情可参考<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115326921.html">集群日志分析可视化工具</a>。</p><h3 id="集群日志分析可视化工具"><a href="#集群日志分析可视化工具" class="headerlink" title="集群日志分析可视化工具"></a>集群日志分析可视化工具</h3><p>目前在黄区测试环境部署了一套vSAN日志分析可视化工具，目前已实现的功能是通过vc-support日志对集群健康状态进行诊断，包括集群信息获取和集群所有异常进行检测，链接：<a href="http://10.70.222.85:5000/%EF%BC%8C%E9%A6%96%E9%A1%B5%E5%B1%95%E7%A4%BA%E5%A6%82%E4%B8%8B%EF%BC%9A">http://10.70.222.85:5000/，首页展示如下：</a></p><img src="/posts/4901/zh-cn_image_0000001115186903.png" class=""><p>需要上传的日志文件如图中红色框所示，通过上传集群配置日志，可以获取集群视图、磁盘、故障虚拟机等信息；通过上传健康状态日志，可以获取当前集群所有告警项及告警原因，示例如下图：</p><img src="/posts/4901/zh-cn_image_0000001115326957.png" class=""><img src="/posts/4901/zh-cn_image_0000001115391433.png" class=""><h3 id="IO超时原因定界"><a href="#IO超时原因定界" class="headerlink" title="IO超时原因定界"></a>IO超时原因定界</h3><p>上一章节中已描述了通过对集群状态的诊断可以确定故障节点，本章节介绍在故障主机中针对IO超时问题的日志分析方法。</p><h4 id="系统日志分析"><a href="#系统日志分析" class="headerlink" title="系统日志分析"></a>系统日志分析</h4><p>系统日志分析通常需要收集vm-support日志和vc-support日志，本章节以刚果项目超时问题为例，由于之前故障时未采集vc-support日志，因此先从vm-support日志进行分析，截图日志来源于4月25日刚果发生故障的主机。</p><h5 id="vm-support日志包结构"><a href="#vm-support日志包结构" class="headerlink" title="vm-support日志包结构"></a>vm-support日志包结构</h5><p>vm-support是在每一台主机上收集的压缩包，记录了该主机在一定时间段的所有相关信息，是分析出问题根因的重要文件，基本结构如下图：</p><img src="/posts/4901/zh-cn_image_0000001115549915.png" class=""><p>整个vm-support压缩包大小从几百M到几个G，大约包含几千个文件，其中最主要的日志目录是上图中的commmands和var，commands目录下主要包含了绝大多数的主机配置信息，var目录下主要包含了主机日志文件。</p><h5 id="vobd-log分析"><a href="#vobd-log分析" class="headerlink" title="vobd.log分析"></a>vobd.log分析</h5><p>vobd日志捕获VMkernel中的重要事件，如果发生磁盘掉盘以及超时故障，最容易发现此告警的就是通过vobd.log文件，该文件的目录路径为：</p><img src="/posts/4901/zh-cn_image_0000001115326959.png" class=""><p>如果发生了IO超时导致的踢盘，可以看到大量的Power-on Reset、under permanent error以及“vSAN device XXXX has gone offline”等信息：</p><img src="/posts/4901/zh-cn_image_0000001115391437.png" class=""><img src="/posts/4901/zh-cn_image_0000001115186905.png" class=""><p>VMkernel.log分析</p><p>VMkernel.log是ESXi主机的核心日志文件，记录了包括设备发现、存储和网络设备、驱动程序事件以及虚拟机启动等所有相关信息，是日志分析中排查底层问题最重要的依据，该文件的目录路径为：</p><img src="/posts/4901/zh-cn_image_0000001115549917.png" class=""><p>如果发生了IO超时导致的踢盘，该文件中依然可以看到Power-on Reset等告警信息以及告警发生过程及原因，截图如下：</p><img src="/posts/4901/zh-cn_image_0000001115326963.png" class=""><ul><li>上图中，首先lsi_mr3报出0x10c，之前VMware工程师针对该错误码已给出过提示，该信息属于严重错误；目前的测试结果是当出现IO超时该错误码必定会出现，但0x10c是由VMware定义的驱动程序的事件码，包含的故障类型可能不仅限于这一类问题，因此反过来不一定能成立，暂时只可作为IO超时的参考标识。</li><li>1号红色框部分代表表示基于SCSI协议的命令下发到磁盘naa.55cd2e414fc9857a的返回码，其中H:0xc表示发生临时错误，该io命令会重新下发（详情见<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115186869.html">VMkernel.log的SCSI码解析</a>）。</li><li>第2个红色框部分表示基于SCSI协议的命令下发到容量盘naa.55cd2e414fc97688的返回码，其中D:0x2表示状态码异常，因此后面的sense data的三个字节是有效的，对应的0x6 0x29 0x00代表发生了POR或者磁盘重启（详情见<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115391397.html">VMkernel.log分析</a>）。</li><li>第3个红色框部分直接给出容量盘naa.55cd2e414fc97688发生了reset的提示。</li></ul><p>除上面截图外，该日志的其他地方还出现了类似的大量的SCSI错误返回码，且从时间上看基本上都是基于lsi_mr3报出的错误引入，例如下图：</p><img src="/posts/4901/zh-cn_image_0000001115391439.png" class=""><p>综合推断正是之前RAID卡的驱动程序发生异常，导致了当前RAID卡发送到对应磁盘的<strong>io</strong>命令Cmd 0xxxxx失败，导致磁盘不断reset。</p><h5 id="VMkernel-log的SCSI码解析"><a href="#VMkernel-log的SCSI码解析" class="headerlink" title="VMkernel.log的SCSI码解析"></a>VMkernel.log的SCSI码解析</h5><p>由于集群采用的磁盘都是SAS盘，所有RAID卡到磁盘的命令下发都是基于SCSI协议进行编码，因此本章节主要介绍如何解析VMkernel文件中的SCSI返回码，属于对<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115391397.html">VMkernel.log分析</a>的补充。</p><p>以<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115391397.html">VMkernel.log分析</a>中H:0x7 D:0x40 P:0x0 Invalid sense data: 0x0 0x0 0x0为例进行说明，H开头的字节为主机码，D开头的字节为状态码，P开头的表示插件码，sense data的第1个字节为sense key,后面两个字节为additional sense data。</p><p>主机码的信息主要反映了RAID卡的驱动或固件，H:0x7代表检测到主机RAID卡发生了内部错误，VMware 官网kb解释如下图：</p><img src="/posts/4901/zh-cn_image_0000001115186907.png" class=""><p>状态码是在单条IO命令执行完毕了才会返回，反应了命令执行的基本情况，通常为D:0x2时表示命令执行异常，此时才需要检查后面的sense data的三个字节，如果不为D:0x2则后面3个字节是无效的，例如示例中时0x40，表明任务强制abort，官网kb如下图：</p><img src="/posts/4901/zh-cn_image_0000001115326965.png" class=""><p>Sense key主要用于指示命令执行失败的原因，只有在状态码为0x2（CHECK CONDITION）时才有效；而最后两个字节描述了该原因的详情，官网kb如下图：</p><img src="/posts/4901/zh-cn_image_0000001115549919.png" class=""><p>SCSI码相关信息的VMware链接：<a href="https://kb.vmware.com/s/article/289902?lang=en_US">https://kb.vmware.com/s/article/289902?lang=en_US</a></p><p>SCSI Addition Sense Data链接：<a href="https://www.t10.org/lists/2asc.htm">https://www.t10.org/lists/2asc.htm</a></p><h5 id="VMkwarning-log分析"><a href="#VMkwarning-log分析" class="headerlink" title="VMkwarning.log分析"></a>VMkwarning.log分析</h5><p>VMkwarning.log文件主要捕获主机中的所有告警信息，其中会包含vSAN设备的permenant error、vSAN软件错误以及RAID卡错误，可作为对vobd和VMkernel日志的补充验证，故障时间段截取的信息如下图所示：</p><img src="/posts/4901/zh-cn_image_0000001115391443.png" class=""><p>上图中，lsi_mr3驱动报出了IO返回错误、以及对应的cmd序号和状态码；第1个红色框表示RAID卡下发到磁盘naa.55cd2e414fc9609f的命令出错，系统重新监测命令下发通道是否正常；第2个红色框表示多个vSAN设备掉盘。</p><h4 id="RAID卡日志分析"><a href="#RAID卡日志分析" class="headerlink" title="RAID卡日志分析"></a>RAID卡日志分析</h4><p>RAID卡日志包含了RAID卡运行过程中事件的全部信息，在日志较大的情况下，先根据问题发生的时间点来对应日志中对应的事件范围。值得注意的是，RAID卡内部有独立的计时器，日志上的时间与真实时间并不是直接对应，需要通过查询所在环境的RAID卡时间与真实时间的差，来反推在日志时间中的真实范围。</p><p>如：当前时间为2021/1/8 08:09，查询系统时间及RAID卡时间如下，即RAID卡时间与真实事件有约5小时的时差，而在查询日志事件时则需要往后计算5小时。</p><img src="/posts/4901/zh-cn_image_0000001115326967.png" class=""><img src="/posts/4901/zh-cn_image_0000001115391445.png" class=""><p>在RAID卡日志中，值得注意的异常事件常见有四类，对应的解析与日志记录如下：</p><ul><li><p>返回Unexpected sense</p><img src="/posts/4901/zh-cn_image_0000001115186913.png" class=""><p>当scsi设备进入SCSI contingent allegiance condition时，Scsi initiator会下发相应的requeset sense至scsi设备，同时返回对应的sense key。根据sense key，则可对此时scsi设备的状态进行判断。Sense key的解析可参考SCSI_Primary_Commands(SPC-4).pdf及<a href="https://en.wikipedia.org/wiki/Key_Code_Qualifier%E3%80%82">https://en.wikipedia.org/wiki/Key_Code_Qualifier。</a></p></li><li><p>IO超时</p><img src="/posts/4901/zh-cn_image_0000001115549921.png" class=""><p>当RAID卡与硬盘的通讯发生IO超时，则RAID卡日志中有以上事件记录，关键字为command timeout，同时还会记录超时对应的CDB命令。在某些情况下，还会记录对应的sense key。</p><p>当有以上事件发生时，可认为RAID卡与硬盘之间的通讯出现了问题。</p><p>以上述日志事件记录为例，CDB以28开头对应为read事件，即RAID卡对s5槽位硬盘读取时发生了IO超时。</p></li><li><p>链路重置</p><img src="/posts/4901/zh-cn_image_0000001115326969.png" class=""><p>当RAID卡诊断与某个硬盘的通讯链路存在问题时，即会尝试对该硬盘的链路进行重置。此时RAID卡对硬盘下发comreset命令，在硬盘收到后，链路发生重置，硬盘与RAID卡之间重新建链。这时候则需考虑链路或者硬盘是否存在异常。</p></li><li><p>踢盘</p><img src="/posts/4901/zh-cn_image_0000001115391447.png" class=""><p>踢盘操作与普通拔盘操作在RAID卡日志中都会被记录为removed字样的事件，二者的区分主要根据以下几点：</p><ul><li><p>知道踢盘发生的准确时间点，即此时的removed事件为踢盘操作。</p></li><li><p>在相同的时间点下，BMC中没有对应槽位盘removed的事件记录，即为踢盘。</p></li><li><p>踢盘操作前该槽位的硬盘存在异常行为，如io超时和链路重置，以及RAID卡将该盘的状态转化为UBAD。</p></li></ul></li></ul><h4 id="分析结论"><a href="#分析结论" class="headerlink" title="分析结论"></a>分析结论</h4><p>综合分析故障时收集到的日志，可得出以下几点结论：</p><ul><li>在客户故障时间点确实产生了大量的链路重置和磁盘reset信息，且全部伴随着RAID驱动发出的lsi_mr3错误事件码0x10c。</li><li>从RAID卡和磁盘通信过程中的SCSI返回码来分析，结合VMware官网kb给出的提示，故障的直接原因可以确定是RAID卡发生internal error导致，诱因通常是驱动、固件或者硬件本身。</li></ul><p>客户升级到3408卡最新版的驱动7.713后并未出现超时，目前判断问题的原因很可能是旧版驱动7.703和7.706存在bug。此外，最早的驱动版本7.703和固件版本2139的组合未做过兼容性认证，业界使用的也比较少，后续应该尽量使用和业界厂商一致的组合，这样如果再出现问题就可以向RAID卡厂商寻求很多支持，降低使用非常规的组合配置带来的维护风险。</p><h3 id="兼容性原因定界"><a href="#兼容性原因定界" class="headerlink" title="兼容性原因定界"></a>兼容性原因定界</h3><h4 id="通过VCG查询vSAN部件兼容性"><a href="#通过VCG查询vSAN部件兼容性" class="headerlink" title="通过VCG查询vSAN部件兼容性"></a>通过VCG查询vSAN部件兼容性</h4><p>用于部署VSAN的所有部件（存储控制器、HDD 和 SSD ，包括PCIe SSD和NVMe SSD）都必须在 VMware VSAN硬件兼容性列表上。使用未经认证的硬件以及驱动/固件版本可能导致出现性能问题或者数据丢失。VMware无法对运行于未经认证的硬件上的环境提供支持。由于存储控制器等部件的驱动和固件是存在配套关系的，需要确保对应驱动和固件始终是VMware VSAN硬件兼容性列表上兼容的最新认证版本，因此首先根据客户反馈的环境信息，检测RAID卡和磁盘是否在vSAN兼容性列表中。通用查询步骤如下：</p><ol><li><p>访问VMware VSAN兼容性查询页面：</p><p><a href="http://www.vmware.com/resources/compatibility/search.php?deviceCategory=vsan">http://www.vmware.com/resources/compatibility/search.php?deviceCategory=vsan</a></p></li><li><p>点击“***Build Your Own based on Certified Components***”即可切换到VSAN Certified Components查询页面。</p><img src="/posts/4901/zh-cn_image_0000001115186915.png" class=""></li><li><p>RAID卡查询以SR120为例，在<em><strong>Search For：*<strong>栏选择*</strong>IO Controller**<em>；在</em></strong>Brand Name：*<strong>栏选择“</strong></em>Huawei Technologies Co. Ltd.*<strong>”，然后点击*</strong>Update and View Results***即可查询相应通过认证的RAID卡。</p><img src="/posts/4901/zh-cn_image_0000001115186917.png" class=""></li><li><p>点击搜索到的SR 120，进入后选择需要的OS版本，然后可以查询到该RAID卡支持的驱动和固件版本。</p><img src="/posts/4901/zh-cn_image_0000001115186919.png" class=""></li><li><p>磁盘查询以SSD Intel3500为例，在<em><strong>Search For：*<strong>栏选择*</strong>SSD**<em>；在</em></strong>Partners：*<strong>栏选择相应SSD盘厂商，然后点击</strong></em>Update and View Results***即可查询相应通过认证的SSD。</p><img src="/posts/4901/zh-cn_image_0000001115549927.png" class=""></li></ol><h4 id="通过可视化工具查询兼容性"><a href="#通过可视化工具查询兼容性" class="headerlink" title="通过可视化工具查询兼容性"></a>通过可视化工具查询兼容性</h4><p>除了上一章节中的利用VMware官网VCG进行查询外，还可以利用<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115326921.html">集群日志分析可视化工具</a>中介绍的可视化工具进行快速分析，首先上传集群诊断日志，如果存在兼容性问题则可以在“集群诊断详情”中看到兼容性情况，如果没有兼容性问题则不会有对应告警。</p><img src="/posts/4901/zh-cn_image_0000001115549929.png" class=""><h3 id="硬件类原因定界"><a href="#硬件类原因定界" class="headerlink" title="硬件类原因定界"></a>硬件类原因定界</h3><p>如果是硬件类故障，除了从系统日志分析外，主要还得通过查看iBMC硬件日志进行分析，主要查看底层硬盘日志是否有报错。硬件类日志分析文档在3ms博客上已有很多，这里不再介绍，可参照以下链接：</p><p><a href="http://3ms.huawei.com/km/blogs/details/8253115">http://3ms.huawei.com/km/blogs/details/8253115</a></p><p><a href="http://3ms.huawei.com/km/blogs/details/5292253">http://3ms.huawei.com/km/blogs/details/5292253</a></p><h3 id="软件类及其它原因定界"><a href="#软件类及其它原因定界" class="headerlink" title="软件类及其它原因定界"></a>软件类及其它原因定界</h3><p>实际处理现网问题过程中，存在一部分故障是由于vSAN系统版本、组件或者网络导致的，这类故障的处理不在华为公司的责任范围内，需要告诉客户向VMware公司进行求助。这类问题的定位主要可以通过vc-support日志进行排查。</p><h4 id="vc-support日志概述"><a href="#vc-support日志概述" class="headerlink" title="vc-support日志概述"></a>vc-support日志概述</h4><p>在收集客户日志信息时，很多客户集群的主机数量较多，且每台主机的vm-support日志又较大，所以维护人员通常只能收集到其中几台主机的日志，因此非常有必要通过收集集群整体状态相关的日志来快速对集群进行诊断。由于一个集群只有一个vcenter，因此无论集群中有多少台主机，只需要收集一份该日志即可。</p><h4 id="vc-support日志包结构"><a href="#vc-support日志包结构" class="headerlink" title="vc-support日志包结构"></a>vc-support日志包结构</h4><p>vc-support日志解压后的目录结构如下图：其中最主要的日志目录是commmands和var，commands目录下主要包含了绝大多数的集群配置信息，var目录下主要包含了vcenter采集到的各类日志文件。</p><img src="/posts/4901/zh-cn_image_0000001115326973.png" class=""><h4 id="vmware-vsan-health-summary-result-log日志分析"><a href="#vmware-vsan-health-summary-result-log日志分析" class="headerlink" title="vmware-vsan-health-summary-result.log日志分析"></a>vmware-vsan-health-summary-result.log日志分析</h4><p>vmware-vsan-health-summary-result.log通常可以保存较长时间范围内集群发生的所有告警信息，该文件大概有几百个压缩包，该日志的路径如下图所示：</p><img src="/posts/4901/zh-cn_image_0000001115391449.png" class=""><p>用户可以根据故障发生的时间去寻找对应时间范围的压缩包，并搜索相应的告警。</p><img src="/posts/4901/zh-cn_image_0000001115326975.png" class=""><p>如上图所示，三个红色框给出了物理磁盘、数据对象和内部组件的告警信息，然后根据具体描述去分析故障发生过程。</p><h4 id="vpxd-log日志分析"><a href="#vpxd-log日志分析" class="headerlink" title="vpxd.log日志分析"></a>vpxd.log日志分析</h4><p>vpxd.log属于vCenter的主日志，包含所有 vSphere Client 和 WebServices 连接、内部任务和事件以及与受管 ESXi/ESX 主机上的 vCenter Server Agent进行的通信，日志文件路径如下图所示：</p><img src="/posts/4901/zh-cn_image_0000001115186921.png" class=""><img src="/posts/4901/zh-cn_image_0000001115549931.png" class=""><p>以上图为例，图中的3个红色框分别给出了主机host-23的FDM状态变化、主机上对应的虚拟机故障迁移、异常发生的原因等；此外，可联合其它日志对同一故障时间范围内的问题原因进行定位。</p><h2 id="问题复现测试方案"><a href="#问题复现测试方案" class="headerlink" title="问题复现测试方案"></a>问题复现测试方案</h2><h3 id="测试背景和目标"><a href="#测试背景和目标" class="headerlink" title="测试背景和目标"></a>测试背景和目标</h3><p>2020年4月刚果客户vSAN集群发生磁盘踢盘现象，且出现虚拟机故障并伴有大量的数据同步io，后来通过连续升级RAID卡3408的驱动后，该问题未再出现。为了分析故障原因及RAID卡驱动对于集群性能的影响，在实验室环境中搭建vSAN集群，并采用客户故障现场一致的OS、RAID卡型号及驱动版本，通过模拟各种IO模型来触发磁盘IO超时及踢盘现象。</p><h3 id="测试工具介绍"><a href="#测试工具介绍" class="headerlink" title="测试工具介绍"></a>测试工具介绍</h3><p>为了在实验室环境模拟客户现场踢盘故障，需要模拟各种常用类型的业务负载，业界常用的IO工作负载生成器有fio、vdbench等，而针对vSAN存储系统，VMware推出了专门的存储性能自动化测试工具HCIbench，架构图如下：</p><img src="/posts/4901/zh-cn_image_0000001115326977.png" class=""><p>HCIbench其实也是通过调用fio等测试工具实现集群性能测试自动化，用户只须在测试前指定需要运行测试的参数，HCIbench就会在测试时自动创建虚拟机，完全自动化地实现端到端的虚拟机部署、测试、协调负载运行并汇总测试结果，因此后面测试执行过程也基于HCIbench来介绍。</p><h3 id="测试环境配置"><a href="#测试环境配置" class="headerlink" title="测试环境配置"></a>测试环境配置</h3><p>为模拟客户现场故障，首先需要收集的客户信息主要包括两个方面：集群配置信息、故障前后操作及状态信息。</p><p>由于客户现场故障发生时间距离测试时间较旧，很多信息无法通过客户直接获得，因此目前当前信息主要通过收集的vm-support日志来获取，客户现场配置信息如下：</p><img src="/posts/4901/zh-cn_image_0000001115391453.png" class=""><p>实验室环境所用的OS版本和RAID卡型号与客户保持一致，磁盘模型选用了基于全闪存的SAS华为盘+SATA Intel盘；此外为了尽可能降低磁盘组性能以便于复现，还另外测试了基于混合模式的SAS华为盘+SATA 华为盘，实验室配置信息如下：</p><img src="/posts/4901/zh-cn_image_0000001115549933.png" class=""><h3 id="IO负载规划依据"><a href="#IO负载规划依据" class="headerlink" title="IO负载规划依据"></a>IO负载规划依据</h3><h4 id="测试思路"><a href="#测试思路" class="headerlink" title="测试思路"></a>测试思路</h4><p>整体测试思路如下图所示，由于集群初始状态未知，且从RAID卡错误日志中无法直接得出客户现场故障的诱因，因此尝试分别从性能测试瓶颈、故障场景模拟等边界去触发磁盘故障踢盘。</p><img src="/posts/4901/zh-cn_image_0000001115326979.png" class=""><h4 id="IO性能指标及负载组合"><a href="#IO性能指标及负载组合" class="headerlink" title="IO性能指标及负载组合"></a>IO性能指标及负载组合</h4><p>IO负载测试时需要模拟尽可能大的负载，常用的性能指标有IOPS、Throughput（吞吐量）和latency（延迟）。因此如果要从性能角度测出vSAN集群的边界值，就需要从以上三个方面分别规划IO模型。</p><p>根据HCIbench官网的负载模型介绍，针对不同的性能指标须对应不同的负载组合，典型HCIbench参数表配置基准如下表：</p><img src="/posts/4901/zh-cn_image_0000001115186925.png" class=""><img src="/posts/4901/zh-cn_image_0000001115549935.png" class=""><p>官方推荐的性能调优方式如上，在各性能指标的配置基准上，单调调整其中一项参数即可提高测试结果的单一性能指标值。</p><h4 id="故障场景模拟"><a href="#故障场景模拟" class="headerlink" title="故障场景模拟"></a>故障场景模拟</h4><p>由于客户现场发生磁盘offline现象时不确定集群处于何种状态，因此模拟一些常用的故障场景，并在这些故障场景下尝试触发Power-on Reset告警。</p><ul><li><p>磁盘故障及模拟</p><p>容量盘或缓存盘故障是任何存储环境中最常见的故障，其中容量盘故障只影响单块磁盘数据，而缓存盘故障会影响整个磁盘组所有数据，当故障磁盘上的组件超过1个小时后集群会重新发起组件重构，集群中会产生一定的重建数据IO，但所有的虚拟机及数据可用性不会受影响。如果要模拟该故障直接拔出测试磁盘即可。</p></li><li><p>主机故障及模拟</p><p>主机故障发生后，主机上所有磁盘组的数据都会不可用，如果超过1个小时后主机依然未能恢复，则集群中将会发起大量重建数据IO，在3节点的集群中，如果单节点主机故障不会影响虚拟机及数据可用性，但重建的数据IO会占用大量网络带宽，会影响业务IO吞吐量。如果要模拟该故障可以将单台主机断开（网络断开或者电源断开）。</p></li><li><p>磁盘容量超载及模拟</p><p>磁盘容量超过阈值时，集群会自动进行数据重平衡操作，此时集群中也会产生大量数据io；此外，如果某些磁盘已经完全被写满时，vSAN集群会暂停对这些磁盘的发出写请求的虚拟机，即这部分虚拟机会变得不可用。如果要模拟该故障可以在配置HCIbench参数时适当增大虚拟机数量和磁盘大小使之超出集群容量阈值。</p></li></ul><h4 id="IO负载测试参数"><a href="#IO负载测试参数" class="headerlink" title="IO负载测试参数"></a>IO负载测试参数</h4><p>IO工作负载的测试参数除了<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115549893.html">IO性能指标及负载组合</a>中的基本参数配置外，常用的还包括块尺寸、读写比例、随机性、工作集大小、队列深度等，针对常用的业务负载模型，HCIbench官网也给出了基准配置建议，如下图：</p><img src="/posts/4901/zh-cn_image_0000001115391455.png" class=""><p>其中，现实中最常见的测试参数为快尺寸=4k，70%比例读，100%随机性，大部分的web应用就可以归到这一类中；像OLTP这类的业务类型，就可以采用快尺寸=8k，50%比例读，100%随机性来模拟；如果要追求最大吞吐量，就可以增加块尺寸，并以顺序写的方式来执行测试。</p><p>以上给出的是官方提供的一些常用经验，可以作为调试参数的参考基准，在实际测试过程中应根据需求适当调整，得出的结论以实际测试结果为准。</p><h4 id="测试执行过程"><a href="#测试执行过程" class="headerlink" title="测试执行过程"></a>测试执行过程</h4><h5 id="HCIbench工具下载及部署"><a href="#HCIbench工具下载及部署" class="headerlink" title="HCIbench工具下载及部署"></a>HCIbench工具下载及部署</h5><p>首先从VMware官网下载的HCIbench模板，链接：<a href="https://flings.vmware.com/hcibench">https://flings.vmware.com/hcibench</a></p><p>接着在vSAN集群中部署HCIbench虚拟机，具体步骤如下：</p><ol><li><p>选择下载的OVF模板。</p><img src="/posts/4901/zh-cn_image_0000001115391457.png" class=""></li><li><p>选择部署虚拟机的数据中心和集群。</p><img src="/posts/4901/zh-cn_image_0000001115186927.png" class=""></li><li><p>选择一个vSAN数据存储进行部署。</p><img src="/posts/4901/zh-cn_image_0000001115186929.png" class=""></li><li><p>选择虚拟机部署的网络。</p><img src="/posts/4901/zh-cn_image_0000001115326985.png" class=""></li><li><p>输入HCIbench虚拟机的root密码。</p><img src="/posts/4901/zh-cn_image_0000001115391459.png" class=""></li><li><p>完成配置，等虚拟机部署完成后启动电源。</p><img src="/posts/4901/zh-cn_image_0000001115549939.png" class=""></li><li><p>登录HCIbench测试页面地址<a href="https://hcibenchip/8443%EF%BC%8C%E5%B9%B6%E8%BE%93%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E5%AF%86%E7%A0%81%E5%90%8E%E5%8F%AF%E4%BB%A5%E8%BF%9B%E5%85%A5%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E4%B8%BB%E9%A1%B5%EF%BC%8C%E5%A6%82%E4%B8%8B%E5%9B%BE%EF%BC%9A">https://HCIbenchIP:/8443，并输入虚拟机的用户名和密码后可以进入配置参数主页，如下图：</a></p><img src="/posts/4901/zh-cn_image_0000001115186931.png" class=""></li></ol><h5 id="设定测试参数"><a href="#设定测试参数" class="headerlink" title="设定测试参数"></a>设定测试参数</h5><p>首先在“Configuration”页面输入集群相关信息，如vCenter IP、vCenter登录账户、数据中心名等，接着选择底层基准测试工具为fio,然后在Guest VM Confituration配置填入响应的负载组合参数，例如每台主机4个VM，每个VM8个虚拟磁盘，每个磁盘大小100G，如下图：</p><img src="/posts/4901/zh-cn_image_0000001115549943.png" class=""><p>在上图的“Workload Parameter File”中选择“ADD”可以新建IO参数配置表，具体涉及的参数选项如下：</p><img src="/posts/4901/zh-cn_image_0000001115326987.png" class=""><p>上图的负载参数配置完成后，会自动在配置主页生成配置选项，保存之后点击“start test”即可自动化执行测试，如下图：</p><img src="/posts/4901/zh-cn_image_0000001115391463.png" class=""><h5 id="收集测试结果"><a href="#收集测试结果" class="headerlink" title="收集测试结果"></a>收集测试结果</h5><p>当完成一次测试后，点击参数配置页的“Review Result”可以查看本次测试运行结果，包含整体性能测试参数，如下图：</p><img src="/posts/4901/zh-cn_image_0000001115549945.png" class=""><p>此外，还包含了所有虚拟机相关的性能参数，例如IOPS吞吐量、读写延迟等</p><img src="/posts/4901/zh-cn_image_0000001115186933.png" class=""><p>点击参数配置页的“Save Result”可以保存本次测试运行结果。</p><h4 id="测试记录及分析"><a href="#测试记录及分析" class="headerlink" title="测试记录及分析"></a>测试记录及分析</h4><p>在实际测试过程中综合以上所述的负载组合和运行参数，包含了几十种业务负载场景，梳理测试记录大致如下表：</p><img src="/posts/4901/zh-cn_image_0000001115549947.png" class=""><p>通过以上测试记录，可以得出以下几点测试结论：</p><ul><li>测试虚拟机如果要模拟大的IO 写吞吐量，可以使用较大的快尺寸，且尽量减少混合比例。</li><li>测试虚拟机如果需要模拟大的延迟，影响较大的因素是调高虚拟磁盘的队列深度，但要跟实际使用的物理磁盘相关联。通常来说SSD磁盘队列深度为256，HDD磁盘队列深度为32；其次可以增加虚拟机数量。</li><li>测试虚拟机如果需要模拟高的IO读写性能且尽可能符合常用业务模型，推荐使用70r30w100Random模型，4k大小的块尺寸（为最大程度避免出现一些常见的类似日志拥堵的异常，其实在调试的过程中块大小应该用4k的倍数）。</li><li>如果在测试过程中引入模拟故障，与正常测试状态相比IO读写性能和吞吐量会有一定程度的下降。</li><li>负载测试过程中，若要提高某一项性能指标，不能单一对虚拟机或虚拟磁盘加的过大，否则容易导致vSAN内部组件内存不足出现vmkernel报错，导致收集的测试结果为空。</li></ul><h4 id="问题复现结果"><a href="#问题复现结果" class="headerlink" title="问题复现结果"></a>问题复现结果</h4><ul><li><p>通过收集以上负载模型的测试结果，在系统参数/LSOM/diskIoTimeout &lt;= 3s的条件下可以复现出与客户故障一致的场景，即系统日志和RAID卡日志中出现关键的日志报错信息。</p></li><li><p>3408卡的7.703、7.706和7.713驱动的故障复现对比。</p><img src="/posts/4901/zh-cn_image_0000001115549949.png" class=""></li></ul><h2 id="解决方案-amp-建议"><a href="#解决方案-amp-建议" class="headerlink" title="解决方案&amp;建议"></a>解决方案&amp;建议</h2><h3 id="升级RAID卡驱动及固件"><a href="#升级RAID卡驱动及固件" class="headerlink" title="升级RAID卡驱动及固件"></a>升级RAID卡驱动及固件</h3><h5 id="升级的必要性"><a href="#升级的必要性" class="headerlink" title="升级的必要性"></a>升级的必要性</h5><p>vSAN属于硬件强认证的超融合存储方案，首先需要保证集群的RAID卡和磁盘的型号、驱动、固件版本必须在VMware官网的兼容性列表范围内；其实，RAID卡厂商针对旧版本出现过的问题都会通过升级来修复，因此在满足VCG的基础上尽可能地升级到已通过IOVP认证的最新版本，此外出现vSAN软件方面的问题时VMware通常也会要求客户升级完成后才会介入问题处理。</p><h5 id="驱动升级方法"><a href="#驱动升级方法" class="headerlink" title="驱动升级方法"></a>驱动升级方法</h5><ol><li><p>RAID卡的驱动可以直接在VMware官网上进行下载，下面以7.713.07.00为例进行介绍，下载链接：<a href="https://my.vmware.com/web/vmware/details?downloadGroup=DT-ESXI65-BROADCOM-LSI-MR3-77130700-1OEM&amp;productId=614">https://my.vmware.com/web/vmware/details?downloadGroup=DT-ESXI65-BROADCOM-LSI-MR3-77130700-1OEM&amp;productId=614</a></p></li><li><p>获得驱动包后上传到ESXi主机上，然后通过ESXi的通用命令行安装方式进行升级。</p><img src="/posts/4901/zh-cn_image_0000001115326993.png" class=""><p>以上提示说明升级成功，重启主机后新驱动可以生效。</p><img src="/posts/4901/icon-note.png" class=""> **说明：**<p>如果驱动版本需要回退，操作方法与升级完全相同，执行上述命令即可，系统会自动remove现有的驱动并安装新的驱动。</p></li></ol><h5 id="固件升级方法"><a href="#固件升级方法" class="headerlink" title="固件升级方法"></a>固件升级方法</h5><ol><li><p>RAID卡的固件升级需要先下载RAID卡管理工具和固件包。</p><ul><li><p>RAID卡管理工具需要登录博通官网进行下载，链接：</p><p><a href="https://www.broadcom.com/products/storage/raid-controllers/megaraid-9440-8i#downloads">https://www.broadcom.com/products/storage/raid-controllers/megaraid-9440-8i#downloads</a></p><p>通常是后缀为.vib的安装包，如下图：</p><img src="/posts/4901/zh-cn_image_0000001115391471.png" class=""></li><li><p>固件包可以在Support网站</p><p>FusionServer iDriver</p><p>下载，通常是后缀为.rom的安装包（如果是公司还未引入的固件版本，那么须通过兼容性测试团队找厂商提供固件包）。</p><img src="/posts/4901/zh-cn_image_0000001115186937.png" class=""></li></ul></li><li><p>获得以上安装包后先上传到ESXi主机，首先安装管理工具storcli.vib，命令如下：</p><img src="/posts/4901/zh-cn_image_0000001115326995.png" class=""></li><li><p>该工具安装完成后无需重启，然后切换到/opt/lsi/storcli目录下，执行以下命令进行升级：</p><p><strong>./storcli /c0 download file=HuaWei_SAS3408_nopad.rom noverchk</strong></p><p>升级截图及结果如下：</p><img src="/posts/4901/zh-cn_image_0000001115391473.png" class=""><p>固件升级成功后需要重启主机使新固件生效。</p><img src="/posts/4901/icon-note.png" class=""> **说明：**<p>如果固件版本需要回退，同样执行上图执行的命令即可。命令的最后一个参数noverchk表示跳过版本验证，如果不带该参数，则该命令只能用于升级，加了该参数后升级和回退都可以适用。</p></li></ol><h4 id="验证集群配置一致性"><a href="#验证集群配置一致性" class="headerlink" title="验证集群配置一致性"></a>验证集群配置一致性</h4><p>实际现网问题中，排查过程中发现问题经常都出在集群的配置上，最基础的要求是所有的节点的OS版本、RAID卡型号及驱动版本要保持一致；其次使用的磁盘模型必须一致，例如所有节点都是混合模式或者都为全闪存；此外，所有节点的磁盘类型没有强制要求，但为了达到最佳的性能和利用率，推荐使用型号和固件版本一致的磁盘，至少容量和性能等级要求保持一致；例如在刚果项目中综合使用了Micron和Intel的磁盘作为容量盘，但两种磁盘的性能等级不一致（C和E），其实也会影响vSAN集群整体的性能。</p><p>集群的整体磁盘信息状态检测可通过vc-support日志查看，解压vc-support日志后，然后打开commands目录中的文件python_usrlibvmware-vpxvsan-healthvsan-vc-health-statuspy-rvc-basic-support-information.txt，可以查到集群中每个节点包含的磁盘数量、磁盘型号、使用率及磁盘格式等。如果要查看每个节点，截图如下：</p><img src="/posts/4901/zh-cn_image_0000001115186941.png" class=""><p>集群的整体RAID卡驱动和固件版本检查可通过集群健康状态诊断，具体可参照<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0000001115186865.html">集群健康状态诊断</a>，单台主机的RAID卡详细信息可查找vm-support日志下commands目录的localcli_vsan-debug-controller-list.txt文件，信息截图如下：</p><img src="/posts/4901/zh-cn_image_0000001115549951.png" class=""><h4 id="系统参数优化"><a href="#系统参数优化" class="headerlink" title="系统参数优化"></a>系统参数优化</h4><p>vSAN集群运行过程中，由于比较早的ESXi版本存在一些bug，有时候须通过调整vSAN内部组件参数，如/LSOM/diskIoTimeout、/LSOM/blPLOGCacheLines、/LSOM/blLLOGCacheLines、/LSOM/blPLOGLsnCacheLines等首先获取这些参数的当前值命令如下图所示：</p><img src="/posts/4901/zh-cn_image_0000001115326997.png" class=""><p>在vSAN集群实际负载测试过程中，为了避免出现各种拥堵类的故障以及减少IO超时影响,可以根据实际情况适当增加以上几个参数的值，以/LSOM/diskIoTimeout为例，如果要将该值调整为10s则执行命令如下：</p><img src="/posts/4901/zh-cn_image_0000001115391475.png" class=""><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="VMware官网知识库"><a href="#VMware官网知识库" class="headerlink" title="VMware官网知识库"></a>VMware官网知识库</h3><p>问题排查和日志分析过程中，分析重要信息时第一优先级搜索VMware官网知识库（KB）,在KB中尝试输入不同关键字，可快速获取是否已有类似案例及解决措施，链接地址如下：</p><p><a href="https://kb.vmware.com/s/">https://kb.vmware.com/s/</a></p><h3 id="vSAN诊断工具RVC"><a href="#vSAN诊断工具RVC" class="headerlink" title="vSAN诊断工具RVC"></a>vSAN诊断工具RVC</h3><p>如果需要对客户环境进行实时排查，可以通过vCenter中的rvc命令在线查看整个集群的状态，需要通过ssh登录到vCenter主机的BASH，详细操作手册可访问vmware官网，链接地址：</p><p><a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/products/vsan/vmware-ruby-vsphere-console-command-reference-for-virtual-san.pdf">https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/products/vsan/vmware-ruby-vsphere-console-command-reference-for-virtual-san.pdf</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
            <tag> vSAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VMvare的HBA卡驱动存储常见案例</title>
      <link href="/posts/31022/"/>
      <url>/posts/31022/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="Vmvare的HBA卡驱动存储常见案例"><a href="#Vmvare的HBA卡驱动存储常见案例" class="headerlink" title="Vmvare的HBA卡驱动存储常见案例"></a>Vmvare的HBA卡驱动存储常见案例</h1><h2 id="解决措施"><a href="#解决措施" class="headerlink" title="解决措施"></a>解决措施</h2><h3 id="场景1：存储链路故障恢复后MZ220与存储建链失败问题"><a href="#场景1：存储链路故障恢复后MZ220与存储建链失败问题" class="headerlink" title="场景1：存储链路故障恢复后MZ220与存储建链失败问题"></a>场景1：存储链路故障恢复后MZ220与存储建链失败问题</h3><p><strong>问题现象描述</strong></p><p>问题现象：现场组网E9000（MZ220+CX220AG）链接核心光交，光交链接存储。存储与光交之间报口fault，更换光纤光模块后物理链路恢复，但是部分主机与存储之间链路没有自动恢复。</p><p><strong>关键过程、根本原因分析</strong></p><ol><li>存储侧分析，存储与光交链路恢复后，正常情况主机要继续下发PRLI建立4层链接，但是存储侧未收到主机发起的PRLI：</li></ol>  <img src="/posts/31022/zh-cn_image_0261927583.jpg" class=""><ol start="2"><li><p>PRLI失败原因为主机未发起PRLI或由于链路质量问题导致PRLI报文丢失。</p></li><li><p>光交日志显示zone配置正常，端口注册状态也无异常记录；交换板端口相关日志显示端口光功率正常，且误码无增长。故当前日志中未发现链路质量问题。</p><p>端口注册情况：</p></li></ol>  <img src="/posts/31022/zh-cn_image_0261927663.png" class=""><p>   交换端口光功率及误码情况：</p>  <img src="/posts/31022/zh-cn_image_0261927584.png" class=""><ol start="4"><li>查看主机信息，当前使用的HBA卡为MZ220，芯片类型为Emulex Lancer。</li></ol>  <img src="/posts/31022/zh-cn_image_0261927665.jpg" class=""><ol start="5"><li>出现异常的主机dmesg日志中有如下RegLogin failed记录：</li></ol>  <img src="/posts/31022/zh-cn_image_0261927664.jpg" class=""><ol start="6"><li>拉通HBA卡芯片厂商Broadcom对该问题进行分析，Broadcom工程师反馈错误打印中的xc状态说明PRLI资源耗尽导致RegLogin failed。结合之前SFP异常的问题，怀疑原因为SFP异常引起链路抖动，该过程中主机HBA driver不断向firmware注册RPI，导致firmware的PRLI资源耗尽，无法正常建立链接。该问题与Emulex内部已知案例匹配，在11.0.106.0版本驱动解决。</li></ol>  <img src="/posts/31022/zh-cn_image_0261927685.jpg" class=""><ol start="7"><li>现场使用的驱动版本为10.7.0.1，涉及Broadcom工程师所说的问题。</li></ol>  <img src="/posts/31022/zh-cn_image_0261927674.png" class=""><p><strong>结论、解决方案及效果</strong></p><p>结论：</p><p>MZ220卡11.0.106.0以前版本驱动存在链路抖动时，不断向firmware注册RPI，导致firmware的PRLI资源耗尽，无法正常建立链接的问题。</p><p>解决方案：</p><p>升级MZ220驱动至11.0.106.0以上版本，建议升级至support官网版本配套表推荐版本。</p><h3 id="场景2：RH2288H-V3安装ESXi-6-7系统概率出现宕机，操作系统IP不通"><a href="#场景2：RH2288H-V3安装ESXi-6-7系统概率出现宕机，操作系统IP不通" class="headerlink" title="场景2：RH2288H V3安装ESXi 6.7系统概率出现宕机，操作系统IP不通"></a>场景2：RH2288H V3安装ESXi 6.7系统概率出现宕机，操作系统IP不通</h3><p><strong>问题现象描述</strong></p><p>硬件配置：RH2288H V3（配置3108 RAID卡） 安装EXSi6.7</p><p>问题现象：概率出现操作系统宕机，操作系统ip不通，但未发生紫屏，BMC正常，过一段时间可自行恢复，或强制重启操作系统恢复。</p><p><strong>关键过程、根本原因分析</strong></p><p>关键过程：</p><ol><li><p>BMC硬件日志分析无异常。</p></li><li><p>系统恢复后搜集vm-support日志分析，在VMkernel.log记录大量的sioc错误</p></li></ol><img src="/posts/31022/zh-cn_image_0261928120.png" class=""><img src="/posts/31022/zh-cn_image_0261928151.png" class=""><p><strong>根本原因分析：</strong></p><p>VMware support答复是其操作系统bug，ESXi6.7存在已知操作系统bug，参考如下KB</p><p><a href="https://kb.vmware.com/s/article/67543">https://kb.vmware.com/s/article/67543</a></p><img src="/posts/31022/zh-cn_image_0261928152.png" class=""><p><strong>结论、解决方案及效果</strong></p><p>结论：ESXi6.7存在已知操作系统bug</p><p>解决方案：参考上述VMware KB</p><h3 id="场景3：端口占用MSIX中断超过系统资源导致VMware紫屏问题"><a href="#场景3：端口占用MSIX中断超过系统资源导致VMware紫屏问题" class="headerlink" title="场景3：端口占用MSIX中断超过系统资源导致VMware紫屏问题"></a>场景3：端口占用MSIX中断超过系统资源导致VMware紫屏问题</h3><p><strong>问题现象描述</strong></p><p>现象：XX局点在现网将MZ910卡Firmware和driver从RT10.2版本升级到RT11.1版本后，出现VMware紫屏问题。</p><p><strong>关键过程、根本原因分析</strong></p><p>从VMware日志来看，发现日志中出现大量的HBA卡的告警信息：</p><img src="/posts/31022/zh-cn_image_0261928675.jpg" class=""><p>进一步分析，这些告警信息来源于工作在interrupt模式的FCoE端口：</p><img src="/posts/31022/zh-cn_image_0261928676.jpg" class=""><p>而这些端口本应该工作在MSIX模式下，却因无法获得到MSIX中断，被迫改为interrupt模式。</p><p>通过查询VMware下中断数量，发现VMware5.5中MSIX中断个数约为200个，其中OS占用了约50个中断，剩下留给driver的中断个数约为150个。而Emulex网卡驱动从RT10.6版本开始，由于功能的复杂，nic网口需要占用16个中断，FCoE网口需要占用4个中断。客户现场使用了4张工作在FCoE模式下的MZ910，每张卡有4个nic和2个FCoE网口，需要72个MSIX中断，4张卡共需要288个MSIX中断，远远超出系统所拥有的资源。</p><img src="/posts/31022/zh-cn_image_0261928157.jpg" class=""><p>根据VMware的KB信息，对于ESXi5.5系统，由于OS本身的限制，MSIX中断数量不会超过250个，无法通过技术手段去增加。且VMware已经承认此问题并表示不会去解决它。</p><p><a href="http://www.dell.com/support/article/cn/zh/cndhs1/SLN294292/additional-information-regarding-esxi5x-and-vectors?lang=EN">http://www.dell.com/support/article/cn/zh/cndhs1/SLN294292/additional-information-regarding-esxi5x-and-vectors?lang=EN</a></p><p><strong>结论、解决方案及效果</strong></p><p>结论：ESXi5.5系统中MSIX中断资源不满足MZ卡需求。</p><p>规避措施：将不使用的网卡/FCoE口设置为直通模式，则对应端口将不再占用MSIX中断个数。</p><p>解决方案：将OS升级到ESXi6.0及以上版本，无此问题。根据VMware的KB信息，从ESXi6.0开始，MSIX中断数量超过1k个，此问题被根除。</p><p><a href="https://docs.vmware.com/en/VMware-vSphere/6.0/com.vmware.vsphere.networking.doc/GUID-DA8506CE-7813-4B4C-BE14-9B42C36637BA.html">https://docs.vmware.com/en/VMware-vSphere/6.0/com.vmware.vsphere.networking.doc/GUID-DA8506CE-7813-4B4C-BE14-9B42C36637BA.html</a></p><h3 id="场景4：ESXi禁用Interrupt-Remapper中断映射导致Qlogic-FC-HBA卡链路闪断及紫屏案例"><a href="#场景4：ESXi禁用Interrupt-Remapper中断映射导致Qlogic-FC-HBA卡链路闪断及紫屏案例" class="headerlink" title="场景4：ESXi禁用Interrupt Remapper中断映射导致Qlogic FC HBA卡链路闪断及紫屏案例"></a>场景4：ESXi禁用Interrupt Remapper中断映射导致Qlogic FC HBA卡链路闪断及紫屏案例</h3><p><strong>问题现象描述</strong></p><p>RH2288H V3服务器配置Qlogic FC HBA卡，运行Esxi6.0u3系统存在FC HBA卡链路闪断，导致存储LUN断开或紫屏。</p><p><strong>关键过程、根本原因分析</strong></p><p>关键过程分析</p><p>1、OS主机日志文件vmkernel中存在qlnativefc驱动打印如下错误。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">2017-08-09T05:12:38.068Z cpu44:77853)WARNING: qlnativefc: vmhba2(44:0.0): Timeout: Max mbx wait reached.</span><br><span class="line">2017-08-09T05:12:38.068Z cpu44:77853)WARNING: qlnativefc: vmhba2(44:0.0): Mailbox command 0x54 timeout occurred. Issuing ISP abort.</span><br><span class="line">2017-08-09T05:12:38.068Z cpu44:77853)WARNING: qlnativefc: vmhba2(44:0.0): Firmware has been previously dumped (0x4307cc8f3000) -- ignoring request...</span><br><span class="line">2017-08-09T05:12:38.068Z cpu44:77853)qlnativefc: vmhba2(44:0.0): Inside qlnativefcAbortIsp</span><br><span class="line">2017-08-09T05:12:38.068Z cpu44:77853)qlnativefc: vmhba2(44:0.0): Performing ISP error recovery - ha= 0x4307d3a6dc20.</span><br><span class="line">2017-08-09T05:13:08.070Z cpu88:140078)WARNING: qlnativefc: vmhba2(44:0.0): Timeout: Max mbx wait reached.</span><br><span class="line">2017-08-09T05:13:08.080Z cpu37:77853)qlnativefc: vmhba2(44:0.0): FW: Loading via request-firmware...</span><br><span class="line">2017-08-09T05:13:08.158Z cpu30:77853)WARNING: qlnativefc: vmhba2(44:0.0): Firmware dump previously allocated.</span><br><span class="line">2017-08-09T05:13:08.169Z cpu30:77853)qlnativefc: vmhba2(44:0.0): Setting ELS command intercept.</span><br><span class="line">2017-08-09T05:13:08.191Z cpu41:77853)qlnativefc: vmhba2(44:0.0): Enabling PUREX.</span><br><span class="line">2017-08-09T05:13:08.202Z cpu28:77853)qlnativefc: vmhba2(44:0.0): DPORT feature : disabled.</span><br><span class="line">2017-08-09T05:13:08.202Z cpu28:77853)qlnativefc: vmhba2(44:0.0): FAWWN feature : disabled.</span><br><span class="line">2017-08-09T05:13:09.292Z cpu38:77853)qlnativefc: vmhba2(44:0.0): LIP reset occured (f700).</span><br><span class="line">2017-08-09T05:13:09.327Z cpu38:77853)qlnativefc: vmhba2(44:0.0): LOOP UP detected (4 Gbps).</span><br><span class="line">2017-08-09T05:13:10.745Z cpu29:77853)qlnativefc: vmhba2(44:0.0): fcport 2200886639aca5fc (targetId = 0) ONLINE</span><br><span class="line">2017-08-09T05:13:10.780Z cpu29:77853)qlnativefc: vmhba2(44:0.0): fcport 2201886639aca5fc (targetId = 1) ONLINE</span><br><span class="line">2017-08-09T05:13:10.813Z cpu34:77853)qlnativefc: vmhba2(44:0.0): fcport 2210886639aca5fc (targetId = 2) ONLINE</span><br><span class="line">2017-08-09T05:13:10.856Z cpu51:77853)qlnativefc: vmhba2(44:0.0): fcport 2211886639aca5fc (targetId = 3) ONLINE</span><br><span class="line">2017-08-09T05:13:11.346Z cpu28:77853)qlnativefc: vmhba2(44:0.0): fcport 20000425c5e7a5f5 (targetId = 4) ONLINE</span><br></pre></td></tr></table></figure><p><strong>图****1</strong> vmkernel日志片段</p><img src="/posts/31022/zh-cn_image_0261929463.jpg" class=""><p>2、Esxi系统紫屏时，vmkernel日志中会伴随如下类似信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALERT: IntrCookie: 3411: Interrupt received on invalid vector (cpu 0, vector 72); ignoring it.</span><br></pre></td></tr></table></figure><p><strong>根本原因分析：</strong></p><p>为了在处理器之间平均分布中断负载，ESXi 会执行中断重新平衡。在此过程中，ESXi 可能会修改分配给I/O设备的目标处理器和中断向量。此过程称为I/O设备中断迁移。当平台中不存在VT-d中断重新映射程序或ESXi中已禁用VT-d中断重新映射程序（引导选项iovDisableIR=TRUE）时，ESXi 会通过修改I/O设备中的PCI MSI/MSI-X寄存器来执行I/O设备中断迁移。ESXi 在意外处理器中断向量上接收到中断，并已忽略该中断，因为ESXi不知道中断源或要调用的软件处理程序，接收此类中断是不正常的，并且可能会导致断开I/O连接和/或出现ESXi PSOD。</p><p><strong>结论、解决方案及效果</strong></p><p>结论：</p><p>为了在处理器之间平均分布中断负载，ESXi 会执行中断重新平衡。在此过程中，ESXi 可能会修改分配给I/O设备的目标处理器和中断向量。此过程称为I/O设备中断迁移。当平台中不存在VT-d中断重新映射程序或ESXi中已禁用VT-d中断重新映射程序（引导选项iovDisableIR=TRUE）时，ESXi 会通过修改I/O设备中的PCI MSI/MSI-X寄存器来执行I/O设备中断迁移。ESXi 在意外处理器中断向量上接收到中断，并已忽略该中断，因为ESXi不知道中断源或要调用的软件处理程序，接收此类中断是不正常的，并且可能会导致断开I/O连接和/或出现ESXi PSOD。</p><p>解决方案：</p><p>参考VMware KB启用interrupt remapper中断映射方式，不使用Esxi提供的IOV特性。</p><p><a href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2150191">https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2150191</a></p><p>具体步骤如下：</p><p>通过将 vmkernel 引导选项iovDisableIR设置为FALSE来启用 VT-d 中断重新映射程序。</p><ol><li>使用 SSH 会话和 root 凭据连接到 ESXi 主机。</li><li>运行以下命令： esxcli system settings kernel set –setting=iovDisableIR -v FALSE</li><li>重新引导 ESXi 主机。</li><li>运行以下命令，确保 iovDisableIR 设置为 FALSE：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">esxcli system settings kernel list -o iovDisableIR</span><br></pre></td></tr></table></figure><p>例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">esxcli system settings kernel list -o iovDisableIR</span><br><span class="line">Name Type Description Configured Runtime Default</span><br><span class="line">------------ ---- --------------------------------------- ---------- ------- -------</span><br><span class="line">iovDisableIR Bool Disable Interrupt Routing in the IOMMU... FALSE FALSE TRUE</span><br></pre></td></tr></table></figure><p>如果发现其他 ESXi 版本存在此问题，请执行以下操作：</p><ul><li><p>确保在 BIOS中启用 VT-d 中断重新映射程序。</p></li><li><p>运行以下命令验证是否处于启用状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vsish -e get /hardware/iov/IntrRemappingEnabled</span><br></pre></td></tr></table></figure><p>如果已在 BIOS中启用 VT-d 中断重新映射程序并用于 ESXi，则此命令返回值1，否则返回值0。</p></li><li><p>如果警示仍然存在，请联系 VMware 技术支持，提出支持请求。</p></li></ul><h3 id="场景5：MZ910网卡与HP-3PAR-20000存储兼容性导致紫屏问题"><a href="#场景5：MZ910网卡与HP-3PAR-20000存储兼容性导致紫屏问题" class="headerlink" title="场景5：MZ910网卡与HP 3PAR 20000存储兼容性导致紫屏问题"></a>场景5：MZ910网卡与HP 3PAR 20000存储兼容性导致紫屏问题</h3><p><strong>关键过程、根本原因分析</strong></p><p>经网卡厂家初步分析，发现DIF报错：</p><p>1）HBA驱动报了DI_ERROR，也在存储上看到了DIF CRC error：</p><img src="/posts/31022/zh-cn_image_0262030477.png" class=""><p>2）从11.1 的代码上来看，驱动对HP 3PAR设备的T10-DIF 有特殊处理：</p><p>驱动文件lpfc.h 中，line 360行，看到只有对 HP “3PARdata”的特殊处理，没看到对其它存储设备有这样的特殊处理。</p><img src="/posts/31022/zh-cn_image_0262030273.png" class=""><p>3）在HP的官网上有类似问题：正好客户现场的存储型号是3PAR 20000，在受影响的设备列表里。Emulex的内部buglist帮忙也看下，应该有这个的说明。</p><p><a href="https://h20564.www2.hpe.com/hpsc/doc/public/display?docId=emr_na-c05348035de_de">https://h20564.www2.hpe.com/hpsc/doc/public/display?docId=emr_na-c05348035de_de</a></p><img src="/posts/31022/zh-cn_image_0262030478.png" class=""><p><strong>结论、解决方案及效果</strong></p><p>MZ910网卡RT11.1版本驱动在开启T10_DIF特性后，与HP 3PAR 20000存储有兼容性问题。</p><h3 id="场景6：端口占用MSIX中断超过系统资源导致VMware紫屏问题"><a href="#场景6：端口占用MSIX中断超过系统资源导致VMware紫屏问题" class="headerlink" title="场景6：端口占用MSIX中断超过系统资源导致VMware紫屏问题"></a>场景6：端口占用MSIX中断超过系统资源导致VMware紫屏问题</h3><p><strong>问题现象描述</strong></p><p>现象：XX局点在现网将MZ910卡Firmware和driver从RT10.2版本升级到RT11.1版本后，出现VMware紫屏问题。</p><p><strong>关键过程、根本原因分析</strong></p><p>从VMware日志来看，发现日志中出现大量的HBA卡的告警信息：</p><img src="/posts/31022/zh-cn_image_0262031916.jpg" class=""><p>进一步分析，这些告警信息来源于工作在interrupt模式的FCoE端口：</p><img src="/posts/31022/zh-cn_image_0262031917.jpg" class=""><p>而这些端口本应该工作在MSIX模式下，却因无法获得到MSIX中断，被迫改为interrupt模式。</p><p>通过查询VMware下中断数量，发现VMware5.5中MSIX中断个数约为200个，其中OS占用了约50个中断，剩下留给driver的中断个数约为150个。而Emulex网卡驱动从RT10.6版本开始，由于功能的复杂，nic网口需要占用16个中断，FCoE网口需要占用4个中断。客户现场使用了4张工作在FCoE模式下的MZ910，每张卡有4个nic和2个FCoE网口，需要72个MSIX中断，4张卡共需要288个MSIX中断，远远超出系统所拥有的资源。</p><img src="/posts/31022/zh-cn_image_0262031918.jpg" class=""><p>根据VMware的KB信息，对于ESXi5.5系统，由于OS本身的限制，MSIX中断数量不会超过250个，无法通过技术手段去增加。且VMware已经承认此问题并表示不会去解决它。</p><p><a href="http://www.dell.com/support/article/cn/zh/cndhs1/SLN294292/additional-information-regarding-esxi5x-and-vectors?lang=EN">http://www.dell.com/support/article/cn/zh/cndhs1/SLN294292/additional-information-regarding-esxi5x-and-vectors?lang=EN</a></p><p><strong>结论、解决方案及效果</strong></p><p>结论：ESXi5.5系统中MSIX中断资源不满足MZ卡需求。</p><p>规避措施：将不使用的网卡/FCoE口设置为直通模式，则对应端口将不再占用MSIX中断个数。</p><p>解决方案：将OS升级到ESXi6.0及以上版本，无此问题。根据VMware的KB信息，从ESXi6.0开始，MSIX中断数量超过1k个，此问题被根除。</p><p><a href="https://docs.vmware.com/en/VMware-vSphere/6.0/com.vmware.vsphere.networking.doc/GUID-DA8506CE-7813-4B4C-BE14-9B42C36637BA.html">https://docs.vmware.com/en/VMware-vSphere/6.0/com.vmware.vsphere.networking.doc/GUID-DA8506CE-7813-4B4C-BE14-9B42C36637BA.html</a></p><h3 id="场景7：2488H-V5主机无响应问题"><a href="#场景7：2488H-V5主机无响应问题" class="headerlink" title="场景7：2488H V5主机无响应问题"></a>场景7：2488H V5主机无响应问题</h3><p><strong>问题现象描述</strong></p><p>硬件配置：2488H V5</p><p>问题现象：主机之前发生过紫屏重启，本次又无响应，客户怀疑硬件有故障，要求分析原因</p><p><strong>关键过程、根本原因分析</strong></p><p>分析过程</p><p>一、硬件分析：检查硬件日志，未发现有硬件异常的记录</p><p>二、现象：此前问题触发VMware宕机紫屏。本次问题不同，主机无响应，无紫屏</p><p>OS日志分析——</p><p>局点设备产品名和序列号：</p><p>Manufacturer: “Huawei”</p><p>Product: “2488H V5”</p><p>Version: “Purley”</p><p>Serial: “***”</p><p>主机名：***</p><p>操作系统版本号：</p><p>VMware ESXi 6.7.0 build-13981272</p><p>VMware ESXi 6.7.0 Update 2</p><p>Vmkernel日志：</p><p>2019-11-20T01:02:56.576Z cpu78:2637720)MemSchedAdmit: 471: Admission failure in path: sioc/storageRM.2637720/uw.2637720</p><p>2019-11-20T01:02:56.576Z cpu78:2637720)MemSchedAdmit: 478: UserWorld ‘storageRM’ with cmdline ‘/sbin/storageRM’</p><p>2019-11-20T01:02:56.576Z cpu78:2637720)MemSchedAdmit: 489: uw.2637720 (3073507) extraMin/extraFromParent: 256/256, sioc (802) childEmin/eMinLimit: 14328/14336</p><p>相关VMware KB：<a href="https://kb.vmware.com/s/article/67543">https://kb.vmware.com/s/article/67543</a></p><img src="/posts/31022/zh-cn_image_0262031950.jpg" class=""><p>结论：硬件无异常。主机无响应原因是Storage I/O Control存在异常导致，解决方案是升级到VM6.7 U3</p><p>客户联系VMware，VMware确认该问题并提供解决措施：升级版本或禁用SIOC（Storage I/O Control）</p><p>客户选择升级版本后解决。</p><p><strong>根本原因分析</strong>：</p><p>VMware 自身问题导致，按KB升级版本到VM6.7 U3</p><p><strong>结论、解决方案及效果</strong></p><p>结论：硬件无异常。VMware 自身问题导致</p><p>解决方案：按KB升级到VM6.7 U3或禁用SIOC</p>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VMware系统紫屏问题定位思路</title>
      <link href="/posts/22695/"/>
      <url>/posts/22695/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="VMware系统紫屏问题定位思路"><a href="#VMware系统紫屏问题定位思路" class="headerlink" title="VMware系统紫屏问题定位思路"></a>VMware系统紫屏问题定位思路</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>Vmware EXSi主机在运行过程遇到严重错误时，会出现紫屏（类似windows系统的蓝屏），然后系统挂死。本文讲解如果定位VMware系统的紫屏问题。</p><h2 id="紫屏解析"><a href="#紫屏解析" class="headerlink" title="紫屏解析"></a>紫屏解析</h2><p>出现紫屏以后，根据紫屏的提示信息，可以完成问题的初步定位。从VMware 紫屏可以获取以下下的信息。</p><h3 id="产品和内部版本"><a href="#产品和内部版本" class="headerlink" title="产品和内部版本"></a>产品和内部版本</h3><img src="/posts/22695/zh-cn_image_0258619345.png" class=""><p>紫色诊断屏幕中的此部分表示出错的产品和内部版本。在本示例中，产品是esxi 6.0 build号是3247720。</p><h3 id="错误消息"><a href="#错误消息" class="headerlink" title="错误消息"></a>错误消息</h3><img src="/posts/22695/zh-cn_image_0258619346.png" class=""><p>紫色诊断屏幕的此部分表示报告的错误消息。指示出是什么错误导致的VMware系统紫屏，本示例中是mce问题导致的VMware系统紫屏，这个信息对定位问题非常重要。本文后面会针对常见的错误类型分别讲解。</p><h3 id="CPU寄存器"><a href="#CPU寄存器" class="headerlink" title="CPU寄存器"></a>CPU寄存器</h3><img src="/posts/22695/zh-cn_image_0258619381.png" class=""><p>出错时，这些值存储在物理CPU寄存器中。这些寄存器中的信息千差万别，具体取决于出现的VMkernel错误。这些寄存器只能用于内部调试VMkernel错误的核心转储。</p><h3 id="物理CPU"><a href="#物理CPU" class="headerlink" title="物理CPU"></a>物理CPU</h3><img src="/posts/22695/zh-cn_image_0258619353.png" class=""><p>紫色诊断屏幕的此部分表示VMkernel出错期间运行指令的物理CPU。</p><h3 id="堆栈跟踪"><a href="#堆栈跟踪" class="headerlink" title="堆栈跟踪"></a>堆栈跟踪</h3><img src="/posts/22695/zh-cn_image_0258619485.png" class=""><p>堆栈表示出错时VMkernel正在执行的操作。此信息是一个重要工具，有助于通过评估出错时内核所执行的操作来诊断紫色屏幕错误。</p><h3 id="主机运行时长"><a href="#主机运行时长" class="headerlink" title="主机运行时长"></a>主机运行时长</h3><img src="/posts/22695/zh-cn_image_0258619503.png" class=""><p>VMK uptime表示自上次启动以来服务器运行的时间。在本示例中，Esxi主机已运行了1天14时6分26秒。</p><h3 id="核心转储"><a href="#核心转储" class="headerlink" title="核心转储"></a>核心转储</h3><img src="/posts/22695/zh-cn_image_0258619927.png" class=""><p>紫色诊断屏幕的此部分表示正复制到vmkcore分区的VMkernel内存内容。</p><h2 id="常见紫屏问题分析"><a href="#常见紫屏问题分析" class="headerlink" title="常见紫屏问题分析"></a>常见紫屏问题分析</h2><p>常见的导致VMware紫屏的错误有NMI、MCE、no heartbeat、failed to ack TLB invalidate、GP Exception(13)、PF Exception type 14等。下面一次介绍这几种常见的紫屏问题产生的原因。</p><h3 id="NMI"><a href="#NMI" class="headerlink" title="NMI"></a>NMI</h3><img src="/posts/22695/zh-cn_image_0258620622.png" class=""><h4 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h4><p>服务器从V2 开始增加了故障诊断功能（fdm）。故障诊断功能使能以后，CPU检测到IIO（包括：PCI Express interfaces, DMI2 interface, IIO core logic, and Intel® VT-d）错误以后，先产生SMI中断跳转到BIOS的故障处理流程中。BIOS的故障处理流程负责记录这个Aer错误，当BIOS检测到不可恢复的Aer错误时，会产生NMI中断给OS。Vmware系统检测到这个NMI中断以后就会出现紫屏挂死，紫屏显示的错误类型为 “LINT1/NMI…” 。</p><p>下图IIO Modules的错误处理流程如下图所示，仅供参考。</p><img src="/posts/22695/zh-cn_image_0258621254.png" class=""><h4 id="定位思路"><a href="#定位思路" class="headerlink" title="定位思路"></a>定位思路</h4><p>对于NMI导致的紫屏问题，绝大多数为PCIe设备问题导致的。出现这类问题时，优先查看fdm log中挂死时刻的错误日志，找到对应PCIe设备进行定位。</p><h4 id="解决措施"><a href="#解决措施" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：3108-RAID卡FW-amp-驱动问题导致VMware紫屏"><a href="#场景1：3108-RAID卡FW-amp-驱动问题导致VMware紫屏" class="headerlink" title="场景1：3108 RAID卡FW&amp;驱动问题导致VMware紫屏"></a>场景1：3108 RAID卡FW&amp;驱动问题导致VMware紫屏</h5><p><strong>硬件配置：</strong>RH5885 V3服务器，配置3108 RAID卡。</p><p><strong>OS****：</strong>VMware 6.0</p><p><strong>问题现象：</strong></p><ol><li><p>操作系统宕机，VMware紫屏，紫屏信息如图1所示。</p><p><strong>图1</strong> VMware紫屏信息</p><img src="/posts/22695/zh-cn_image_0261130308.jpg" class=""></li><li><p>BMC日志中有RAID卡异常打印，如图2所示。</p><p><strong>图2</strong> BMC日志</p> <img src="/posts/22695/zh-cn_image_0261130302.png" class=""></li><li><p>现场更换RAID卡，告警依旧。</p></li><li><p>现场升级RAID卡FW和VMware驱动后，问题解决。</p></li></ol><p><strong>关键过程、根本原因分析</strong></p><p>故障根因：OS中自带驱动版本和3108 RAID卡FW不配套，需要执行华为网站上的驱动包并按照驱动包脚本提示进行FW配套升级。详细升级方案在解决方案中给出。</p><p><strong>结论、解决方案及效果</strong></p><p>升级前请先下载软件：</p><p>驱动下载链接：<a href="https://support.huawei.com/enterprise/zh/computing/fusionserver-idriver-pid-21588909/software">https://support.huawei.com/enterprise/zh/computing/fusionserver-idriver-pid-21588909/software</a></p><p><strong>FW****升级指导</strong></p><ol><li><p>将下载的FW镜像挂在到KVM虚拟光驱界面，服务器上电。</p><img src="/posts/22695/zh-cn_image_0261130328.png" class=""></li><li><p>按F11进入启动项，选择从虚拟光驱启动。</p><img src="/posts/22695/zh-cn_image_0261130325.png" class=""></li><li><p>选择Toolkit-V101。</p><img src="/posts/22695/zh-cn_image_0261130310.png" class=""></li><li><p>按C进入命令行模式。</p><img src="/posts/22695/zh-cn_image_0261130327.png" class=""></li><li><p>输入用户名密码。用户名为<strong>root</strong>，默认密码为**Huawei12#$**。</p><img src="/posts/22695/zh-cn_image_0261130312.png" class=""></li><li><p>执行指令**cd /home/Project/FTK/upgrade/raid/tool/**进入文件夹。执行指令 ****./FwUpgrade.py FwUpgrade.XML****，回车确定后开始升级。升级完成后，重启服务器生效。</p><img src="/posts/22695/zh-cn_image_0261130334.png" class=""></li><li><p>查看3108 RAID的FW版本，最新版本是4.270.00.4382。</p><img src="/posts/22695/zh-cn_image_0261130314.png" class=""><p><em>*<em>*</em>*驱动升级指导****</em>*</p></li><li><p>将VMware系统对应的文件通过SSH等工具上传到操作系统tmp文件夹下。</p><img src="/posts/22695/zh-cn_image_0261130313.png" class=""></li><li><p>执行指令<strong>cd tmp/vmware5.5</strong>进入tmp文件夹。</p></li><li><p>执行指令<strong><em>*</em>*sh install_driver.sh**。*</strong>*</p></li><li><p>选择1，进行全部升级。</p></li><li><p>升级驱动版本至6.606.06.00。升级完成后，重启操作系统生效。</p></li></ol><img src="/posts/22695/zh-cn_image_0261130339.jpg" class=""><h5 id="场景2：LSI3108-5288-V3配置3108安装VMware运行中紫屏案例"><a href="#场景2：LSI3108-5288-V3配置3108安装VMware运行中紫屏案例" class="headerlink" title="场景2：LSI3108-5288 V3配置3108安装VMware运行中紫屏案例"></a>场景2：LSI3108-5288 V3配置3108安装VMware运行中紫屏案例</h5><p><strong>问题现象描述</strong></p><p>硬件配置：RH5288 V3服务器，配置3108扣卡和3108标卡，并配有超级电容模块；</p><p>软件配置：安装VMware操作系统</p><p>故障现象：运行过程中出现VMware紫屏</p><img src="/posts/22695/zh-cn_image_0261128938.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p><strong>查看<strong><strong>RAID</strong></strong>卡日志</strong>：</p><p>系统日志中/raid目录下的sasraidlog.txt，显示No Controller found。</p><p>有可能是驱动没有安装，或者是RAID卡硬件没有运行。</p><p><strong>查看系统****dmesg</strong>：</p><p>系统日志中/system目录下的dmesg，全局搜索关键字mega，没有搜索到。</p><p>确认驱动没有安装。</p><p><strong>查看<strong><strong>lspci</strong></strong>记录</strong>：</p><p>系统日志/mainboard目录下的lspci，全局搜索3108, LSI等关键字，没有搜到。</p><p>说明3108扣卡和标卡硬件（PCIe底层）都没有运行。</p><p><strong>确认已连接的****RAID卡</strong> ：</p><p>在BMC dump_info中，在/AppDump/card_manage/card_info文件中，看到确实安装了3108标卡和扣卡。</p><img src="/posts/22695/zh-cn_image_0261128939.png" class=""><img src="/posts/22695/zh-cn_image_0261128874.png" class=""><p>说明3108标卡和扣卡硬件确实在位。</p><p>以上分析表明，3108扣卡和标卡的底层硬件逻辑（如PCIe）都没有运行。</p><p>两个卡都坏掉的可能性不大，这时建议优先从主板分析，排查硬件原因。</p><p><strong>结论：</strong></p><p>由各种日志综合分析，3108扣卡和标卡都没有运行，优先从主板开始分析，排查硬件故障原因。</p><p><strong>解决方案：</strong></p><p>排查硬件故障原因后，更换故障件。</p><h5 id="场景3：RH2288-V5配合VMware-6-0，在长期业务压力下导致紫屏"><a href="#场景3：RH2288-V5配合VMware-6-0，在长期业务压力下导致紫屏" class="headerlink" title="场景3：RH2288 V5配合VMware 6.0，在长期业务压力下导致紫屏"></a>场景3：RH2288 V5配合VMware 6.0，在长期业务压力下导致紫屏</h5><p><strong>问题现象描述</strong></p><p>2288H V5在环境上装VMware6.0，在vm下装有red7.3（数据库服务器）和suse12.2（文件服务器），这两台虚拟机是装在连接的外部的磁阵上。通过外部设备，向搭建的数据库和文件服务器长期打进业务流（TCP/IP/HTTP），发现业务持续一周之后，VMware6.0出现紫屏现象，并自己复位，bmc有CPU1和fc卡error的相关信息。</p><ol><li>2288H V5安装VMware6.0，配置相关以太、QL2672 FC标卡。</li><li>通过外接的磁阵，安装suse12.2（文件服务器）虚拟机、Redhat7.3（数据库服务器）虚拟机。</li><li>外部工具持续向虚拟机打流。</li><li>业务持续一周，发现host上VMware6.0紫屏，业务中断。</li></ol><img src="/posts/22695/zh-cn_image_0261129584.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p>出问题的环境QL2672 FC卡的FW版本是8.01.02，而驱动版本是qlnativefc 2.1.63.0-1OEM，但是VMware官网上版本配套关系是qlnativefc 2.1.63.0-1OEM要配套8.07.xx的版本，环境升级FW版本到8.07.xx后问题不再出现。</p><p><strong>结论、解决方案及效果</strong></p><p>Vmware环境下部件FW&amp;驱动要和官网发布的关系配套。</p><h3 id="MCE"><a href="#MCE" class="headerlink" title="MCE"></a>MCE</h3><img src="/posts/22695/zh-cn_image_0258621493.png" class=""><h4 id="原因分析-1"><a href="#原因分析-1" class="headerlink" title="原因分析"></a>原因分析</h4><p>Mce 问题大家肯定都很熟悉，绝大多数的mce 问题都是硬件错误导致的。</p><h4 id="定位思路-1"><a href="#定位思路-1" class="headerlink" title="定位思路"></a>定位思路</h4><p>对于mce 问题触发的紫屏，紫屏信息上会提示出故障的 bank，bank 的status 状态寄存器（IA32_MCi_STATUS），MISC 寄存器（IA32_MCi_MISC），ADDR 寄存器（IA32_MCi_ADDR）。</p><p>示例中的故障：</p><p>B:19 ，表示故障bank为19</p><p>S：0xfe200000003110a ，表示 IA32_MC19_STATUS 为0xfe200000003110a</p><p>M：0x4f008b888c01086，表示 IA32_MC19_MISC 寄存器为0x4f008b888c01086</p><p>A：0x3551615440 ，表示 IA32_MC19_ADDR 寄存器为0x3551615440</p><p>在fdm 使能的情况，出现mce 导致紫屏时，fdm log 也会记录到相同的错误。如果紫屏的信息不完整时，可以结合fdm log 中故障时间端的日志记录进行定位。</p><h4 id="解决措施-1"><a href="#解决措施-1" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：RH5885-V3服务器内存故障导致Vmware紫屏"><a href="#场景1：RH5885-V3服务器内存故障导致Vmware紫屏" class="headerlink" title="场景1：RH5885 V3服务器内存故障导致Vmware紫屏"></a>场景1：RH5885 V3服务器内存故障导致Vmware紫屏</h5><p><strong>问题现象描述</strong></p><p>硬件配置：RH5885 V3服务器： E7-4850 v4*4+3108RAID卡</p><p>问题现象：客户反馈服务器运行过程中紫屏</p><img src="/posts/22695/zh-cn_image_0261656414.png" class=""><p><strong>关键过程、根本原因分析</strong></p><p>关键过程：</p><p>1.curren日志中记录内存DIMM001 UCE错误，同时记录系统致命错误。</p><img src="/posts/22695/zh-cn_image_0261656413.png" class=""><p>2.fdm_log多次记录内存DIMM001 UCE错误。</p><img src="/posts/22695/zh-cn_image_0261656415.png" class=""><p>3.fdm_output中先打印内存DIMM001 CE风暴，3秒后打印内存 DIMM001 UCE。</p><img src="/posts/22695/zh-cn_image_0261656416.png" class=""><p><strong>根本原因分析：</strong></p><p>内存DIMM001故障导致wmware系统紫屏。</p><p><strong>结论、解决方案及效果</strong></p><p>结论：内存DIMM001故障导致wmware系统紫屏。</p><p>解决方案：更换内存DIMM001。</p><h5 id="场景2：地址空间属性问题导致紫屏案例"><a href="#场景2：地址空间属性问题导致紫屏案例" class="headerlink" title="场景2：地址空间属性问题导致紫屏案例"></a>场景2：地址空间属性问题导致紫屏案例</h5><p><strong>问题现象描述</strong></p><p><strong>图****1</strong> 2015年12月19日至2016年2月4日，客户现场陆续出现5台RH2288H V3 VMware紫屏，系统重启后恢复</p><img src="/posts/22695/zh-cn_image_0261656932.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p>对于2015-12-19的VMware紫屏，我们可以确认紫屏报错类别是MCE（Machine Check Exception），紫屏时间点是2015-12-19 03:04:42（VMware时间），报错地址是0x35516154440。</p><img src="/posts/22695/zh-cn_image_0261656947.jpg" class=""><p>对于2015-12-19的VMware紫屏，分析iBMC fdm log，问题发生时间点是2015-12-19 03:04:42（iBMC时间），MCE错误类型是SAD_ERR_WB_TO_MMIO错误，报错地址是0x35516154440 (FAILED TO LOCATE ADDRESS)，说明该地址是无效地址。RH2288H V3服务器所用的Intel Grantley平台配置能用的最高地址为2T+256G，0x35516154440地址属于无效地址范围。由于硬件故障仅限于有效地址的报错，无效地址报错说明不是硬件故障，而是软件错误地访问无效地址导致问题。</p><img src="/posts/22695/zh-cn_image_0261656948.jpg" class=""><p><strong>结论、解决方案及效果</strong></p><p><strong>结论：</strong>该问题原因已确认是上层软件错误地访问无效地址。</p><p><strong>解决方案：</strong></p><ol><li>配合客户查明导致该问题的异常软件。</li><li>将无效地址默认属性设置为UC（使用BIOS V157版本），使上层软件无法错误地访问无效地址而避免触发MCE紫屏。</li><li>升级到兼容性列表中要求的驱动。</li></ol><h5 id="场景3：VMware紫屏问题案例"><a href="#场景3：VMware紫屏问题案例" class="headerlink" title="场景3：VMware紫屏问题案例"></a>场景3：VMware紫屏问题案例</h5><p><strong>现象、问题描述</strong></p><p>客户反馈一台RH5885H V3设备上部署VMware操作系统，物理机5月21日发生紫屏，需分析是否有硬件异常。</p><p><strong>关键过程、根本原因分析</strong></p><p>1.紫屏信息分析：</p><p>根据客户反馈的紫屏截图可以看到本次紫屏是由于MCE（Machine Check Exception）导致，设备检测到了PCPU72上有不可纠正的错误发生。其次从截图中我们可以看到本次系统启动后运行时间为427天，发生紫屏的时间为2018年5月21日9:14:41。如下图1所示。</p><p><strong>图****1</strong> 紫屏信息</p><img src="/posts/22695/zh-cn_image_0261657360.png" class=""><p>2.Vmksummary日志分析：</p><p>Vmksummary日志中每隔一小时会记录一次心跳，从该日志中可以看到系统在2018-05-21T09:59:57重启，如下图2所示。</p><p><strong>图****2</strong> Vmksummary日志信息</p><img src="/posts/22695/zh-cn_image_0261657379.jpg" class=""><p>3.SEL日志分析：</p><p>根据紫屏出现时间和设备重启时间来查询对应时间段内服务器BMC SEL事件记录信息，仅看到有重启前的电源线插拔lost的告警，无其他任何信息，如下图3所示。</p><p><strong>图****3</strong> SEL日志信息</p><img src="/posts/22695/zh-cn_image_0261657359.jpg" class=""><p>4.FDM日志分析：</p><p>根据紫屏出现时间和设备重启时间来查询对应时间段内服务器FDM日志，发现2018-05-21 09:14:41有打印逻辑CPU2（物理CPU3）不可纠正错误，如下图4所示。</p><p><strong>图****4</strong> FDM日志信息</p><img src="/posts/22695/zh-cn_image_0261657380.png" class=""><p>进一步确认vmkernel下查询CPU与PCPU对应关系，可看到PCPU72归属于逻辑CPU2（物理CPU3），如下图5所示。</p><p><strong>图****5</strong> CPU与PCPU对应关系</p><img src="/posts/22695/zh-cn_image_0261657381.png" class=""><p><strong>结论、解决方案及效果</strong></p><p>通过以上分析可知本次紫屏是由于逻辑CPU2（物理CPU3）发生不可纠正错误导致。更换CPU后恢复。</p><h3 id="Failed-to-ack-TLB-invalidate"><a href="#Failed-to-ack-TLB-invalidate" class="headerlink" title="Failed to ack TLB invalidate"></a>Failed to ack TLB invalidate</h3><img src="/posts/22695/zh-cn_image_0258622057.png" class=""><h4 id="原因分析-2"><a href="#原因分析-2" class="headerlink" title="原因分析"></a>原因分析</h4><p>什么是“TLB invalidate”？</p><p>我们都知道，操作系统用的虚拟地址。虚拟地址和物理地址进行转换要用到page table，但是每次内存访问的时候都遍历一遍page table，会很耗时间。为了加速page table转换，intel 设计了TLB，有了TLB 以后，CPU访问内存时，会先查找TLB buffer ，如果能查到，可以直接完成page table的转换，不需要去遍历page table 。当内核进行进程切换时，由于要装载新的page table，所以要把之前的TLB buffer invalidate。</p><p>TLB buffer invalidate 的过程是这样，发生进程切换的CPU把自己TLB buffer invalidate ,然后通过ipi 中断通知其他CPU也要进行TLB buffer invalidate 。CPU发送ipi 中断给其他CPU以后，会循环等待其他的CPU回复它已经完成TLB buffer invalidate。如果在等待的时间阈值内有一颗或多颗CPU未回应，EXSi 就会提示 “Failed to ack TLB invalidate”出现紫屏。</p><h4 id="定位思路-2"><a href="#定位思路-2" class="headerlink" title="定位思路"></a>定位思路</h4><p>导致Failed to ack TLB invalidate 原因可能是VMware 系统的问题，也可能是硬件的问题。</p><p>之前5885HV3上曾出现过BIOS下mwait 默认使能，CPU进入C state 以后无法唤醒是Intel CPU的一个bug ，最新的BIOS都已经合入微码解决这个问题。</p><p>一般遇到Failed to ack TLB invalidate”问题时，优先检查BIOS的C state ，mwait 等菜单是否已经禁用，如果禁用以后还有问题，收集vm-support 日志提case 给VMware 进行深入定位分析。</p><h4 id="解决措施-2"><a href="#解决措施-2" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：Mwait故障导致VMware系统紫屏问题"><a href="#场景1：Mwait故障导致VMware系统紫屏问题" class="headerlink" title="场景1：Mwait故障导致VMware系统紫屏问题"></a>场景1：Mwait故障导致VMware系统紫屏问题</h5><p><strong>问题现象描述</strong></p><p>Vmware系统运行过程中出现紫屏。紫屏信息显示 “Failed to ack TLB invalidate”</p><img src="/posts/22695/zh-cn_image_0261724540.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p>通过VMware 分析系统日志，发现紫屏时 故障CPU处于C state ，进一步排查BIOS设置，发现BIOS下 Monitor/Mwait 设置为 “Enable”。 Monitor/Mwait enable 时，CPU会进入C state 导致系统问题。</p><img src="/posts/22695/zh-cn_image_0261724521.png" class=""><p><strong>结论、解决方案及效果</strong></p><p><strong>结论：</strong></p><p>Monitor/Mwait enable 时，CPU进入C state ，无法响应TLB invalidate ，导致VMware系统出现紫屏 。</p><p><strong>解决方案：</strong></p><p>升级到最新 BIOS版本，已默认把Monitor/Mwait设置为Disable 。</p><h5 id="场景2：【RH5885-V3】【VMware-6-0】Intel-Haswell-CPU平台（微码编号为erratum-HSX54，Mwait功能）缺陷导致ESXi6-0紫屏，BMC日志打印CatError告警，FDM日志打印MCA错误"><a href="#场景2：【RH5885-V3】【VMware-6-0】Intel-Haswell-CPU平台（微码编号为erratum-HSX54，Mwait功能）缺陷导致ESXi6-0紫屏，BMC日志打印CatError告警，FDM日志打印MCA错误" class="headerlink" title="场景2：【RH5885 V3】【VMware 6.0】Intel Haswell CPU平台（微码编号为erratum HSX54，Mwait功能）缺陷导致ESXi6.0紫屏，BMC日志打印CatError告警，FDM日志打印MCA错误"></a>场景2：【RH5885 V3】【VMware 6.0】Intel Haswell CPU平台（微码编号为erratum HSX54，Mwait功能）缺陷导致ESXi6.0紫屏，BMC日志打印CatError告警，FDM日志打印MCA错误</h5><p><strong>问题现象描述</strong></p><p>硬件配置：RH5885 V3服务器，配置Emulex OCe11102 CNA卡。</p><p>软件配置：VMware6.0</p><p>问题现象：操作系统宕机，VMware紫屏，紫屏信息如下：</p><img src="/posts/22695/zh-cn_image_0261724868.png" class=""><p>BMC日志中有CatError告警，FDM日志中CPU1和CPU2均发生了不可修复的MCA错误：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CPU:0 (socket:CPU1)    core:0    LogType:MCA BANK4  (PCU)    MCA mode:Corrupt Data Containment</span><br><span class="line">Error type:Uncorrected Errors-Catastrophic1/Fatal    MCACODE:0x0402 (Any logged Error for the PCU) </span><br><span class="line">CPU:1 (socket:CPU2)    core:0    LogType:MCA BANK4  (PCU)    MCA mode:Corrupt Data Containment</span><br><span class="line">Error type:Uncorrected Errors-Catastrophic1/Fatal    MCACODE:0x0400 (Internal Timer Error)</span><br></pre></td></tr></table></figure><p><strong>关键过程、根本原因分析</strong></p><p>紫屏显示TLB虚拟内存快速映射模块在调用TLB invalidate功能相关函数时刷新TLB时发生CPU死锁，与BMC日志相符，当时初步判断为CPU硬件故障。但是之后去现场更换硬件以及升级V628版本的BIOS之后问题仍然出现，之后推动VMware L3服务人员和美国研发人员继续分析之后，定位出紫屏问题是Intel最新Haswell CPU平台微码的编号为erratum HSX54的缺陷引起的，属于Intel平台节能功能与VMware的兼容性问题，并且是概率性触发。而V628版本只是关闭了mwait功能(合入的补丁为patch 0x7版本)，并未合入修改该缺陷的patch 0x9 补丁，V630版本将会合入修正所有已知缺陷的patch 0x9补丁，并且为了保险起见，默认关闭了mwait功能。</p><p><strong>解决方案</strong></p><p>Haswell-EX CPU机型升级BIOS到V630版本。</p><p><strong>备注</strong></p><p>Monitor/Mwait指令介绍：</p><p>当在一个多处理器系统中的一个逻辑处理器（包括多核处理器或支持Intel超线程技术的处理器）处于空闲（没有工作可做）或阻塞（等待一个锁或信号量）时，核心执行引擎资源的额外的管理可以通过使用HLT（中止）、PAUSE或MONITOR/MWAIT指令来完成。</p><p>MONITOR指令定义一些特定的要被等待的回写地址区域，MWAIT指令用于配合MONITOR指令使用，它指定一个软件线程去等待对MONITOR指令定义的地址做出回写动作(a write-back store)。</p><p>除了MONITOR定义的区域的数据被写这个条件之外，以下条件也能触发MWAIT唤醒：</p><ul><li>External interrupts: NMI, SML, INIT, BINIT, MCERR</li><li>Faults, Aborts including Machine Check</li><li>Architectural TLB invalidations, including writes to CR0, CR3, CR4 and certain MSR writes</li><li>Voluntary transitions due to fast system call and far calls</li></ul><p>Intel官网对Monitor/Mwait功能的介绍。</p><p><a href="https://software.intel.com/en-us/articles/how-to-use-the-monitor-and-mwait-streaming-simd-extensions-3-instructions">https://software.intel.com/en-us/articles/how-to-use-the-monitor-and-mwait-streaming-simd-extensions-3-instructions</a></p><h3 id="No-heartbeat"><a href="#No-heartbeat" class="headerlink" title="No heartbeat"></a>No heartbeat</h3><img src="/posts/22695/zh-cn_image_0258622063.png" class=""><h4 id="原因分析-3"><a href="#原因分析-3" class="headerlink" title="原因分析"></a>原因分析</h4><p>ESX VMkernel和服务控制台 Linux内核同时在 ESX 上运行。服务控制台 Linux内核会定时向VMkernel发送心跳信号。如果一定时间内未收到心跳信号，VMkernel 会触发紫屏。</p><h4 id="定位思路-3"><a href="#定位思路-3" class="headerlink" title="定位思路"></a>定位思路</h4><p>导致No heartbeat的原因肯能是软件问题，也可能是硬件问题。我们曾遇到过，内存可纠正错误ECC过多，导致VMware系统紫屏。紫屏的原因就是内存ECC错误一直产生CMCI中断给VMware系统，VMware系统无法响应心跳检查，导致系统挂死。详解VMware kb：</p><p><a href="http://kb.vmware.com/kb/2140848">http://kb.vmware.com/kb/2140848</a></p><h4 id="解决措施-3"><a href="#解决措施-3" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：VMware-6-5跑虚拟机NVME硬盘压力出现紫屏问题"><a href="#场景1：VMware-6-5跑虚拟机NVME硬盘压力出现紫屏问题" class="headerlink" title="场景1：VMware 6.5跑虚拟机NVME硬盘压力出现紫屏问题"></a>场景1：VMware 6.5跑虚拟机NVME硬盘压力出现紫屏问题</h5><p><strong>现象、问题描述</strong></p><p>Vmware 6.5系统运行NVMe硬盘压力过程中出现紫屏。紫屏信息显示 “no heartbeat”。</p><img src="/posts/22695/zh-cn_image_0261729306.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p>Vmware 6.5系统bug</p><p><a href="https://kb.vmware.com/s/article/2151597#q=2151597">https://kb.vmware.com/s/article/2151597#q=2151597</a></p><img src="/posts/22695/zh-cn_image_0261729307.jpg" class=""><p><strong>结论、解决方案及效果</strong></p><p><strong>结论：</strong></p><p>Vmware 6.5系统bug导致紫屏。</p><p><strong>解决方案：</strong></p><p>升级系统版本到6.5U1版本。</p><h5 id="场景2：Esxi-6-0U2-lsi-mr3驱动导致紫屏"><a href="#场景2：Esxi-6-0U2-lsi-mr3驱动导致紫屏" class="headerlink" title="场景2：Esxi_6.0U2_lsi_mr3驱动导致紫屏"></a>场景2：Esxi_6.0U2_lsi_mr3驱动导致紫屏</h5><p><strong>问题现象描述</strong></p><p>RH5885H V3服务器配置LSI 3108卡，运行Esxi 6.0U2过程中出现紫屏（如图1所示），RAID卡驱动使用OS自带的lsi_mr3，非华为发布的megaraid_sas。</p><p><strong>图****1</strong> Esxi紫屏</p><img src="/posts/22695/zh-cn_image_0261735763.png" class=""><p><strong>图****2</strong> lsi_mr3驱动信息</p><img src="/posts/22695/zh-cn_image_0261735713.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p><strong>根本原因分析：</strong></p><p>Esxi自带的lsi_mr3驱动程序从低内存区域初始引导期间不会保留所需的完整内存，导致RAID卡运行过程中出现异常。</p><p><strong>图****3</strong> VMWare分析结果</p><img src="/posts/22695/zh-cn_image_0261735762.jpg" class=""><p><strong>结论、解决方案及效果</strong></p><p><strong>结论：</strong></p><p>Esxi自带的lsi_mr3驱动程序从低内存区域初始引导期间不会保留所需的完整内存，导致RAID卡运行过程中出现异常。</p><p><strong>解决方案：</strong></p><p>参考VMWare分析结果，该问题有两种方案，选择其一解决即可。</p><p>1、升级主机OS版本至ESXi 6.0 P04。</p><p>2、如果主机OS版本无法升级，可以安装传统驱动程序（如megaraid sas）而不使用本地驱动程序（如lsi_mr3）。建议使用华为发布的megaraid_sas驱动。</p><h5 id="场景3：RH2288-V3服务器VMware系统紫屏问题"><a href="#场景3：RH2288-V3服务器VMware系统紫屏问题" class="headerlink" title="场景3：RH2288 V3服务器VMware系统紫屏问题"></a>场景3：RH2288 V3服务器VMware系统紫屏问题</h5><p><strong>问题现象描述</strong></p><p>硬件配置：RH2288 V3，CPU型号Xeon E5-2640 V3</p><p>问题现象：VMware系统频繁重启，没有硬件告警，紫屏</p><p><strong>关键过程、根本原因分析</strong></p><p>关键过程：</p><ol><li>BMC版本2.41，BIOS版本3.57</li></ol><img src="/posts/22695/zh-cn_image_0261735888.jpg" class=""><ol start="2"><li>sel日志看到12月30日9:47分带内业务侧power off，没有硬件告警，前后几次上下电是人为操作按下power button的打印</li></ol><img src="/posts/22695/zh-cn_image_0261735889.jpg" class=""><ol start="3"><li>operate日志看到09:47的下电前无人为操作按power button的记录，判断为系统侧异常下电</li></ol><img src="/posts/22695/zh-cn_image_0261735823.jpg" class=""><ol start="4"><li>fdm日志没有有效信息，仅几次2019年1月9日的内存CE告警，指向DIMM001</li></ol><img src="/posts/22695/zh-cn_image_0261735890.png" class=""><ol start="5"><li>vmsummary日志看到有core dump文件生成</li></ol><img src="/posts/22695/zh-cn_image_0261735824.jpg" class=""><ol start="6"><li>vmwarning日志中有PCPU 21无心跳响应8秒，可能locked up的打印，且有NMI IPI received打印</li></ol><img src="/posts/22695/zh-cn_image_0261735905.jpg" class=""><ol start="7"><li>紫屏打印是no heartbeat，时间去年12月30日8:50，OS比BMC时间多8小时，即硬件时间2019-12-30 0:50</li></ol><img src="/posts/22695/zh-cn_image_0261735906.jpg" class=""><img src="/posts/22695/zh-cn_image_0261735907.jpg" class=""><p><strong>根本原因分析：</strong></p><p>PCPU 21无心跳响应8秒，可能locked up的打印，且有NMI IPI received打印，导致系统紫屏。</p><p>结论：</p><p>PCPU 21逻辑核所在物理CPU2故障。</p><p>解决方案：</p><p>更换CPU2。</p><h5 id="场景4：MZ510-FC驱动和FW不匹配导致VMware紫屏"><a href="#场景4：MZ510-FC驱动和FW不匹配导致VMware紫屏" class="headerlink" title="场景4：MZ510 FC驱动和FW不匹配导致VMware紫屏"></a>场景4：MZ510 FC驱动和FW不匹配导致VMware紫屏</h5><p><strong>问题现象描述</strong></p><p><strong>硬件配置：</strong></p><p>2x E5-2603 CPU，16x8G，LSI2308 RAID卡、MZ510扣卡。</p><p><strong>软件配置：</strong></p><p>MZ510扣卡驱动: 8.2.3.1-127vmw；FW: 4.4.262.3 OS:VMware5.1</p><p><strong>问题描述：</strong></p><p>客户在CH121服务器上安装VMware5.1系统后，概率性出现紫屏。如图1所示。</p><p><strong>图****1</strong> VMware系统紫屏</p><img src="/posts/22695/zh-cn_image_0261736931.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p><strong>定位步骤如下：</strong></p><ol><li>分析VMware日志，确认是MZ510扣卡FC驱动和FW不匹配导致紫屏。如图2所示。</li></ol><p><strong>图****2</strong> VMware日志分析</p><img src="/posts/22695/zh-cn_image_0261736932.jpg" class=""><p>请参考此KB：<a href="http://kb.vmware.com/kb/2052729%E3%80%82">http://kb.vmware.com/kb/2052729。</a></p><p><strong>根本原因分析**</strong>:**</p><p>现场使用的MZ510扣卡FC驱动和FW不匹配会概率性出现紫屏，且不是经过华为兼容性测试的配套版本。</p><p><strong>结论、解决方案**</strong>:**</p><p>结论：</p><p>MZ510扣卡FC驱动和FW不匹配</p><p>解决方案：</p><p>参考E9000服务器驱动版本配套表，升级MZ510扣卡FC的驱动版本8.2.4.151.65，FW：4.6.320.3。</p><h3 id="PF-Exception-14-amp-GP-Exception-13"><a href="#PF-Exception-14-amp-GP-Exception-13" class="headerlink" title="PF Exception 14 &amp; GP Exception 13"></a>PF Exception 14 &amp; GP Exception 13</h3><img src="/posts/22695/zh-cn_image_0258622940.png" class=""><h4 id="原因分析-4"><a href="#原因分析-4" class="headerlink" title="原因分析"></a>原因分析</h4><p>PF Exception 14 ，产生的原因：</p><ul><li>正在请求的页面未成功加载到内存时出现页面错</li></ul><p>GP Exception 13，在以下任一情况下都会出现一般保护错误。</p><ul><li>正在请求的页面不属于请求该页的程序（未映射到程序内存中）</li><li>程序无权在页面上执行读取或写入操作。</li></ul><h4 id="定位思路-4"><a href="#定位思路-4" class="headerlink" title="定位思路"></a>定位思路</h4><p>GP Exception 13或者PF Exception 14，一般都是软件导致的紫屏，跟服务器没有关系，这类问题直接找VMware 创建case分析即可。</p><p>示例是我们曾经遇到VMware系统驱动bug 导致的PF Exception 14问题。参考如下的kb：</p><p><a href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2052368">https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2052368</a></p><h4 id="解决措施-4"><a href="#解决措施-4" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：VMware系统自带2208驱动紫屏问题"><a href="#场景1：VMware系统自带2208驱动紫屏问题" class="headerlink" title="场景1：VMware系统自带2208驱动紫屏问题"></a>场景1：VMware系统自带2208驱动紫屏问题</h5><p><strong>问题现象描述</strong></p><p>Vmware系统运行过程中出现紫屏。紫屏信息显示 “PF Exception 14 in xxx”</p><img src="/posts/22695/zh-cn_image_0261740943.png" class=""><p><strong>关键过程、根本原因分析</strong></p><p>Vmware 5.x系统bug 导致2208 卡在复位过程中出现紫屏无响应。</p><p><a href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2052368">https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2052368</a></p><p><strong>结论、解决方案及效果</strong></p><p><strong>结论：</strong></p><p>Vmware 系统自带2208驱动驱动bug 导致紫屏。</p><p><strong>解决方案：</strong></p><p>升级最新的iDriver驱动。</p><h5 id="场景2：CH121-V3服务器EXSi紫屏问题"><a href="#场景2：CH121-V3服务器EXSi紫屏问题" class="headerlink" title="场景2：CH121 V3服务器EXSi紫屏问题"></a>场景2：CH121 V3服务器EXSi紫屏问题</h5><p><strong>问题现象描述</strong></p><p>3台CH121 V3服务器ESXi 6.5出现紫屏，现象如下：</p><img src="/posts/22695/zh-cn_image_0261742568.jpg" class=""><p>VMware版本信息为：</p><img src="/posts/22695/zh-cn_image_0261742569.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p>分析BMC SEL日志，在ESXi主机出现紫屏时硬件没有异常：</p><img src="/posts/22695/zh-cn_image_0261742551.jpg" class=""><p>FDM日志也没有检测到硬件有异常：</p><img src="/posts/22695/zh-cn_image_0261742570.jpg" class=""><p>分析VMware日志发下在出现紫屏时出现以下异常：</p><img src="/posts/22695/zh-cn_image_0261742552.jpg" class=""><p><strong>结论、解决方案及效果</strong></p><p>联合VMware定位，该问题是由于EXSi 6.5 U2内核存在BUG导致紫屏，参考如下KB：</p><p><a href="https://kb.vmware.com/s/article/56492">https://kb.vmware.com/s/article/56492</a></p><h5 id="场景3：VMware-5-5自带MZ910网卡驱动bug导致紫屏"><a href="#场景3：VMware-5-5自带MZ910网卡驱动bug导致紫屏" class="headerlink" title="场景3：VMware 5.5自带MZ910网卡驱动bug导致紫屏"></a>场景3：VMware 5.5自带MZ910网卡驱动bug导致紫屏</h5><p><strong>问题现象描述</strong></p><p>硬件配置：E9000 CH配置MZ910</p><p>软件配置：VMware 5.5</p><p>问题描述：VMware5.5出现紫屏。如图1所示。</p><p><strong>图****1</strong> VMware 5.5紫屏</p><img src="/posts/22695/zh-cn_image_0261742625.png" class=""><p><strong>关键过程、根本原因分析</strong></p><p><strong>关键过程：</strong></p><p>联系VMware厂家分析VMware和Coredump文件。</p><p>紫屏是由VMware5.5系统自带MZ910驱动（驱动版本：4.6.100.0v）所导致的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vmnic0 be2net 10df:e220 10df:e264 4.6.100.0v 1.1.43.24 </span><br><span class="line">vmnic1 be2net 10df:e220 10df:e264 4.6.100.0v 1.1.43.24 </span><br><span class="line">vmnic2 be2net 10df:e220 10df:e264 4.6.100.0v 1.1.43.24 </span><br><span class="line">vmnic3 be2net 10df:e220 10df:e264 4.6.100.0v 1.1.43.24 </span><br><span class="line">#0 0x0000418015c8e218 in be_cq_create_v2 (pfob=0x410ae8948218, rd=, length=, solicited_eventable=, no_delay=, cqe_dma_coalescing=, eq_object=0x120, cq_object=0x410ae8948778) at vmkdrivers/src_9/private_drivers/ServerEngines/be2net/hwlib/cq.c:269 #1 0x0000418015c796de in be_mcc_create (adapter=0x410ae89481c0) at vmkdrivers/src_9/private_drivers/ServerEngines/be2net/be_init.c:2523 #2 mcc_setup (adapter=0x410ae89481c0) at vmkdrivers/src_9/private_drivers/ServerEngines/be2net/be_init.c:2908 #3 0x0000418015c7d41c in pf_reset (adapter=0x410ae89481c0, tx_timeo_ctxt=8 &#x27;b&#x27;) at vmkdrivers/src_9/private_drivers/ServerEngines/be2net/be_init.c:3989 #4 0x0000418015ae5516 in vmklnx_workqueue_callout (data=) at vmkdrivers/src_92/vmklinux_92/vmware/linux_workqueue.c:696 #5 0x000041801546165a in helpFunc (data=) at bora/vmkernel/main/helper.c:3251 #6 0x0000418015653532 in CpuSched_StartWorld (destWorld=, previous=) at bora/vmkernel/sched/cpusched.c:10052 #7 0x0000000000000000 in ?? ()</span><br></pre></td></tr></table></figure><p>在宕机前，vmnic0产生如下消息:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2014-07-02T15:29:12.477Z cpu12:33361)VMK_PCI: 720: device 0000:02:00.0 allocated 8 interrupts (intrType 3) 2014-07-02T15:29:12.477Z cpu12:33361)MSIX enabled for dev 0000:02:00.0 2014-07-02T15:29:12.480Z cpu12:33361)TX queue creation failed 2014-07-02T15:29:12.480Z cpu12:33361)Rings creation of ring set 2 failed 2014-07-02T15:29:12.483Z cpu12:33361)pf_reset: ring_sets_setup Failed 2014-07-02T15:29:12.483Z cpu12:33361)World: 8773: PRDA 0x418043000000 ss 0x0 ds 0x10b es 0x10b fs 0x10b gs 0x0 2014-07-02T15:29:12.483Z cpu12:33361)World: 8775: TR 0x4020 GDT 0x4123c9461000 (0x402f) IDT 0x4180154f3000 (0xfff) 2014-07-02T15:29:12.483Z cpu12:33361)World: 8776: CR0 0x80010031 CR3 0x1686a54000 CR4 0x42768</span><br></pre></td></tr></table></figure><p><strong>根本原因分析：</strong></p><p>VMware5.5系统自带MZ910驱动（驱动版本：4.6.100.0v）导致紫屏。</p><p><strong>结论、解决方案及效果</strong></p><p><strong>定位结论：</strong></p><p>VMware5.5系统自带MZ910驱动（驱动版本：4.6.100.0v）导致紫屏。</p><p><strong>解决方案：</strong></p><ol><li><p>下载VMware5.5驱动和MZ910的firmware，请参考《华为服务器操作系统安装指南》安装</p></li><li><p>通过虚拟光驱挂载MZ910的firmware。</p></li><li><p>在VMware系统下升级驱动。</p></li><li><p>把VMware5.5的驱动上传到VMware5.5系统某个目录。</p></li><li><p>在此目录下执行sh install.sh命令安装驱动。</p></li><li><p>选择1自动全部安装。</p></li><li><p>升级完成驱动后，重启VMware系统，然后按F11选择虚拟光驱启动，详细请参考指导书升级MZ910的firmware。</p></li><li><p>MZ910的firmware升级完成后，按照提示重启进入VMware系统，执行如下三条命令确认版本。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">esxcli software vib list |grep lpfc</span><br><span class="line">esxcli software vib list |grep elxnet</span><br><span class="line">esxcli network nic get -n vmnicx (x表示网卡序号)</span><br></pre></td></tr></table></figure></li></ol><h5 id="场景4：2288H-V5服务器VMware系统出现紫屏"><a href="#场景4：2288H-V5服务器VMware系统出现紫屏" class="headerlink" title="场景4：2288H V5服务器VMware系统出现紫屏"></a>场景4：2288H V5服务器VMware系统出现紫屏</h5><p><strong>问题现象描述</strong></p><p>硬件配置：2288H V5服务器+SM212网卡</p><p>问题现象：客户升级SM212网卡1.4.7版本驱动后，运行过程中出现紫屏问题</p><p><strong>关键过程、根本原因分析</strong></p><p>关键过程：</p><p>1、查看BMC日志，未发现硬件故障；</p><p>2、查看VMware官方论坛，找到同样紫屏打印的KB案例</p><p>客户服务器紫屏打印：</p><img src="/posts/22695/zh-cn_image_0261745792.png" class=""><p>VMware官方论坛紫屏KB案例打印</p><img src="/posts/22695/zh-cn_image_0261745793.png" class=""><p>3、对比call trace的函数和偏移量均完全匹配，说明代码调用逻辑完全一样</p><p><strong>根本原因分析：</strong></p><p>驱动版本和VMware系统不兼容</p><p><strong>结论、解决方案及效果</strong></p><p>结论：SM212网卡驱动版本和VMware系统不兼容，导致紫屏</p><p>解决方案：升级网卡驱动至1.4.10最新版本</p><h5 id="场景5：MZ910驱动不配套导致紫屏"><a href="#场景5：MZ910驱动不配套导致紫屏" class="headerlink" title="场景5：MZ910驱动不配套导致紫屏"></a>场景5：MZ910驱动不配套导致紫屏</h5><p><strong>问题现象描述</strong></p><p>E9000服务器安装MZ910网卡安装VMware5.5系统，并使用系统自带网卡驱动，然后跑网络压力，会概率性出现系统紫屏，如下图所示：</p><p>Vmawre5.5下紫屏</p><img src="/posts/22695/zh-cn_image_0261745843.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><ol><li>使用MZ910网卡在CH121刀片上安装VMware5.5系统，并使用系统自带MZ910网卡驱动，然后跑网络压力，很大概率性出现紫屏。</li><li>重启该套环境，进入系统后卸载掉系统自带驱动，并安装发布配套的驱动，再跑网络压力三天，未出现紫屏现象。</li><li>因此基本确认紫屏是由于系统自带MZ910驱动导致。</li><li>将出现紫屏的系统dump系统以及OS内日志反馈给供应商，供应商反馈原因是由于系统自带MZ910网卡驱动导致，建议卸载系统自带MZ910网卡驱动，并升级至配套版本。</li></ol><p><strong>结论、解决方案及效果</strong></p><p><strong>结论：</strong></p><p>系统自带MZ910网卡驱动导致系统紫屏，需要卸载系统自带驱动，并升级到华为官网发布的FW&amp;驱动。</p><p><strong>解决方案：</strong></p><p>在Vmware5.5系统下卸载MZ910 系统自带vmklnux driver，包括lpfc存储和be2net以太驱动。</p><p>esxcli software vib remove -n net-be2net</p><p>esxcli software vib remove -n scsi-lpfc820</p><p>然后在华为官网下载查看驱动配套表，并升级FW和安装驱动，重启生效。以当前发布的VMware5.5下配套关系为例：</p><p>MZ910 FW:10.2.590.0</p><p>elxnet：10.2.590.0</p><p>lpfc: 10.2.455.0</p><h5 id="场景6：MZ910网卡三次闪断问题"><a href="#场景6：MZ910网卡三次闪断问题" class="headerlink" title="场景6：MZ910网卡三次闪断问题"></a>场景6：MZ910网卡三次闪断问题</h5><p><strong>问题现象描述</strong></p><p>（一） 第一次闪断问题</p><p>1、问题回顾：</p><p>7月24日~8月3日，客户现网CH242 V3刀片运行ESXi操作系统，上层运行虚拟机。13个刀片不同时间发生网络瞬断问题，3个刀片出现紫屏宕机。</p><p>2、现象分析：</p><ol><li><p>瞬断现象：网络瞬断的过程中，网卡驱动能检查到FW产生dump，并上报ERR错误<img src="/posts/22695/zh-cn_image_0261746880.jpg" class=""></p></li><li><p>紫屏现象：在网卡瞬断的过程中，大概率出现紫屏现象，紫屏现象如下图所示。</p><img src="/posts/22695/zh-cn_image_0261746881.png" class=""></li></ol><p>3、根因分析：</p><p>网卡FW缺陷导致TX 方向的报文出现阻塞，之后网卡重启自愈，并出现闪断的现象。</p><p>4、网卡原厂报告：</p><img src="/posts/22695/zh-cn_image_0261746882.jpg" class=""><p>（二） 第二次闪断问题</p><p>1、问题回顾</p><p>8月10日~9月6日，在FW升级到11.1.245.5版本之后，客户现网再次出现网络瞬断与紫屏问题。</p><p>2、现象分析：</p><ol><li><p>瞬断现象：网络瞬断的过程中，网卡驱动同样检查到FW产生dump，并上报ERR错误。(由于出现瞬断时，网卡驱动的打印相似，这里不再描述)</p></li><li><p>紫屏现象：在网卡瞬断的过程中，小概率出现紫屏现象，紫屏现象如下图所示。</p><img src="/posts/22695/zh-cn_image_0261746883.jpg" class=""></li><li><p>根因分析：</p></li><li><p>网卡FW缺陷导致处理队列(HQPE)出现死锁，之后网卡重启自愈，并出现闪断的现象。</p></li><li><p>对比前两次网卡闪断的堆栈信息：第二次网卡紫屏后的堆栈明显不同于第一次，也从侧面说明两次问题的触发点与根因也不同。</p></li></ol><p>根因分析报告：</p><img src="/posts/22695/zh-cn_image_0261746884.png" class=""><p>解决措施说明<strong>：</strong></p><img src="/posts/22695/zh-cn_image_0261746885.png" class=""><p>瞬断现象：网络瞬断的过程中，网卡驱动同样检查到FW产生dump，并上报ERR错误。(出现瞬断时，网卡驱动的打印相似)</p><img src="/posts/22695/zh-cn_image_0261746859.jpg" class=""><p>紫屏现象：暂没有出现紫屏现象。</p><p><strong>关键过程、根本原因分析</strong></p><p>网卡三次闪断时的现象相似，但根因却不同。经初步分析认为：当网卡运行在客户新业务的流量场景下，并强制在GE的速率配置时，会大概率触发网卡FW缺陷，导致网卡闪断。</p><h5 id="场景7：VMware主机紫屏异常问题"><a href="#场景7：VMware主机紫屏异常问题" class="headerlink" title="场景7：VMware主机紫屏异常问题"></a>场景7：VMware主机紫屏异常问题</h5><p><strong>问题现象描述</strong></p><p>硬件配置：E9000机框+16<em>CH121 V3 +2</em> CX311+MZ512.</p><p>驱动版本信息如下：</p><p>Firmware Version: 11.1.240.0</p><p>Driver Version: lpfc/11.1.145.18-1OEM.600.0.0.2768847</p><p>组网配置如下：</p><img src="/posts/22695/zh-cn_image_0261747896.png" class=""><p><strong>问题现象：</strong></p><img src="/posts/22695/zh-cn_image_0261747927.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p>三个紫屏的 stack trace 是相同的：</p><p>VMware官方KB： <a href="https://kb.vmware.com/s/article/2151391">https://kb.vmware.com/s/article/2151391</a></p><p>由 lpfc driver 的问题导致，解决方法是 “Upgrade brcmfcoe driver to 11.2.1153.13 and lpfc driver to 11.2.156.20 or newer”</p><p><strong>结论、解决方案及效果</strong></p><p>There is same issue on ESXi6.5, please update to 11.2.156.20 or above your OS is ESXi6.0 and 6.5.</p><p>Issue happens when there are error frames on the line, and in FC SAN, usually the link is clean and you will not see the issue very frequently。</p><h5 id="场景8：2288H-V5-CPU故障导致Vmware紫屏PSOD"><a href="#场景8：2288H-V5-CPU故障导致Vmware紫屏PSOD" class="headerlink" title="场景8：2288H V5 CPU故障导致Vmware紫屏PSOD"></a>场景8：2288H V5 CPU故障导致Vmware紫屏PSOD</h5><p><strong>问题现象描述</strong></p><p>硬件配置：RH 2288HV5</p><p>问题现象：荷兰某局点2288H V5服务器，虚拟机在迁移过程中，发生紫屏PSOD</p><p><strong>关键过程、根本原因分析</strong></p><p>关键过程：</p><p>基于BMC日志分析，硬件无异常，fdm诊断日志无异常</p><img src="/posts/22695/zh-cn_image_0261747988.png" class=""><img src="/posts/22695/zh-cn_image_0261748748.png" class=""><p>OS日志分析</p><img src="/posts/22695/zh-cn_image_0261748749.png" class=""><p>Vmware厂商分析</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">All the PSOD instances are referring hardware related issues. PSOD is always seen on CPU 32.</span><br><span class="line">Panic Details: Crash at 2019-02-08T11:54:28.085Z on CPU 32 running world 66483. VMK Uptime:0:00:01:23.077</span><br><span class="line">Panic Details: Crash at 2019-02-08T12:06:25.189Z on CPU 32 running world 67007. VMK Uptime:0:00:01:59.485</span><br><span class="line">Panic Details: Crash at 2019-02-12T08:05:58.130Z on CPU 32 running world 65568. VMK Uptime:0:00:01:36.781</span><br><span class="line">Panic Details: Crash at 2019-02-14T13:53:33.024Z on CPU 32 running world 67077. VMK Uptime:0:00:01:25.644</span><br><span class="line">Panic Details: Crash at 2019-02-19T12:42:55.571Z on CPU 32 running world 71368. VMK Uptime:0:03:48:01.755</span><br><span class="line">Panic Details: Crash at 2019-02-20T11:43:12.443Z on CPU 32 running world 65682. VMK Uptime:0:00:51:15.911</span><br><span class="line">Panic Details: Crash at 2019-02-21T13:29:33.365Z on CPU 32 running world 69634. VMK Uptime:0:00:17:53.863</span><br><span class="line">CPU global information &#123;</span><br><span class="line">Hyperthreading state:Hyperthreading state: 3 -&gt; enabled</span><br><span class="line">HV state:HV state: 3 -&gt; HV Enabled</span><br><span class="line">Number of packages:2</span><br><span class="line">Number of cores:24</span><br><span class="line">Number of CPUs (threads):48</span><br><span class="line">Number of licensable cores:24</span><br><span class="line">SLC64 capable:0</span><br><span class="line">HV Replay capable:0</span><br><span class="line">&#125;</span><br><span class="line">Core:16</span><br><span class="line">Package:1</span><br><span class="line">Node:1</span><br><span class="line">Number of microcode updates:0</span><br><span class="line">Kindly engage hardware vendor and perform extensive diagnostic test on CPU. Core 16 (package 1) has some issues.</span><br><span class="line">Also try limiting the CPU to use the package 12 via CLI VMkernel.Boot.maxPCPUS=12. This shall avoid ESXi to use secondary package and we do not expect another crash. If so, post the said changes made, I shall take it further with VMware Engineering team for further investigation.</span><br><span class="line">I also did notice about BIOS of the said physical hardware isn&#x27;t compatible. Considering this to be a latest version, request you to receive acknowledge from hardware vendor about its compatibility and no known issues with reference to its room for kernel crash.</span><br></pre></td></tr></table></figure><p><strong>根本原因分析</strong>：</p><p>CPU故障导致VmwarePSOD</p><p><strong>结论、解决方案及效果</strong></p><p>结论：</p><p>CPU 16核和32核硬件故障导致Vmware发生紫屏PSOD现象</p><p>解决方案：</p><p>更换两个CPU，故障解决。</p><h5 id="场景9：RH2288H-V3使用ESXi-6-5-U2操作系统，加入vsan集群后出现紫屏"><a href="#场景9：RH2288H-V3使用ESXi-6-5-U2操作系统，加入vsan集群后出现紫屏" class="headerlink" title="场景9：RH2288H V3使用ESXi 6.5 U2操作系统，加入vsan集群后出现紫屏"></a>场景9：RH2288H V3使用ESXi 6.5 U2操作系统，加入vsan集群后出现紫屏</h5><p><strong>问题现象描述</strong></p><p>硬件配置：RH2288H V3</p><p>问题现象：RH2288H V3使用Esxi 6.5 U2操作系统，加入vsan集群后出现紫屏告警</p><p><strong>关键过程、根本原因分析</strong></p><p>关键过程：</p><p>1、紫屏代码：GP Exception 13所以初步判断是软件导致的紫屏</p><img src="/posts/22695/zh-cn_image_0261750602.png" class=""><p>2、VMware工程师分析如下，判断是硬件问题导致</p><img src="/posts/22695/zh-cn_image_0261750978.png" class=""><p>3、针对上述分析结果，进行了进一步测试，分别使用FTK压测各个部件均没有发现异常</p><p>4、交叉CPU测试，加入集群，发现BMC始终有CPU1告警（VTD 97类型告警，非硬件原因）</p><p>5、由于告警没有跟随CPU走，所以判断是主板原因，进行主板更换后，问题仍未解决。</p><p>6、经过了解，现场使用的ESXI6.5 U2的系统是通过ESXI 6.0 U3升级而来，怀疑是系统残留数据导致的不兼容，现场重装系统后问题未再复现。</p><p><strong>根本原因分析</strong>：</p><p>系统升级后，有残留文件导致存在导致集群内系统存在兼容性问题。</p><p><strong>结论、解决方案及效果</strong></p><p>结论：</p><p>系统升级后，有残留文件导致存在导致集群内系统存在兼容性问题。</p><p>解决方案：</p><p>重装操作系统。</p><h5 id="场景10：ESXi-5-5-x取消存储映射后可能触发紫屏"><a href="#场景10：ESXi-5-5-x取消存储映射后可能触发紫屏" class="headerlink" title="场景10：ESXi 5.5.x取消存储映射后可能触发紫屏"></a>场景10：ESXi 5.5.x取消存储映射后可能触发紫屏</h5><p><strong>问题现象</strong>：</p><p>你会看到类似的紫屏信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">2016-01-23T00:10:50.992Z cpu62:33922)WARNING: iodm: vmk_IodmEvent:193: vmhba2: FRAME DROP event has been observed 6 times in the last one minute. This suggests a problem with Fibre Channel link/switch!.</span><br><span class="line">2016-01-23T00:10:50.997Z cpu37:33222)WARNING: iodm: vmk_IodmEvent:193: vmhba1: FRAME DROP event has been observed 6 times in the last one minute. This suggests a problem with Fibre Channel link/switch!.</span><br><span class="line">2016-01-23T00:10:51.187Z cpu37:33215)World: 8777: PRDA 0x418049400000 ss 0x0 ds 0x4018 es 0x4018 fs 0x4018 gs 0x4018</span><br><span class="line">2016-01-23T00:10:51.187Z cpu37:33215)World: 8779: TR 0x4020 GDT 0x412546fe1000 (0x402f) IDT 0x418017ef4000 (0xfff)</span><br><span class="line">2016-01-23T00:10:51.187Z cpu37:33215)World: 8780: CR0 0x8001003d CR3 0x7abce000 CR4 0x216c</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)Backtrace for current CPU #37, worldID=33215, ebp=0x412546fdd120</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd120:[0x4180184becc9]vmk_IodmEvent@com.vmware.vmkapi#v2_2_0_0+0x89 stack: 0x412546fdd180,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd210:[0x4180185d8e2b]lpfc_handle_fcp_err@#+0xbb7 stack: 0x4125000000c4, 0x418</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd360:[0x4180185d97fe]lpfc_scsi_cmd_iocb_cmpl@#+0x9c2 stack: 0x410ceeb41500, 0</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd520:[0x4180185df0fb]lpfc_sli4_fcp_process_wcqe@#+0xbb stack: 0x412546fdd5b0,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd590:[0x4180185e64e8]lpfc_sli4_fcp_handle_wcqe@#+0x108 stack: 0x412546fdd600,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd660:[0x4180185f68d0]lpfc_sli4_handle_eqe@#+0x7b4 stack: 0x410a571c1ae0, 0x41</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd690:[0x4180185f7065]lpfc_sli4_intr_bh_handler@#+0x89 stack: 0x410a571c1360,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd720:[0x418017e6abe7]IRQBH@vmkernel#nover+0x2e7 stack: 0x412546fdd7e0, 0x2, 0x10000000000</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd7b0:[0x418017e2e9ff]BH_DrainAndDisableInterrupts@vmkernel#nover+0xf3 stack: 0x3, 0x41804</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd7f0:[0x418017e64277]IDT_IntrHandler@vmkernel#nover+0x1af stack: 0x412546fdd910, 0x418018</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd800:[0x418017ef2064]gate_entry@vmkernel#nover+0x64 stack: 0x4018, 0x4018, 0x0, 0x0, 0x0</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd910:[0x4180181a7b7a]Power_HaltPCPU@vmkernel#nover+0x1fe stack: 0xaa1da00, 0x4100355cc000</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdd980:[0x418018051e61]CpuSchedIdleLoopInt@vmkernel#nover+0x4c5 stack: 0x2546fdda20, 0x410a</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddae0:[0x418018057f30]CpuSchedDispatch@vmkernel#nover+0x1630 stack: 0x412546fddb50, 0x25e6</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddb50:[0x418018059275]CpuSchedWait@vmkernel#nover+0x245 stack: 0x1, 0x412546fddb80, 0x6874</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddbb0:[0x418018059a47]CpuSched_SleepUntilTC@vmkernel#nover+0xfb stack: 0x1, 0x3200000000,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddbe0:[0x41801815574a]SCSI_DelayOnTransientFailure@vmkernel#nover+0x5e stack: 0x2000000000</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddc50:[0x4180181456f1]SCSISyncPathCmdWithRetriesInt@vmkernel#nover+0xd9 stack: 0x200, 0x41</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddca0:[0x418018145794]vmk_ScsiIssueSyncPathCommandWithRetries@vmkernel#nover+0x4c stack: 0</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddcf0:[0x418018aee265]satp_lib_cx_sendAAQ@com.vmware.satp_lib_cx#0+0x99 stack: 0x4180187a5</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddd60:[0x418018aee3c1]satp_lib_cx_checkNaviReg@com.vmware.satp_lib_cx#0+0xa1 stack: 0x4100</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddda0:[0x418018af19f1]satp_inv_prepareInternalNaviReg@#+0x2d stack: 0x412546fd</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fdde20:[0x418018aefa47]satp_inv_updatePathStates@#+0x1f3 stack: 0x412546fddeb0,</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddef0:[0x418018798fe1]nmp_DeviceUpdatePathStates@com.vmware.vmkapi#v2_2_0_0+0x6d stack: 0x</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddf10:[0x41801878e928]nmpDeviceProbe@com.vmware.vmkapi#v2_2_0_0+0x2c stack: 0x410b8912dac0</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddf30:[0x41801810dc41]SCSIDeviceProbe@vmkernel#nover+0xc1 stack: 0x0, 0x412546fe7000, 0x41</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddfd0:[0x418017e6133a]helpFunc@vmkernel#nover+0x6b6 stack: 0x0, 0x0, 0x0, 0x0, 0x0</span><br><span class="line">2016-01-23T00:10:51.253Z cpu37:33215)0x412546fddff0:[0x418018056842]CpuSched_StartWorld@vmkernel#nover+0xfa stack: 0x0, 0x0, 0x0, 0x0, 0</span><br><span class="line">2016-01-23T00:10:51.284Z cpu37:33215)VMware ESXi 5.5.0 [Releasebuild-2456374 x86_64]</span><br><span class="line">#PF Exception 14 in world 33215:helper31-1 IP 0x4180184becc9 addr 0x410c89af6008</span><br></pre></td></tr></table></figure><p>/var/log/vmkernel.log，出现类似信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2015-12-11T11:57:01.035Z cpu58:33904)WARNING: iodm: vmk_IodmEvent:193: vmhba0: FRAME DROP event has been observed 217 times in the last one minute. This suggests a problem with Fibre Channel link/switch! </span><br><span class="line">2015-12-11T11:57:12.044Z cpu60:50767)WARNING: iodm: vmk_IodmEvent:193: vmhba0: FRAME DROP event has been observed 400 times in the last one minute. This suggests a problem with Fibre Channel link/switch! </span><br><span class="line">2015-12-11T11:57:23.001Z cpu48:2805963)WARNING: iodm: vmk_IodmEvent:193: vmhba0: FRAME DROP event has been observed 400 times in the last one minute. This suggests a problem with Fibre Channel link/switch! </span><br></pre></td></tr></table></figure><p><strong>问题原因：</strong></p><p>执行以下取消映射操作后但没有执行”重新扫描”则将会触发此问题：</p><ol><li>卸除VMFS数据存储</li><li>分离从ESXi主机已卸的LUN</li><li>取消映射此LUN从存储到这个ESXi主机</li></ol><p><strong>解决方案：</strong></p><p>要避免此问题，执行取消存储映射操作后务必重新扫描：</p><p>要执行ESXi主机的适配器重新扫描：</p><ol><li>转到在vSphere Web Client中ESXi主机。</li><li>单击管理选项卡</li><li>点击存储。</li><li>点击存储适配器，并选择适配器从列表中重新扫描。</li><li>点击重新扫描适配器。</li></ol><p><strong>涉及版本：</strong></p><p>VMware ESXi 5.5.x</p><h5 id="场景11：使用Intel-Xeon-Processor-E5-v4、-E7-v4-和D-1500系列处理器时，ESXi可能会出现紫屏"><a href="#场景11：使用Intel-Xeon-Processor-E5-v4、-E7-v4-和D-1500系列处理器时，ESXi可能会出现紫屏" class="headerlink" title="场景11：使用Intel Xeon Processor E5 v4、 E7 v4,和D-1500系列处理器时，ESXi可能会出现紫屏"></a>场景11：使用Intel Xeon Processor E5 v4、 E7 v4,和D-1500系列处理器时，ESXi可能会出现紫屏</h5><p><strong>问题现象</strong>：</p><p>当ESXi主机使用英特尔®至强®处理器E5 V4，V4 E7和D-1500系列，您可能会遇到这些症状：</p><ul><li>ESXi主机宕机，出现紫色屏幕（VMware 统称紫屏问题为：PSOD）</li><li>紫屏中没有详细的内核输出信息</li><li>紫色屏幕中，出现以下信息</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2016-07-27T13:14:04.549Z cpu58:42053)@BlueScreen: #PF Exception 14 in world 42053:vmm7:My_VM IP 0x410016bb8000 addr 0x410016bb8000 PTEs:0x10001c023;0x8000010023;0x80000e5023;0x800000408841e063;</span><br><span class="line">2016-07-27T13:14:04.549Z cpu58:42053)Code start: 0x418018000000 VMK uptime: 2:04:41:19.840</span><br><span class="line">2016-07-27T13:14:04.552Z cpu58:42053)base fs=0x0 gs=0x41804e800000 Kgs=0x0</span><br></pre></td></tr></table></figure><p><strong>解决方案：</strong></p><p>这是影响了英特尔®至强®处理器E5 V4，V4 E7和D-1500系列的一个已知的硬件问题。这是不是VMware的问题。</p><p>要解决此问题，升级系统BIOS（固件），以它为相关的Intel Xeon处理器以下微补丁修订级别版本：</p><table><thead><tr><th>CPU系列</th><th>CPUID模型（步进）</th><th>要求微码版本补丁</th><th>支持的ESXi版本</th></tr></thead><tbody><tr><td>英特尔至强E5-2600-V4英特尔至强E5-4600-V4</td><td>0x406F1（B0步进）</td><td>0x0b00001a或更高版本</td><td>ESXi的5.5 U3B或更高版本ESXi 6.0器U1b或更高版本</td></tr><tr><td>英特尔至强E7-8800-V4英特尔至强E7-4800-V4</td><td>0x406F1（B0步进）</td><td>0x0b00001a或更高版本</td><td>ESXi的6.0器U1b或更高版本</td></tr><tr><td>英特尔®至强®D-1500</td><td>0x50663（V2步进）</td><td>0x0700000c或更高版本</td><td>ESXi的6.0器U1b或更高版本</td></tr><tr><td>英特尔®至强®D-1500</td><td>0x50664（Y0步进）</td><td>0x0f00000a或更高版本</td><td>ESXi的6.0器U1b或更高版本</td></tr></tbody></table><p>欲了解更多信息，请联系您的硬件供应商。紫屏输出的内核信息也可能包含以下：</p><ul><li><p>SP_WaitLockIRQ</p><p>SPLockIRQWork</p><p>SPUnlockIRQWork</p><p>VsanSparseUpdateCache</p><p>IpfixPCInit</p><p>IpfixPortInsert</p></li><li><p>Panic_Exception</p><p>WorldletBHHandler</p><p>Timer_BHHandler</p><p>TimerRecomputeInterrupt</p><p>BH_DrainAndDisableInterrupts</p><p>IDT_IntrHandler</p><p>gate_entry_</p><p>Power_HaltPCPU</p><p>CpuSchedIdleLoopInt</p><p>CpuSchedDispatch</p><p>CpuSchedWait</p><p>CpuSched_VcpuHalt</p><p>CpuSched_VcpuMigrateBestPcpu</p><p>CpuSchedMarkReschedule</p><p>CpuSchedVcpuSetRunState</p><p>VMMVMKCall_Call</p><p>CpuSchedRebalance_PcpuMigrateIdle</p><p>IntrCookie_DoInterrupt</p><p>Panicvpanicint</p><p>Panic_NoSave</p></li></ul><p><strong>涉及版本</strong>：</p><p>ESXi 5.5 U3b or later</p><p>ESXi 6.0 U1b or later</p><h5 id="场景12：ESXi使用Broadcom网卡bnx2x驱动时可能会出现紫屏"><a href="#场景12：ESXi使用Broadcom网卡bnx2x驱动时可能会出现紫屏" class="headerlink" title="场景12：ESXi使用Broadcom网卡bnx2x驱动时可能会出现紫屏"></a>场景12：ESXi使用Broadcom网卡bnx2x驱动时可能会出现紫屏</h5><p><strong>问题现象：</strong></p><p>ESXi5.5.x 宕机出现紫色屏幕并出现类似信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@BlueScreen: #PF Exception 14 in world wwww:WorldName IP 0xnnnnnnnn addr 0x0</span><br><span class="line">PTEs:0xnnnnnnnn;0xnnnnnnnn;0x0;</span><br><span class="line"></span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]bnx2x_netqueue_ops@com.broadcom.bnx2x#9.2.2.0+0x54</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]netqueue_op_realloc_queue_with_attr@com.vmware.driverAPI#9.2+0x3cd</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]UplinkRxQueuesLoadBalance@vmkernel#nover+0x212c</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]UplinkLB_LoadBalanceCB@vmkernel#nover+0x8e</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]UplinkAsyncProcessCallsHelperCB@vmkernel#nover+0x223</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]helpFunc@vmkernel#nover+0x6b6</span><br><span class="line">0xnnnnnnnn:[0xnnnnnnnn]CpuSched_StartWorld@vmkernel#nover+0xfa</span><br></pre></td></tr></table></figure><p><strong>问题原因：</strong></p><p>此问题是由于bnx2x驱动程序处理NetQueue数据时不正确地传递一个错误的数据给VMkernel 而引起</p><p><strong>解决方案：</strong></p><p>这是一个QLogic驱动引起的问题，暂时没有解决方法。</p><p>要避免该问题进一步发生，请调整虚拟机延迟敏感度。</p><p>注意：具有高延迟敏感度的虚拟机会引发该问题</p><p>要更改虚拟机敏感度使用vSphere Web Client 登陆：</p><ol><li>导航至<strong>虚拟机&gt;编辑设置&gt; VM选项&gt;高级&gt;延迟灵敏度</strong>。</li><li>点击<strong>正常</strong>。</li></ol><p><strong>涉及版本：</strong></p><p>VMware ESXi 5.5.x</p><h5 id="场景13：VMware-ESXi-5-x主机出现指示-E1000PollRxRing和E1000DevRx的紫色诊断屏幕（紫屏）"><a href="#场景13：VMware-ESXi-5-x主机出现指示-E1000PollRxRing和E1000DevRx的紫色诊断屏幕（紫屏）" class="headerlink" title="场景13：VMware ESXi 5.x主机出现指示 E1000PollRxRing和E1000DevRx的紫色诊断屏幕（紫屏）"></a>场景13：VMware ESXi 5.x主机出现指示 E1000PollRxRing和E1000DevRx的紫色诊断屏幕（紫屏）</h5><p><strong>问题现象：</strong></p><ul><li>ESXi 5.x 主机出现故障并显示紫色诊断屏幕</li><li>ESXi 主机正在运行使用 E1000e 虚拟网络适配器的虚拟机</li><li>紫色诊断屏幕包含类似于以下内容的条目：</li></ul><p>注意： 确保在您的环境中遇到的问题符合本知识库文章中指定的症状。 知识库文章 <a href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2097304">VMware ESXi 5.x 主机出现紫色诊断屏幕，提及 E1000PollRxRing、E1000DevRx 和 Net_AcceptRxList (2097304)</a> 列举了一些与本知识库文章类似的症状，并且权宜措施完全相同。 但回溯中功能的偏差不同。</p><p><strong>解决方案：</strong></p><p>该问题在以下版本中已解决：</p><ul><li>ESXi 5.0 Patch Release ESXi500-201401001。 有关详细信息，请参见 <a href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2065814">VMware ESXi 5.0, Patch Release </a><a href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2065814">ESXi500-201401001 (2065814)</a>。</li><li>ESXi 5.1 Update 2（可在 <a href="https://https//my.vmware.com/web/vmware/info/slug/datacenter_cloud_infrastructure/vmware_vsphere/5_1">VMware Downloads</a> 上获取）。 有关详细信息，请参见 <a href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2065814">VMware </a><a href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2062314">VMware ESXi 5.1, Patch ESXi510-Update02: ESXi 5.1 Complete Update 2 (2062314)</a>。</li><li>有关 VMware ESXi 5.5 Patch Release ESXi550-201410001 (2087358) 的详细信息，请参见 <a href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2087358">VMware ESXi 5.5, Patch Release ESXi550-201410001 (2087358)</a></li><li>ESXi 6.0 GA，可从 <a href="https://https//my.vmware.com/web/vmware/info/slug/datacenter_cloud_infrastructure/vmware_vsphere/6_0">VMware Downloads</a> 获取。 有关详细信息，请参见 <a href="http://www.vmware.com/support/vsphere6/doc/vsphere-esx-vcenter-server-60-release-notes.html">VMware ESXi 6.0 Release notes</a>。</li></ul><p>VMware 推荐您将 ESXi 主机升级到最新可用的版本。 要检查最新可用版本，请转到 <a href="https://my.vmware.com/group/vmware/info?slug=datacenter_cloud_infrastructure/vmware_vsphere/6_0">VMware Downloads</a>，然后选择正使用的 ESXi 版本。</p><p>注意： 在更新 ESXi 主机版本后，需要更新 VMware Tools。</p><p>有关其他信息，请参见<a href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2077966">将 VMware 产品内部版本号与更新级别关联 (2077966)</a>。</p><p><strong>权宜措施</strong>：</p><p>要临时解决此问题，请执行以下操作：</p><ol><li><p>确定在使用 E1000e 系列虚拟网络接口的虚拟机：注意： 通过 vSphere PowerCLI 确定正使用 E1000e 网络适配器的虚拟机。 有关 PowerCLI 安装和使用的详细信息，请参见</p><p>vSphere PowerCLI Documentation</p><p>。</p><p>打开 vSphere PowerCLI。</p><p>运行以下命令连接到 vCenter Server：</p><p>Connect-VIServer vCenterServerHostnameOrIPAddress</p><p>注意： 在 PowerCLI 5.5 中运行 Connect-VIServer vCenterServerHostnameOrIPAddress 命令</p><p>运行以下命令生成使用 E1000e 网络适配器的虚拟机列表：</p><p>ForEach( $VM in (Get-VM) ) { $VM|Where{ $VM|Get-NetworkAdapter|Where{ $_.ExtensionData -like “<em>e1000e</em>“ } } }</p><p>您会看到类似以下内容的输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Name PowerState NumCPUs MemoryGB</span><br><span class="line">---- ---------- ------- --------</span><br><span class="line">VirtualMachineA PoweredOn 2 4.000</span><br><span class="line">VirtualMachineB PoweredOff 1 2.000</span><br></pre></td></tr></table></figure><p>此列表中的每个虚拟机都具有一个或多个 E1000e 虚拟网络接口。</p><p>执行其中一个选项：</p><ul><li>使用 VMXNET3 虚拟适配器并减少 E1000e 系列适配器的使用。 有关添加或修改虚拟机的虚拟网络接口的详细信息，请参见 <a href="http://pubs.vmware.com/vsphere-55/index.jsp?topic=/com.vmware.vsphere.vm_admin.doc/GUID-3719A0BE-4B4A-44FF-8A21-290950918FBD.html">Configuring Virtual Machine Hardware in the vSphere Web Client Guide</a> 中的“在 vSphere Web Client 中更改虚拟网络适配器（网卡）配置”部分。</li><li>在使用 e1000e 适配器的虚拟机中，禁用 RSS 或者将客户机操作系统中的 RSS 多个 rx 队列配置为 1。 有关详细信息，请参见 <a href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&docType=kc&docTypeID=DT_KB_1_1&externalId=2093679">Windows 虚拟机上的网络性能低下或网络延迟时间较长 (2093679)</a>。</li></ul><p><strong>Additional Information</strong></p><p>要在更新本文时收到提醒，请在“Actions”框中单击<strong>Subscribe to Document</strong>。</p><p><strong>Tags</strong></p><p><em>简体中文 Simplified Chinese</em></p><p><strong>See Also</strong></p><p>[VMware ESXi 5.x host experiences a purple diagnostic screen mentioning E1000PollRxRing and E1000DevRx (2059053)](<a href="https://kb.vmware.com/selfservice/microsites/">https://kb.vmware.com/selfservice/microsites/</a> <a href="http://kb.vmware.com/kb/2059053">http://kb.vmware.com/kb/2059053</a>)</p></li></ol><h5 id="场景14：物理CPU内部的二级Cache缓存故障导致VMware-ESXi主机前后多次紫屏问题"><a href="#场景14：物理CPU内部的二级Cache缓存故障导致VMware-ESXi主机前后多次紫屏问题" class="headerlink" title="场景14：物理CPU内部的二级Cache缓存故障导致VMware ESXi主机前后多次紫屏问题"></a>场景14：物理CPU内部的二级Cache缓存故障导致VMware ESXi主机前后多次紫屏问题</h5><p><strong>问题现象：</strong></p><p>局点一台ESXi主机上虚拟机业务均中断，登陆vCenter查看到ESXi主机失去连接，且无法正常ping通业务虚拟机和ESXi管理IP，登陆到单板的带外管理虚拟远程控制台，看到紫色屏幕，如下图：</p><p>（提示：物理单板两颗CPU，每颗12个core，开启了超线程，每颗24个逻辑core，第一颗CPU逻辑core为：pCPU0-pCPU23，第二颗CPU逻辑core为：pCPU24-pCPU47）</p><p>第一次紫屏如下（pCPU33上出错，第2颗物理CPU上）</p><img src="/posts/22695/zh-cn_image_0261797883.png" class=""><p><strong>处理过程：</strong></p><p>关注是否为ESXi软件问题导致，分析VMware日志和Coredump文件。 随后1天左右，接连又发生多次紫屏，如下图：第二次紫屏如下（pCPU32上出错，第2颗物理CPU上）：</p><img src="/posts/22695/zh-cn_image_0261799399.png" class=""><p>第三次紫屏如下（pCPU25上出错，第2颗物理CPU上）：</p><img src="/posts/22695/zh-cn_image_0261799904.png" class=""><p><strong>问题原因：</strong></p><p>通过前后发生多次紫屏，而且每次紫屏的信息完全不同，这很有可能为硬件导致。如果为ESXi软件问题，一般会在同一处出错而紫屏，而硬件问题则会引起ESXi错误信息多样化。同时发现三张紫屏错误信息中，每次发生错误都是在第二颗物理CPU上，初步判断为硬件CPU问题。虽然通过VMware侧观察到单板硬件状态信息均正常（ESXi通过CIM服务从单板BIOS获取状态信息），但无法完全确保硬件完全没有问题。</p><p>通过收集单板硬件日志，从硬件日志中看到物理CPU2内部的二级Cache缓存出现大量不可纠正错误，确认CPU2故障：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Hardware Error Log]:NO.1    SMI Serial NO.1   </span><br><span class="line">collect:bios(smi)    time: 2017-12-21 06:52:18 GMT    Validate(0x00)</span><br><span class="line">CPU:1 (socket:CPU2)    core:Uncore    LogType:MCA BANK19    (CBo_2_5_8_11_14_17)    MCA mode:CDC</span><br><span class="line">Error type:Uncorrected Errors-Catastrophic/Fatal</span><br><span class="line">MCACODE:0x110a (Cache Hierarchy Error: &#123;Generic&#125;CACHE&#123;Level-2&#125;_&#123;Generic-Error&#125;_ERR)</span><br></pre></td></tr></table></figure><p>经验总结:</p><p>1、排查是否存在硬件故障，建议从硬件侧日志分析确保；</p><p>2、同台ESXi主机多次紫屏情况下，如果紫屏错误信息多样化，一般可定界为硬件问题，详细总结请点此<a href="http://3ms.huawei.com/km/groups/2026933/blogs/details/5291495">链接</a> 中的“同主机多次紫屏的初步定界”部分介绍。</p><h5 id="场景15：【RH2288H-V2】【VMware-5-5】Qle2562-HBA卡故障，导致VMware系统无法正常安装，系统紫屏"><a href="#场景15：【RH2288H-V2】【VMware-5-5】Qle2562-HBA卡故障，导致VMware系统无法正常安装，系统紫屏" class="headerlink" title="场景15：【RH2288H V2】【VMware 5.5】Qle2562 HBA卡故障，导致VMware系统无法正常安装，系统紫屏"></a>场景15：【RH2288H V2】【VMware 5.5】Qle2562 HBA卡故障，导致VMware系统无法正常安装，系统紫屏</h5><p><strong>问题现象：</strong></p><p>硬件配置：RH2288H V2+Qle2562+LSI2208</p><p>OS：VMware5.5</p><p>问题描述：客户反馈开局过程中有一台RH2288H V2安装VMware5.5系统失败，出现紫屏：</p><p>图1 VMware5.5紫屏</p><img src="/posts/22695/zh-cn_image_0261799959.png" class=""><p><strong>处理过程：</strong></p><p>1） 分析紫屏截图，qla2x00是Qle2562 HBA卡驱动，运行qla2x00时出现VMware系统紫屏。初步分析和Qle2562 HBA卡相关，建议一线把Qle2562 HBA卡拔掉。</p><p>2） 一线把Qle2562 HBA卡拔掉后，可以正常安装VMware5.5系统，重启3次也没有问题；</p><p>3） 一线更换一个好的Qle2562 HBA卡后，可以正常安装VMware5.5系统，重启3次也没有问题；</p><p><strong>问题原因：</strong></p><p>Qle2562 HBA卡故障导致VMware系统无法正常安装。</p><p><strong>结论及解决方案：</strong></p><p>结论：</p><p>Qle2562 HBA卡故障导致VMware系统无法正常安装。</p><p>解决方案：</p><p>更换Qle2562 HBA卡备件。</p><h5 id="场景16：ESXi5-1-E1000虚拟网卡内核bug导致紫屏问题"><a href="#场景16：ESXi5-1-E1000虚拟网卡内核bug导致紫屏问题" class="headerlink" title="场景16：ESXi5.1 E1000虚拟网卡内核bug导致紫屏问题"></a>场景16：ESXi5.1 E1000虚拟网卡内核bug导致紫屏问题</h5><p><strong>问题现象：</strong></p><p>硬件配置： RH5885 V2 配置 Intel 82580网卡</p><p>软件配置： VMware 5.1</p><p>VMware5.1出现紫屏。如图1所示。</p><p>图1 VMware 5.1 紫屏</p><img src="/posts/22695/zh-cn_image_0261800553.png" class=""><p><strong>处理过程</strong>：</p><p>联系VMware厂家分析该紫屏信息，厂家给出了如下的KnowLedgeBase 链接：</p><p><a href="http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=2079118">http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=2079118</a></p><p>是E1000虚拟网卡开启了rss功能之后，内核中虚拟网卡与该功能处理相关的问题引发的紫屏：</p><img src="/posts/22695/zh-cn_image_0261800564.png" class=""><p><strong>问题根因：</strong></p><p>VMware5.1 内核问题导致紫屏。</p><p><strong>结论及解决方案：</strong></p><p>结论：</p><p>VMware5.1内核中E1000虚拟网卡相关模块问题导致紫屏。</p><p>解决方案：</p><p>1、到如下的VMWare官网链接安装VMware vSphere Update Manager并下载Patch ESXi510-201407401-BG补丁包后升级ESXi系统：</p><p><a href="http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=2079118">http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=2079118</a></p><h3 id="Vmkernel-amp-驱动主动触发的紫屏"><a href="#Vmkernel-amp-驱动主动触发的紫屏" class="headerlink" title="Vmkernel &amp;驱动主动触发的紫屏"></a>Vmkernel &amp;驱动主动触发的紫屏</h3><img src="/posts/22695/zh-cn_image_0258636669.png" class=""><h4 id="原因分析-5"><a href="#原因分析-5" class="headerlink" title="原因分析"></a>原因分析</h4><p>EXSi 主机，或者驱动在某些软件异常情况下调用vmk_Panic 函数可以触发紫屏（类似linux 系统的panic）。</p><p>此页内容对您是否有帮助？</p><h4 id="定位思路-5"><a href="#定位思路-5" class="headerlink" title="定位思路"></a>定位思路</h4><p>定位这类问题，首先查看挂死时的栈信息，如果栈信息在服务器设备的驱动上面（网卡、RAID卡）等，一般都是驱动导致的问题，优先检查VMware系统是否已经使用iDriver升级过驱动，驱动是否最新，如果驱动已经是最新，联系厂家进行定位。</p><p>示例是emulex be3网卡的一个bug 导致VMware系统紫屏。从紫屏信息上可以看出故障的代码在 elxnet_main.c 的 elxnet_txComplProcess 函数的 4057行。代码如下：</p><img src="/posts/22695/zh-cn_image_0258637887.png" class=""><p>可以看到elxnet_txComplProcess 函数调用 ELXNET_HALT_COND宏，最终调用vmk_Panic 触发VMware 系统紫屏。</p><img src="/posts/22695/zh-cn_image_0258637888.png" class=""><p>如果栈信息不在任何的驱动上面，联系VMware 进行定位。</p><h3 id="其他类型的紫屏错误"><a href="#其他类型的紫屏错误" class="headerlink" title="其他类型的紫屏错误"></a>其他类型的紫屏错误</h3><p>以下的这些紫屏错误都跟硬件没有关系，都是VMware 系统自身的bug导致，有兴趣的同事可以去了解下。</p><h4 id="控制台警告"><a href="#控制台警告" class="headerlink" title="控制台警告"></a>控制台警告</h4><p>错误示例：COS Error: Oops</p><p>描述：ESX 主机出现故障并在出现服务控制台警告时显示紫色屏幕。与大多数紫色屏幕错误不同的是，该错误并非由 VMkernel 触发。相反，它由服务控制台触发，并发生在 Linux 级别。这些紫色屏幕错误包含来自 Linux 内核的其他信息。有关控制台警告的详细信息，请参见 Understanding an “Oops” purple diagnostic screen (1006802)。</p><h4 id="断言"><a href="#断言" class="headerlink" title="断言"></a>断言</h4><p>错误示例：ASSERT bora/vmkernel/main/pframe_int.h:527</p><p>描述：断言错误属于软件错误，因为它们都与程序所基于的假设条件有关。此类型的紫色屏幕错误主要是由软件错误导致的。有关断言错误消息的详细信息，请参见 Understanding ASSERT and NOT_IMPLEMENTED purple diagnostic screens (1019956)。</p><h4 id="未执行"><a href="#未执行" class="headerlink" title="未执行"></a>未执行</h4><p>错误示例：NOT_IMPLEMENTED /build/mts/release/bora-84374/bora/vmkernel/main/util.c:83</p><p>描述：代码遇到超出设计处理范围的情形时会出现未执行错误消息。有关详细信息，请参见 Understanding ASSERT and NOT_IMPLEMENTED purple diagnostic screens (1019956)。</p><h4 id="转数已超出-可能出现死锁"><a href="#转数已超出-可能出现死锁" class="headerlink" title="转数已超出/可能出现死锁"></a>转数已超出/可能出现死锁</h4><p>错误示例：Spin count exceeded (iplLock) - possible deadlock</p><p>描述：线程尝试在代码关键部分执行时，VMware ESX 主机可能在紫色诊断屏幕上报告转数已超出且可能出现死锁。由于线程正尝试进入关键部分，因此，它需要执行自旋锁操作，以便先轮询互斥锁，然后再执行代码。线程在执行自旋锁操作期间会继续轮询互斥锁，但是，互斥锁轮询次数存在一定限制。有关转数已超出错误的详细信息，请参见 Understanding a “Spin count exceeded” purple diagnostic screen (1020105)。</p><h4 id="解决措施-5"><a href="#解决措施-5" class="headerlink" title="解决措施"></a>解决措施</h4><h5 id="场景1：【CH121】【VMware-ESXi5-1】Heap内存不足导致VMware紫屏"><a href="#场景1：【CH121】【VMware-ESXi5-1】Heap内存不足导致VMware紫屏" class="headerlink" title="场景1：【CH121】【VMware ESXi5.1】Heap内存不足导致VMware紫屏"></a>场景1：【CH121】【VMware ESXi5.1】Heap内存不足导致VMware紫屏</h5><p><strong>问题现象：</strong></p><p>硬件配置：CH121+16<em>8G内存+2</em>E5-2620</p><p>软件版本：MM910:2.20；刀片服务器BIOS:V378 BMC:5.11；</p><p>OS：VMware5.1</p><p>问题描述：客户反馈在安装Trend Micro厂家的第三方安全软件dvfilter-dsa模块后，服务器运行一段时间后，多台服务器出现如图1-1的紫屏。</p><p>图1 dvfilter-dsa模块调用异常导致PSOD</p><img src="/posts/22695/zh-cn_image_0261898928.png" class=""><p><strong>处理过程：</strong></p><p>1） VMware工程师分析：</p><p>这些主机发生紫屏时都有相似的错误信息输出,确定是同一类故障。</p><p>“dlmalloc.c”是内存分配相关的一段代码。</p><p><strong>紫屏报警信息如下:</strong></p><p>-—————</p><p>PSOD (HZ504K0601)</p><p>-—————</p><p>2015-03-29T13:48:07.558Z cpu8:4711920)@BlueScreen: PANIC bora/vmkernel/main/dlmalloc.c:4827 - Usage error in dlmalloc 2015-03-29T13:48:07.558Z cpu8:4711920)Code start: 0x41802d800000 VMK uptime: 110:08:30:31.303 2015-03-29T13:48:07.559Z cpu8:4711920)0x4122d7c1b588:[0x41802d87b31a]PanicvPanicInt@vmkernel#nover+0x61 stack: 0x3000000008 2015-03-29T13:48:07.560Z cpu8:4711920)0x4122d7c1b668:[0x41802d87bb1b]Panic@vmkernel#nover+0xae stack: 0x4100344b04a0</p><p>-—————</p><p>PSOD(HZ504K0603)</p><p>-—————</p><p>2015-03-31T02:10:17.680Z cpu45:34771)@BlueScreen: PANIC bora/vmkernel/main/dlmalloc.c:4827 - Usage error in dlmalloc 2015-03-31T02:10:17.680Z cpu45:34771)Code start: 0x418005c00000 VMK uptime: 0:18:46:14.697 2015-03-31T02:10:17.681Z cpu45:34771)0x41225f4db348:[0x418005c7b31a]PanicvPanicInt@vmkernel#nover+0x61 stack: 0x3000000008 2015-03-31T02:10:17.682Z cpu45:34771)0x41225f4db428:[0x418005c7bb1b]Panic@vmkernel#nover+0xae stack: 0x410058699b20</p><p><strong>检查系统kernel日志：</strong></p><p>这些主机在发生紫屏时都出现大量下面的告警信息:</p><p>-—————</p><p>(HZ504K0601)</p><p>-—————</p><p>2015-03-29T13:46:18.395Z cpu26:103997)WARNING: Heap: 3058: Heap_Align(dvfilter-dsa, 80/80 bytes, 64 align) failed. caller: 0x41802d819aa7 2015-03-29T13:46:18.734Z cpu31:6538979)WARNING: Heap: 2677: Heap dvfilter-dsa already at its maximum size. Cannot expand.</p><p>2015-03-29T13:46:19.120Z cpu29:16413)WARNING: Heap: 2677: Heap dvfilter-dsa already at its maximum size. Cannot expand.</p><p>-—————-</p><p>(HZ504K0603)</p><p>-—————</p><p>2015-03-31T02:10:17.021Z cpu37:34772)WARNING: Heap: 2677: Heap dvfilter-dsa already at its maximum size. Cannot expand.</p><p>2015-03-31T02:10:17.295Z cpu39:34771)WARNING: Heap: 3058: Heap_Align(dvfilter-dsa, 880/880 bytes, 8 align) failed. caller: 0x4180064742f2 2015-03-31T02:10:17.512Z cpu45:16429)WARNING: Heap: 3058: Heap_Align(dvfilter-dsa, 392/392 bytes, 8 align) failed. caller: 0x418006488890</p><p>2） Trend Micro厂家分析：</p><p>Trend Micro厂家给出了一个kb，确认该问题和Heap内存不足会导致VMware系统紫屏，官方链接：</p><p><a href="http://esupport.trendmicro.com/solution/en-us/1095995.aspx">http://esupport.trendmicro.com/solution/en-us/1095995.aspx</a></p><p>图2 Trend Micro厂家官方说明：</p><img src="/posts/22695/zh-cn_image_0261898974.png" class=""><p><strong>问题原因：</strong></p><p>Heap内存不足会导致VMware系统紫屏。</p><p><strong>结论和解决方案：</strong></p><p>结论：</p><p>Heap内存不足会导致VMware系统紫屏。</p><p>解决方案：</p><p>通过优化heap memory 分配给filter driver大小调整解决紫屏问题。参考Trend Micro厂家官方建议或者直接联系厂家解决。</p><p><a href="http://esupport.trendmicro.com/solution/en-us/1095995.aspx">http://esupport.trendmicro.com/solution/en-us/1095995.aspx</a></p><h5 id="场景2：RH2288H-V2服务器VMware-5-5报Can-not-detect-the-last-level-cache紫屏问题"><a href="#场景2：RH2288H-V2服务器VMware-5-5报Can-not-detect-the-last-level-cache紫屏问题" class="headerlink" title="场景2：RH2288H V2服务器VMware 5.5报Can not detect the last level cache紫屏问题"></a>场景2：RH2288H V2服务器VMware 5.5报Can not detect the last level cache紫屏问题</h5><p><strong>环境说明：</strong></p><p>服务器：RH2288H V2；</p><p>操作系统：VMware 5.5；</p><p><strong>问题现象：</strong></p><p>秘鲁GMD客户反馈在RH2288H V2服务器上安装VMware 5.5时，出现以下报错：</p><p>“can’t detect the last level cache”</p><img src="/posts/22695/zh-cn_image_0261899521.png" class=""><p><strong>问题原因：</strong></p><p>该问题与BIOS中的Max CPUID Value Limit选项的设置有关。</p><ol><li><p>Max CPUID Value Limit选项默认是隐藏的。RH2288H V2服务器使用BIOS版本V386以下时，可以在启动过程中按ctrl+alt+1进入高级菜单，此时才可以在BIOS中看到Max CPUID Value Limit选项；</p></li><li><p>Max CPUID Value Limit选项默认设置为Disabled，这里将其设置为Enabled；</p></li><li><p>重新安装VMware 5.5，此时问题复现，测试截图如下所示：</p><img src="/posts/22695/zh-cn_image_0261910114.png" class=""></li><li><p>将Max CPUID Value Limit<strong>选项设置为</strong>Disabled<strong>，重新启动服务器；</strong></p></li><li><p>重新安装VMware 5.5，此时可以正常安装；</p></li></ol><p><strong>结论和解决方案：</strong></p><p>这个问题与BIOS中的Max CPUID Value Limit选项的设置有关；</p><h5 id="场景3：VMware-5-x-ixgbe驱动bug导致紫屏"><a href="#场景3：VMware-5-x-ixgbe驱动bug导致紫屏" class="headerlink" title="场景3：VMware 5.x ixgbe驱动bug导致紫屏"></a>场景3：VMware 5.x ixgbe驱动bug导致紫屏</h5><p><strong>问题现象：</strong></p><p>服务器安装VMware 5.5紫屏，屏幕打印ixgbe驱动相关堆栈信息，如下截图。</p><img src="/posts/22695/zh-cn_image_0261899601.png" class=""><img src="/posts/22695/zh-cn_image_0261899618.png" class=""><p><strong>问题原因：</strong></p><p>Issue is seen with Driver Version: 3.19.1iov for Network adapter Intel Corporation Ethernet 10G 2P X520 Adapter.</p><p>The code added for Linux driver to handle SFP module hot plug affected ESX driver. The new code caused ESX driver to constantly poll for the module info if there is no module installed. Every poll constantly added a 1 second delay which eventually locked up a CPU and led to a system crash.</p><p><strong>结论和解决方案：</strong></p><p>Upgrade driver for Network adapter Intel Corporation Ethernet 10G 2P X520 Adapter Driver to version: ixgbe 3.21.4 or later.</p><p>You can download the driver ixgbe 3.21.4 from:</p><p><a href="https://my.vmware.com/web/vmware/details?downloadGroup=DT-ESXI55-INTEL-IXGBE-3214&amp;productId=353">https://my.vmware.com/web/vmware/details?downloadGroup=DT-ESXI55-INTEL-IXGBE-3214&amp;productId=353</a></p><p>Guidance for installing async drivers on vmware esxi 5.0, 5.1, and 5.5:</p><p><a href="http://kb.vmware.com/kb/2005205">http://kb.vmware.com/kb/2005205</a></p><h5 id="场景4：E9000服务器多节点故障紫屏问题"><a href="#场景4：E9000服务器多节点故障紫屏问题" class="headerlink" title="场景4：E9000服务器多节点故障紫屏问题"></a>场景4：E9000服务器多节点故障紫屏问题</h5><p><strong>问题现象描述</strong></p><p>NA客户E9000服务器slot2，slot4，slot11，slot12四个槽位的计算节点依次出现紫屏现象。该四个节点的操作系统为Vmware，上行业务为虚拟化集群。</p><p>操作系统紫屏后，重启该节点刀片，系统恢复正常。并且E9000管理界面无任何硬件告警。</p><img src="/posts/22695/zh-cn_image_0261899741.jpg" class=""><img src="/posts/22695/zh-cn_image_0261899742.jpg" class=""><p>slot4计算节点紫屏截图</p><img src="/posts/22695/zh-cn_image_0261899743.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p><strong>1****、初步分析</strong></p><p>BMC硬件分析无任何异常，且从问题现象判断与硬件相关不大。</p><p>已有的紫屏截图：</p><img src="/posts/22695/zh-cn_image_0261899744.jpg" class=""><img src="/posts/22695/zh-cn_image_0261899640.jpg" class=""><p>报错驱动模块为elxnet，即Emulex 网卡扣卡的驱动，出错的处理过程是txCompleProcess，即发送报文时遇到UE(Unrecoverable Error不可修复错误)故障。</p><p>下图为硬件信息:</p><img src="/posts/22695/zh-cn_image_0261899745.jpg" class=""><p>根据VMware的commands目录下相关文件，确认驱动与固件版本分别为：</p><p>Driver: elxnet</p><p>Firmware Version: 1.1.43.34</p><p>Version: 10.2.309.6v</p><p>操作系统版本：ESXi5.5</p><p>刀片型号：IT11SRCD，即CH240。</p><p>根据版本iDriver配套表，完全不满足匹配要求。</p><p><strong>2****、进一步分析</strong></p><p>客户升级当前OS版本VMware5.5.0为VMware6.5.0后，升级对应驱动和FW配套版本。</p><p>CH121 CPU 2650 V2，CH240 CPU 4650 V2，联想服务器CPU 2650 V2。</p><p>客户反馈之前有几台虚机在E9000漂移不定，客户发现这几台虚机漂移到哪个刀片那个刀片就紫屏。</p><table><thead><tr><th><strong>厂商</strong></th><th><strong>型号</strong></th><th><strong>CPU****型号</strong></th><th><strong>华为</strong> <strong>TO</strong> <strong>联想</strong></th><th><strong>联想</strong> <strong>TO</strong> <strong>华为</strong></th></tr></thead><tbody><tr><td>华为刀片</td><td>CH121</td><td>2650V2</td><td>√</td><td>×</td></tr><tr><td>联想刀片</td><td>X240</td><td>2650V2</td><td>√</td><td>×</td></tr><tr><td><strong>厂商</strong></td><td><strong>型号</strong></td><td><strong>CPU****型号</strong></td><td><strong>华为</strong> <strong>TO</strong> <strong>联想</strong></td><td><strong>联想</strong> <strong>TO</strong> <strong>华为</strong></td></tr><tr><td>华为刀片</td><td>CH240</td><td>4650V2</td><td>√</td><td>×</td></tr><tr><td>联想刀片</td><td>X240</td><td>2650V2</td><td>√</td><td>×</td></tr><tr><td><strong>厂商</strong></td><td><strong>型号</strong></td><td><strong>CPU****型号</strong></td><td><strong>CH121 TO CH240</strong></td><td><strong>CH240 TO CH121</strong></td></tr><tr><td>华为刀片</td><td>CH121</td><td>2650V2</td><td>√</td><td>√</td></tr><tr><td>华为刀片</td><td>CH240</td><td>4650V2</td><td>√</td><td>√</td></tr><tr><td><strong>厂商</strong></td><td><strong>型号</strong></td><td><strong>CPU****型号</strong></td><td><strong>BIOS****版本</strong></td><td><strong>网卡驱动版本</strong></td></tr><tr><td>华为刀片</td><td>CH121</td><td>2650V2</td><td>5.21</td><td>11.1.240.0</td></tr><tr><td>华为刀片</td><td>CH240</td><td>4650V2</td><td>5.21</td><td>11.1.240.0</td></tr></tbody></table><p>查询最新紫屏截图和错误打印，确认为VMware版本bug问题。</p><p><a href="https://kb.vmware.com/articleview?docid=2147958&amp;lang=zh_CN">https://kb.vmware.com/articleview?docid=2147958&amp;lang=zh_CN</a></p><p>错误打印：#GP Exception 13 in world 187416:vmm3:XXXXXXXX @ 0x418021d8adc7</p><img src="/posts/22695/zh-cn_image_0261899641.jpg" class=""><p><strong>结论、解决方案及效果</strong></p><p>结论</p><ol><li><p>最初刀片紫屏是因为网卡和RAID卡FW和驱动不配套。</p></li><li><p>刀片虚拟机迁移紫屏原因在于VMware6.5.0版本bug。</p></li></ol><p>解决方案</p><ol><li>升级FW和驱动至配套版本。</li><li>此问题在 ESX 6.5.0a（可从 VMware Downloads 获得）中已得到解决。</li></ol><p>要针对从以前版本迁移到 ESXi 6.5 主机的虚拟机临时解决此问题，请从 ESXi 6.5 主机恢复虚拟机并在所有 ESXi 6.5 主机上将 Numa.FollowCoresPerSocket 设置为 1。</p><h5 id="场景5：安装包损坏（Could-not-load-multiboot-modules-Bad-parameter）"><a href="#场景5：安装包损坏（Could-not-load-multiboot-modules-Bad-parameter）" class="headerlink" title="场景5：安装包损坏（Could not load multiboot modules : Bad parameter）"></a>场景5：安装包损坏（Could not load multiboot modules : Bad parameter）</h5><p><strong>问题现象描述</strong></p><p>客户在安装VMWare ESXi 失败（“Could not load multiboot modules : Bad parameter”），提示如下紫屏错误：</p><img src="/posts/22695/zh-cn_image_0261907005.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p>分析原因一般有两个：</p><ol><li>兼容性问题。</li><li>安装源损坏，无法加载XXX modules。</li></ol><p><strong>结论、解决方案及效果</strong></p><p><strong>结论：</strong></p><ol><li>查看安装的版本是否在兼容性列表。</li><li>重新刻制安装光盘，可以成功安装。</li></ol><h5 id="场景6：CH220-V3服务器安装VMware-ESXi-5-1-U2紫屏问题"><a href="#场景6：CH220-V3服务器安装VMware-ESXi-5-1-U2紫屏问题" class="headerlink" title="场景6：CH220 V3服务器安装VMware ESXi 5.1 U2紫屏问题"></a>场景6：CH220 V3服务器安装VMware ESXi 5.1 U2紫屏问题</h5><p><strong>问题现象描述</strong></p><p>CH220 V3服务器配置E5-2697 V3 CPU，安装VMware ESXi 5.1U2系统，在loading阶段出现紫屏问题，无法完成安装；</p><p>【环境描述】</p><p>OS: VMware5.1.0.update02-1483097.x86_64.iso</p><p>CPU: Intel(R) Xeon(R) CPU E5-2697 v3 @ 2.60GHz *2</p><p>内存：Samsung 16384 MB 2133 MHz</p><p>RAID卡：LSI2308卡</p><p>硬盘：THSHIBA MBF2300RC 300GB</p><img src="/posts/22695/zh-cn_image_0261907406.jpg" class=""><p><strong>关键过程、根本原因分析</strong></p><p>该问题定位为VMware ESXi 5.1U2 bug；当CPU核数刚好等于56时，安装VMware ESXi 5.1U2过程中会出现紫屏。这个bug在VMware ESXi 5.1 Patch 5（build版本2000251），即VMware ESXi 5.1 U2a得到解决。</p><p>分析过程：</p><ol><li>在同一环境下，RH2288 V3 配置Intel(R) Xeon(R) CPU E5-2698 v3 @ 2.30GHz的CPU, 可以完成VMware ESXi 5.1U2系统安装；</li><li>在同一环境下，RH2288 V3与CH220 V3对调CPU, 进行VMware ESXi 5.1U2系统安装；在RH2288 V3配置E5-2697 V3 CPU后，安装过程中（loading阶段）也出现紫屏问题；而在CH220 V3上，配置E5-2698 V3 CPU后可以完成VMware ESXi 5.1U2系统安装。</li><li>遍历CPU型号，发现V3服务器配置E5-2697 V3 CPU时该紫屏问题才出现；</li><li>对比验证友商同代服务器，在配置了E5-2697 V3 CPU后，友商服务器可以完成VMware ESXi 5.1U2系统安装；发现友商服务器的BIOS中关闭了超线程，而华为服务器默认开启了超线程；</li><li>友商服务器的BIOS中开启超线程后，重新安装VMware ESXi 5.1U2，复现了紫屏问题。</li><li>V3服务器配置E5-2697 V3 CPU且开启超线程的情况下，CPU核数为56个核；通过定制BIOS，将E5-2698 V3 关掉2个核，即开启56个核，发现此时紫屏问题也能复现。当关掉3个核，即开启55个核或者关掉1个核，即开启57个核的情况下，都可以正常安装VMware ESXi 5.1U2；</li><li>使用VMware ESXi 5.1 U2a的ISO安装，发现此时即使CPU核数为56个时，都可以正常安装操作系统；</li><li>通过测试验证以及与VMware沟通确认，VMware答复该问题为VMware ESXi 5.1U2 bug，需要通过VMware ESXi 5.1 Patch 5（build版本2000251），即VMware ESXi 5.1 U2a解决；</li></ol><img src="/posts/22695/zh-cn_image_0261907398.jpg" class=""><p><strong>结论、解决方案及效果</strong></p><p><strong>结论：</strong></p><p>该问题定位为VMware ESXi 5.1U2 bug。</p><p><strong>解决方案：</strong></p><p>当服务器配置E5-2697 V3 CPU时，请使用VMware ESXi 5.1 Patch 5（build版本2000251），即VMware ESXi 5.1 U2a或者ESXi 5.1 U3等更高版本来安装；</p><p><strong>备注：</strong></p><p>在VMware官网，可以通过输入build版本号获取相应VMware ESXi 5.1 U2a ISO文件，如下所示：</p><p><a href="https://www.vmware.com/patchmgr/findPatchByReleaseName.portal">https://www.vmware.com/patchmgr/findPatchByReleaseName.portal</a></p><img src="/posts/22695/zh-cn_image_0261907399.jpg" class=""><img src="/posts/22695/zh-cn_image_0261907400.jpg" class=""><h5 id="场景7：RH2288-V3启动EXSi紫屏"><a href="#场景7：RH2288-V3启动EXSi紫屏" class="headerlink" title="场景7：RH2288 V3启动EXSi紫屏"></a>场景7：RH2288 V3启动EXSi紫屏</h5><p><strong>问题现象描述</strong></p><p>硬件配置：RH2288 V3</p><p>问题现象：系统启动时发生紫屏无法进入系统</p><p><strong>关键过程、根本原因分析</strong></p><p>关键过程：</p><p>1.系统启动界面发生紫屏。</p><img src="/posts/22695/zh-cn_image_0261908655.png" class=""><p>2.NOT_IMPLEMENTED紫屏代码说明。</p><img src="/posts/22695/zh-cn_image_0261908544.png" class=""><p>3.VM官网相关案例说明。</p><p><a href="https://kb.vmware.com/s/article/2063837">https://kb.vmware.com/s/article/2063837</a></p><img src="/posts/22695/zh-cn_image_0261908665.png" class=""><p>4.重新安装系统后紫屏现象消失。</p><p><strong>根本原因分析</strong>：</p><p>系统文件损坏导致无法系统无法启动。</p><p><strong>结论、解决方案及效果</strong></p><p>结论：</p><p>系统文件损坏导致无法系统无法启动。</p><p>解决方案：</p><p>重新安装系统。</p><h3 id="参考KB"><a href="#参考KB" class="headerlink" title="参考KB"></a>参考KB</h3><p><a href="http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=1004250">http://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=1004250</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VMware日志分析方法</title>
      <link href="/posts/2252/"/>
      <url>/posts/2252/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="VMware日志分析方法"><a href="#VMware日志分析方法" class="headerlink" title="VMware日志分析方法"></a>VMware日志分析方法</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="查看日志收集时间"><a href="#查看日志收集时间" class="headerlink" title="查看日志收集时间"></a>查看日志收集时间</h3><p>收到vm support日志后第一件事就是确认日志的收集时间是否包含故障发生时间，如果没有包含日志已经没分析的必要了。日志收集时间在commands\date.txt文件中。</p><h3 id="查看Vmware版本信息"><a href="#查看Vmware版本信息" class="headerlink" title="查看Vmware版本信息"></a>查看Vmware版本信息</h3><p>确认VMware ESXi系统的版本与服务器的版本的兼容性，VMware ESXi系统的版本在commands\vmware_-vl.txt中查询。如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">VMware ESXi 5.5.0 build-2068190</span><br><span class="line">VMware ESXi 5.5.0 Update 2</span><br></pre></td></tr></table></figure><h3 id="查看重启关机记录"><a href="#查看重启关机记录" class="headerlink" title="查看重启关机记录"></a>查看重启关机记录</h3><p>查看vmksummary日志，vmksummary会记录所有OS的重启关机记录，正常运行时每一个小时记录一次心跳，通过它可以对EXSi主机的运行情况有一个大概的了解。</p><p>vmksummary日志在var\run\log\vmksummary.log文件中，如下图所示：</p><img src="/posts/2252/zh-cn_image_0258617288.png" class=""><p><a href="https://kb.vmware.com/s/article/2004566">https://kb.vmware.com/s/article/2004566</a></p><h3 id="确认BMC时间和OS时间时差"><a href="#确认BMC时间和OS时间时差" class="headerlink" title="确认BMC时间和OS时间时差"></a>确认BMC时间和OS时间时差</h3><p>vm-support日志中的异常记录，通常需要结合BMC日志查看硬件是否异常。由于服务器的BMC时间和OS时间是两套时钟源，且用户在设置时区时可能会有所差异，在问题分析前，确认BMC时间和OS时间的时差就显得尤为重要。</p><p>确认BMC时间和OS时间的时差，需要结合<a href="https://support-it.huawei.com/docs/zh-cn/typical-scenarios-1/server-knowledgebase/zh-cn_topic_0258617212.html">查看重启关机记录</a>的vmksummary日志和BMC sel日志，sle日志在BMC一键收集日志中AppDump\sensor_alarm\sel_current.csv。确认方法如下：</p><ol><li>在vmksummary日志中查找到一次重启的记录，如“2015-11-19T09:14:46Z bootstop: Host is rebooting”，记录下OS重启的时间。</li><li>在BMC sel日志中，查找到该时间前后的重启记录，如“SysRestart”,”System Restart [Unknown][IPMB]”，记录下两者之间的差异。</li><li>再次查找2~3个vmksummary和sel日志的重启或者关机时间进行确认，如果时差是固定的话基本可以确认BMC时间和OS时间的时差。</li></ol><h2 id="查看FW和驱动的配套关系"><a href="#查看FW和驱动的配套关系" class="headerlink" title="查看FW和驱动的配套关系"></a>查看FW和驱动的配套关系</h2><p>在处理VMware问题的过程中，我们发现很大一部分问题都是使用系统自带inbox驱动，或者使用的驱动和FW 不配套导致的。因此检查驱动和FW配套是VMware日志分析中很重要的一步，一旦发现有驱动和FW不配套的问题，即使最后确认问题跟驱动和FW无关，也要推动客户升级到配套的版本。下面我们详细介绍驱动、FW配套检查的方法。</p><h3 id="网卡"><a href="#网卡" class="headerlink" title="网卡"></a>网卡</h3><p>网卡的驱动和FW版本检查比较简单，方法如下：</p><ol><li>首先通过查看vm support日志中的“commands\nicinfo.sh.txt”找到对应网卡的驱动和FW版本，如下图所示：</li></ol>  <img src="/posts/2252/zh-cn_image_0258617299.png" class=""><ol start="2"><li>和驱动版本配套表中的驱动和FW版本进行对比即可。</li></ol>  <img src="/posts/2252/zh-cn_image_0258617310.png" class=""><h3 id="RAID卡"><a href="#RAID卡" class="headerlink" title="RAID卡"></a>RAID卡</h3><p>VMware自ESXi5.5开始引入native驱动，原有的驱动为legacy驱动。 对于2208/3008/3108等RAID卡会存在两种类型的驱动，ESXi默认使用native驱动。在使用过程中发现native驱动问题较多，iDriver发布的RAID卡驱动采用了legacy驱动。所以升级驱动时请特别注意，一定要使用iDriver的自动升级脚本进行升级，不要只取iDriver软件包的RAID卡驱动进行升级。因为ESXi系统默认使用的是native驱动，只升级iDriver下的legacy驱动，ESXi系统还是会加载默认的native驱动，需要将native驱动禁用以后，系统才会加载legacy驱动。</p><h4 id="驱动类型"><a href="#驱动类型" class="headerlink" title="驱动类型"></a>驱动类型</h4><p>检查RAID卡的驱动和FW版本之前，首先要检查系统加载的是native驱动还是legacy驱动，这个通过驱动名称就可以区分。</p><table><thead><tr><th>RAID卡类型</th><th>legacy驱动名称</th><th>native驱动名称</th></tr></thead><tbody><tr><td>LSI SAS2208</td><td>megaraid_sas</td><td>lsi-mr3</td></tr><tr><td>LSI SAS2308</td><td>scsi-mpt2sas</td><td>NULL</td></tr><tr><td>LSI SAS3008</td><td>mpt3sas</td><td>lsi_msgpt3</td></tr><tr><td>LSI SAS3108</td><td>megaraid_sas</td><td>lsi-mr3</td></tr></tbody></table><p>RAID卡加载的驱动类型，在vm support日志的commands\localcli_storage-core-adapter-list.txt文件中可以查看。</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617370.png%}</p><h4 id="驱动版本"><a href="#驱动版本" class="headerlink" title="驱动版本"></a>驱动版本</h4><p>驱动版本信息在vm support日志的commands\localcli_software-vib-list.txt文件中可以查看。</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617514.png%}</p><h4 id="FW版本"><a href="#FW版本" class="headerlink" title="FW版本"></a>FW版本</h4><p>RAID卡的FW版本信息，可以通过在var\run\log\vmkernel*中查看ESXi主机启动日志中查询到。如LSI SAS2308 RAID卡驱动在加载时的打印信息如下，如果在vmkernel中没有查询到FW版本，可以通过查询RAID卡的日志确认。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mpt2sas0: LSISAS2308: FWVersion(15.00.03.00), ChipRevision(0x05), BiosVersio</span><br></pre></td></tr></table></figure><h3 id="vm-support日志分析"><a href="#vm-support日志分析" class="headerlink" title="vm-support日志分析"></a>vm-support日志分析</h3><p>本节开始讲解如何查看vm support日志。下图是vm support日志解压完成后的视图，内容比较多，这里重点讲解定位问题时最常用的/var目录和/commands目录。</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617526.png%}</p><h4 id="vm-support-log目录"><a href="#vm-support-log目录" class="headerlink" title="vm-support log目录"></a>vm-support log目录</h4><p>这节开始讲解vm support日志的log目录，先看一下VMware官网的介绍。</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617528.png%}</p><p>这里看到的log目录都在/var/log目录下，实际上在ESXi系统下有2个目录都有系统日志一个是/var/log 一个是/var/run/log ，两者实际是相同的。</p><p>/var/log目录，日志都是链接到/scratch/log/目录下。</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617557.png%}</p><p>/var/run/log也是链接到/scratch/log/目录。</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617531.png%}</p><p>vm support日志中也有2个log目录，我们关注/var/run/log下的内容即可。下面重点介绍一下常用的log文件。</p><h5 id="vmkernel"><a href="#vmkernel" class="headerlink" title="vmkernel"></a>vmkernel</h5><p>vmkernel log文件中记录虚拟机和ESXi主机的有关的活动，vmkernel是一个大宝矿，几乎所有的故障，vmkernel中都会有记录。</p><h5 id="vmkwarning"><a href="#vmkwarning" class="headerlink" title="vmkwarning"></a>vmkwarning</h5><p>vmkwarning log把vmkernel中的“WARNING”信息单独过滤出来，可以更快地浏览系统的warning信息。</p><h5 id="vpxa-amp-host"><a href="#vpxa-amp-host" class="headerlink" title="vpxa &amp; host"></a>vpxa &amp; host</h5><p>VC（VCenter）要管理ESXi主机，需要在VC侧运行一个vpxd的daemon ，ESXi主机侧运行一个vpxa的agent ，VC对ESXi主机的管理通过vpxd和vpxa的通信完成。同时vpxa收到VC的任务以后，会通知hostd来完成最终的任务。因此我们在vSphere client上下发一个任务，任务依次通过vpxd-&gt;vpxa-&gt;hostd。</p><p>在定位问题时，我们经常想了解故障时用户在做什么操作。通过分析vpxa和hostd log就可以看到故障时用户在做什么操作，对我们分析、复现问题都有很大的帮助。下面看几个典型场景下的vpxa和hostd log。</p><h6 id="关闭虚拟机"><a href="#关闭虚拟机" class="headerlink" title="关闭虚拟机"></a>关闭虚拟机</h6><p>vpxa.log</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2016-11-25T15:19:22.146Z info vpxa[FFE12B70] [Originator@6876 sub=vpxLro opID=51602CC1-000022D9-a3-3b] [VpxLRO] -- BEGIN task-47493 -- vpxa -- vpxapi.VpxaService.powerOffVm -- 523432f3-831a-5c5c-553f-43b662264e5d</span><br></pre></td></tr></table></figure><p>hostd.log</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2016-11-25T15:19:22.148Z info hostd[4F5C2B70] [Originator@6876 sub=Vimsvc.TaskManager opID=51602CC1-000022D9-a3-3b-f6a1 user=vpxuser:VSPHERE.LOCAL\Administrator] Task Created : haTask-10-vim.VirtualMachine.powerOff-39668</span><br></pre></td></tr></table></figure><h6 id="启动虚拟机"><a href="#启动虚拟机" class="headerlink" title="启动虚拟机"></a>启动虚拟机</h6><p>vpxa.log</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2016-11-25T15:31:22.080Z info vpxa[5107CB70] [Originator@6876 sub=vpxLro opID=51602CC1-00002325-6f-ce-40-f4-b-bf] [VpxLRO] -- BEGIN task-47531 -- vpxa -- vpxapi.VpxaService.powerOnVm -- 523432f3-831a-5c5c-553f-43b662264e5d</span><br></pre></td></tr></table></figure><p>hostd.log</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2016-11-25T15:31:22.082Z info hostd[4F540B70] [Originator@6876 sub=Vimsvc.TaskManager opID=51602CC1-00002325-6f-ce-40-f4-b-bf-f929 user=vpxuser:VSPHERE.LOCAL\Administrator] Task Created : haTask-10-vim.VirtualMachine.powerOn-397025</span><br></pre></td></tr></table></figure><h6 id="迁移虚拟机"><a href="#迁移虚拟机" class="headerlink" title="迁移虚拟机"></a>迁移虚拟机</h6><p>迁移的情况比较复杂，我们要分源主机的vpxa.log和host.log，以及目的主机的vpxa.log和host.log。</p><p>源主机vpxa.log</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">2016-11-25T15:51:01.878Z info vpxa[51184B70] [Originator@6876 sub=vpxLro opID=51602CC1-000023CC-a3-85-f5] [VpxLRO] -- BEGIN task-47615 -- vmotionManager -- vim.host.VMotionManager.prepareSourceEx -- 523432f3-831a-5c5c-553f-43b662264e5d</span><br><span class="line">2016-11-25T15:51:01.878Z verbose vpxa[51184B70] [Originator@6876 sub=vpxaDatastoreContext opID=51602CC1-000023CC-a3-85-f5] [VpxaDatastoreContext] Resolved URL ds:///vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx to localPath /vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx</span><br><span class="line">2016-11-25T15:51:01.878Z verbose vpxa[51184B70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-f5] [MIGRATE] (1480060321983341) PrepareSourceEx start</span><br><span class="line">2016-11-25T15:51:01.878Z verbose vpxa[51184B70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-f5] [MIGRATE] (1480060321983341) srcIp 172.168.104.102</span><br><span class="line">2016-11-25T15:51:01.878Z verbose vpxa[51184B70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-f5] [MIGRATE] (1480060321983341) dstIp 172.168.104.101</span><br><span class="line">2016-11-25T15:51:01.878Z verbose vpxa[51184B70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-f5] [MIGRATE] (1480060321983341) VM moId vm-11</span><br><span class="line">2016-11-25T15:51:01.878Z verbose vpxa[51184B70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-f5] [MIGRATE] (1480060321983341) srcLoggingIp</span><br><span class="line">2016-11-25T15:51:01.878Z verbose vpxa[51184B70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-f5] [MIGRATE] (1480060321983341) dstLoggingIp</span><br><span class="line">2016-11-25T15:51:01.878Z info vpxa[51184B70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-f5] [VpxaMoVMotion::PrepareSourceEx] invoke IsFtFailingOverVm on VM [/vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx].</span><br></pre></td></tr></table></figure><p>源主机hostd.log</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2016-11-25T15:51:01.880Z info hostd[4E7C2B70] [Originator@6876 sub=Vcsvc.VMotion opID=51602CC1-000023CC-a3-85-f5-fe3a user=vpxuser:VSPHERE.LOCAL\Administrator] PrepareSourceEx [1480060321983341], VM = &#x27;10&#x27;</span><br><span class="line">2016-11-25T15:51:01.880Z info hostd[4E7C2B70] [Originator@6876 sub=Vcsvc.VMotionSrc (1480060321983341) opID=51602CC1-000023CC-a3-85-f5-fe3a user=vpxuser:VSPHERE.LOCAL\Administrator] VMotionEntry: migrateType = 1</span><br><span class="line">2016-11-25T15:51:01.880Z info hostd[4E7C2B70] [Originator@6876 sub=Vmsvc.vm:/vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx opID=51602CC1-000023CC-a3-85-f5-fe3a user=vpxuser:VSPHERE.LOCAL\Administrator] State Transition (VM_STATE_ON -&gt; VM_STATE_EMIGRATING)</span><br><span class="line">2016-11-25T15:51:01.881Z info hostd[4E7C2B70] [Originator@6876 sub=Vmsvc.vm:/vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx opID=51602CC1-000023CC-a3-85-f5-fe3a user=vpxuser:VSPHERE.LOCAL\Administrator] VMotionPrepare: srcLoggingIp=</span><br><span class="line">2016-11-25T15:51:01.881Z info hostd[4E7C2B70] [Originator@6876 sub=Vmsvc.vm:/vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx opID=51602CC1-000023CC-a3-85-f5-fe3a user=vpxuser:VSPHERE.LOCAL\Administrator] VMotionPrepare: dstLoggingIp=</span><br><span class="line">2016-11-25T15:51:01.881Z info hostd[4E7C2B70] [Originator@6876 sub=Vmsvc.vm:/vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx opID=51602CC1-000023CC-a3-85-f5-fe3a user=vpxuser:VSPHERE.LOCAL\Administrator] VMotionPrepare: srcMgmtIp=172.168.103.102</span><br><span class="line">2016-11-25T15:51:01.881Z info hostd[4E7C2B70] [Originator@6876 sub=Vmsvc.vm:/vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx opID=51602CC1-000023CC-a3-85-f5-fe3a user=vpxuser:VSPHERE.LOCAL\Administrator] VMotionPrepare: dstMgmtIp=172.168.103.101</span><br></pre></td></tr></table></figure><p>目的主机vpxa.log</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2016-11-25T15:47:13.586Z verbose vpxa[6A28DB70] [Originator@6876 sub=vpxaDatastoreContext opID=51602CC1-000023CC-a3-85-96] [VpxaDatastoreContext] Resolved URL ds:///vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx to localPath /vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx</span><br><span class="line">2016-11-25T15:47:13.586Z verbose vpxa[6A28DB70] [Originator@6876 sub=vpxaDatastoreContext opID=51602CC1-000023CC-a3-85-96] [VpxaDatastoreContext] Resolved URL ds:///vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/ to localPath /vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/</span><br><span class="line">2016-11-25T15:47:13.586Z verbose vpxa[6A28DB70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-96] [MIGRATE] (1480060321983341) PrepareDestinationEx start</span><br><span class="line">2016-11-25T15:47:13.586Z verbose vpxa[6A28DB70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-96] [MIGRATE] (1480060321983341) srcIp 172.168.104.102</span><br><span class="line">2016-11-25T15:47:13.586Z verbose vpxa[6A28DB70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-96] [MIGRATE] (1480060321983341) dstIp 172.168.104.101</span><br><span class="line">2016-11-25T15:47:13.586Z verbose vpxa[6A28DB70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-96] [MIGRATE] (1480060321983341) srcLoggingIp</span><br><span class="line">2016-11-25T15:47:13.586Z verbose vpxa[6A28DB70] [Originator@6876 sub=vpxaMoVMotion opID=51602CC1-000023CC-a3-85-96] [MIGRATE] (1480060321983341) dstLoggingIp</span><br></pre></td></tr></table></figure><p>目的主机hostd.log</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2016-11-25T15:47:13.587Z info hostd[FFF93B70] [Originator@6876 sub=Vcsvc.VMotion opID=51602CC1-000023CC-a3-85-96-1c1e user=vpxuser:VSPHERE.LOCAL\Administrator] PrepareDestinationEx [1480060321983341]</span><br><span class="line">2016-11-25T15:47:13.587Z info hostd[FFF93B70] [Originator@6876 sub=Vcsvc.VMotionDst (1480060321983341) opID=51602CC1-000023CC-a3-85-96-1c1e user=vpxuser:VSPHERE.LOCAL\Administrator] VMotionEntry: migrateType = 1</span><br><span class="line">2016-11-25T15:47:13.587Z info hostd[FFF93B70] [Originator@6876 sub=Vcsvc.VMotion opID=51602CC1-000023CC-a3-85-96-1c1e user=vpxuser:VSPHERE.LOCAL\Administrator] Completed PrepareDestinationEx [1480060321983341]</span><br><span class="line">2016-11-25T15:47:13.695Z info hostd[4F110B70] [Originator@6876 sub=Vcsvc.VMotion opID=51602CC1-000023CC-a3-85-dc-1c23 user=vpxuser:VSPHERE.LOCAL\Administrator] InitiateDestination [1480060321983341], VM = &#x27;/vmfs/volumes/vsan:5225575656b0c9c4-5971c24874feb971/43942c58-a892-5658-dc5f-18c58a0f795f/vm-24.vmx&#x27;</span><br></pre></td></tr></table></figure><h5 id="vobd-log"><a href="#vobd-log" class="headerlink" title="vobd.log"></a>vobd.log</h5><p>/var/log/vobd.log:</p><ul><li>VMkernel observations</li><li>Useful for network and performance issues</li></ul><p>vobd.log会记录一些网卡up down或者IO latency告警信息。这些信息一般在vmkenrel中都会有记录，某些情况下vmkernel中可能没有记录，而vobd.log中有记录，可以辅助分析一些问题。如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">IO latency 告警</span><br><span class="line">Device naa.60030130f09000001fbc610c7c39d5bd performance has improved. I/O latency reduced from 4694 microseconds to 4393 microseconds.</span><br><span class="line">网卡up/down 信息</span><br><span class="line">Uplink: vmnic0 is down. Affected portgroup: VM Network. 0 uplinks up. Failed criteria: 128</span><br></pre></td></tr></table></figure><h5 id="esxupdate-log"><a href="#esxupdate-log" class="headerlink" title="esxupdate.log"></a>esxupdate.log</h5><p>/var/log/esxupdate.log ESXi patch and update installation logs.</p><p>esxupdate.log记录了用户的升级记录，对于一些升级某个补丁或者驱动导致的问题分析很有帮助。</p><h5 id="shell-log"><a href="#shell-log" class="headerlink" title="shell.log"></a>shell.log</h5><p>shell.log会记录所有在shell 上执行的命令，通过这个log可以了解用户在shell 下做过哪些配置。</p><h5 id="虚拟机log"><a href="#虚拟机log" class="headerlink" title="虚拟机log"></a>虚拟机log</h5><p>需要查看虚拟机log时，首先查看系统运行的虚拟机列表，虚拟机列表在“commands\localcli_vm-process-list.txt” 文件中。 如下图所示：</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617603.png%}</p><p>然后进入虚拟机config File对应的目录下，如：</p><p>vmfs\volumes\vsan_5225575656b0c9c4-5971c24874feb971\29a72958-9671-ae9c-9a7c-18c58a0f795f</p><p>目录内容如下图所示，其中.vmx是虚拟机的配置文件，vmware.log是虚拟机的日志。</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617626.png%}</p><p>注意：虚拟机信息是动态变化的，一定要确认清楚vm support日志收集的时间是否就是问题的发生时间，很多问题的日志都是事后收集的，这时候的虚拟机日志已经没有太大的分析价值了。</p><h5 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h5><p>下面以硬盘故障为例进行说明。假如在vmkernel中看到“Cmd xxx to dev xxx failed H：x D：x P：x Possible sense data：xxx”，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ScsiDeviceIO: 2607: Cmd(0x439e69844f00) 0x28, CmdSN 0x147e257d from world 0 to dev &quot;naa.6101b5442bcc70001d54102408dd4fa9&quot; failed H:0x5 D:0x0 P:0x0 Possible sense data: 0x5 0x20 0x0.</span><br></pre></td></tr></table></figure><p>看到上述日志时，首先确认dev “naa.6101b5442bcc70001d54102408dd4fa9” 这个设备是本地磁盘还是存储设备。通过vm support的“commands\localcli_storage-core-device-list.txt”查找到对应设备，查看设备的详细信息。如下图所示：</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617633.png%}</p><p>接着我们解析“H：x D：x P：x Possible sense data：xxx”信息，意义如下：</p><p>H:0xA D:0xB P:0xC Possible sense data: 0xD 0xE 0xF</p><p>A = Host status (Initiator)</p><p>B = Device Status (Target)</p><p>C = Plugin (VMware Specific)</p><p>D = Sense Key</p><p>E = Additional Sense Code</p><p>F = Additional Sense Code Qualifier</p><p>详细的信息介绍，请参考VMware KB：</p><p><a href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&cmd=displayKC&externalId=289902">Interpreting SCSI sense codes in VMware ESXi and ESX (289902)</a></p><p>最后推荐一款VMware开发的解析工具，链接如下：</p><p><a href="https://www.virten.net/vmware/esxi-scsi-sense-code-decoder/">https://www.virten.net/vmware/esxi-scsi-sense-code-decoder/</a></p><p>打开链接后，依次输入“H：x D：x P：x”以及sense data的信息，单击“Submit”提交进行解析，会显示如下的结果：</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617624.png%}</p><p>通过工具解析，可以看到这是一个“ILLEGAL REQUEST”非法请求，Host端把该IO ABORT掉了。</p><h4 id="dump解析"><a href="#dump解析" class="headerlink" title="dump解析"></a>dump解析</h4><p>如果ESXi主机运行过程中出现紫屏，会自动收集dump日志信息，类似linux系统的core dump。dump日志在vm support日志的“var\core”目录下，名字为 vmkernel-zdump.1。</p><p>解析esxi zdump log只能在对应的ESXi系统上进行解析，如ESXi 5.5的zdump只能在ESXi 5.5系统上解析，ESXi 6.0的zdump只能在ESXi 6.0系统上解析。ESXi系统下解析zdump的方法如下：</p><p># esxcfg-dumppart –log ./vmkernel-zdump.1</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617644.png%}</p><p>打开解压出来的vmkernel-log.1 ，搜索“BlueScreen”关键字查看死机的原因，以及挂死时的trace信息。</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617648.png%}</p><p>在“BlueScreen”前ESXi系统会打印出各个CPU core的运行进程和VM信息，有助于分析死机前系统的运行状态。</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617651.png%}</p><p>由于VMware ESXi系统不是开源的，更多的dump信息解析需要将日志提交给VMware的技术支持才能分析出死机的原因。</p><h4 id="commands目录"><a href="#commands目录" class="headerlink" title="commands目录"></a>commands目录</h4><p>vm support日志的commands目录包含了EXSi系统的很多重要配置，也是一座大宝矿，这里选取一些常用的关键信息讲解，更多的内容需要大家自己去发掘。</p><table><thead><tr><th>文件</th><th>用途</th></tr></thead><tbody><tr><td>esxcfg-info_-a.txt*</td><td>查看CPU、memory、PCIe等硬件信息</td></tr><tr><td>esxcfg-vmknic_-l.txt</td><td>vmk网卡信息及配置</td></tr><tr><td>esxcfg-vswitch_-l.txt</td><td>vswitch相关的配置信息</td></tr><tr><td>fdisk_-lu.txt</td><td>磁盘已经分区信息</td></tr><tr><td>irqinfo.txt</td><td>中断统计信息，类似linux系统的/proc/ interrupts</td></tr><tr><td>localcli_hardware-ipmi*</td><td>通过ipmi获取的单板sdr sel等信息，一般这些信息我们都在BMC下查看，不需要太多关注。注意：localcli_hardware-ipmi-fru-list–p–i–n-all.txt，中包含单板的Serial Number，可以帮助我们确认单板，避免分析的vm support日志和BMC 日志不是同一台机器的情况。</td></tr><tr><td>localcli_iscsi*</td><td>iscsi 相关的配置</td></tr><tr><td>localcli_software*</td><td>软件、驱动包相关的信息</td></tr><tr><td>localcli_storage*</td><td>存储适配器，存储设备相关的信息</td></tr><tr><td>localcli_vsan*</td><td>vsan相关的配置信息</td></tr><tr><td>localcli_vm-process-list.txt</td><td>运行虚拟机列表信息</td></tr><tr><td>vmware_-vl.txt</td><td>uname_-a.txt</td></tr><tr><td>lspci.txtlspci_-v.txt</td><td>PCIe相关信息，但是vm support只收集了基本的lspci信息，更多的PCIe配置空间的信息没有收集，必要时可以在系统下运行#lspci –d或者 # lspci –e收集更多信息</td></tr><tr><td>smartinfo.sh.txt</td><td>磁盘设备的smart信息</td></tr><tr><td>smbiosDump.txt</td><td>服务器的SMBIOS信息</td></tr></tbody></table><h3 id="vCenter日志分析"><a href="#vCenter日志分析" class="headerlink" title="vCenter日志分析"></a>vCenter日志分析</h3><p>VCenter日志在“ProgramData\VMware\vCenterServer\logs”目录下，该目录下各个日志的介绍如下。</p><p>![img](C:\Users\gaoshuai\Desktop\tblog\source_posts\VMware系统专题\zh-cn_image_0258617652.png%}</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2115740">https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2115740</a></p><p><a href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=289902">https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=289902</a></p><p><a href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=2004566">https://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=2004566</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> VMware </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
